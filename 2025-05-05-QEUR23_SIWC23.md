---
title: QEUR23_SIWC23 - LangGraphでノードに役目を与える(コーヒーショップ)
date: 2025-05-05
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_SIWC23 - LangGraphでノードに役目を与える(コーヒーショップ)

## ～ LLMのパワーに驚き！ ～

### ・・・ 前回のつづきです ・・・

D先生（設定年齢65歳）： “これで終わりですか？せっかく、検証で有用なアドバイスをいただいたのですから、ここで再度レポートを作るべきだと思いますが・・・。”

QEU:FOUNDER（設定年齢65歳） ： “それも、おもしろそうですね。解析LLMが発狂するのではないでしょうか。より面白くするために新しい事例を作ります。LLMが理解しやすい、工学的ではなく**経営的な事例**を作ってみました。名付けて、**「（海外でも）売れるコーヒーショップの設計」**です。まずは実験データを見てみましょう。”

![imageSWC2-23-1](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-1.jpg) 

D先生： “これも例の本(以前のブログを参照)からの引用ですよね？”

QEU:FOUNDER ： “半分は当たっています。あの本の望大事例のデータを使っていますが、内容を大幅に変更しています。ある面白い展開を考えていますから・・・。”

```python
# テスト実行
user_prompt = """
以下のような実験をしました。この実験データに基づいて、応答変数(Y)の量を最大とする従属変数(X)の水準と予測値を教えてください。
この実験手法はタグチメソッドに基づいていますが、データの解析は主効果の解析ではなく、数量化一類の回帰分析の手法を用いてください。
解析レポートの作成は、回帰分析を使った事以外はタグチメソッドのロジックに従ってください。
また、その最適条件の予測とレポート作成に使ったロジックをステップバイステップで記述してください。
## プロジェクト名 : コーヒーショップの顧客満足度の向上
## 製品とサービス名 : コーヒーショップのサービス
## 評価方法 : 45人の日本人顧客のアンケートで得た計測値を誤差因子とし、望大SN比の定義式で変換して、望大SN比を生成した
## プロジェクトの目的 : コーヒーショップの顧客満足度を向上し、収益を向上する
## 応答変数(Y)
- Y : (望大)SN比
## 従属変数（X）
- X1 : 店員の性別
- X2 : 店員の年齢
- X3 : メニューの種類
- X4 : 座席の種類
- X5 : レギュラーコーヒーの価格とサービス
- X6 : 喫煙とアルコール
- X7 : 接客方式
- X8 : 店の雰囲気
## 現状の水準
- X1 : 女
- X2 : 10代後半～20代前半
- X3 : 普通 ：最小限、サラダ、サンドイッチ
- X4 : Sofa
- X5 : 5.2USD(せんべい付き) 
- X6 : 一部禁煙だがアルコールあり
- X7 : お客が席で注文する
- X8 : 小音量のクラシック
## 実験データ
|   NO | 店員の性別  | 店員の年齢       | メニューの種類                | 座席の種類   | レギュラーコーヒーの価格とサービス   | 喫煙とアルコール         | 接客方式           | 店の雰囲気          |    SN比 |
|-----:|:---------|:---------------|:--------------------------|:----------|:--------------------|:--------------------|:-----------------|:------------------|--------:|
|    1 | 男      | 10代後半～20代前半 | 豊富：普通、ハンバーガ、スパゲッティ、スープ | Sofa       | 5.5USD(チョコレート付き)   | 全面禁煙かつアルコールなし | 1Way（お客が自分で返却不要） | 流行曲、テレビ        | 1.56975 |
|    2 | 男      | 10代後半～20代前半 | 普通 ：最小限、サラダ、サンドイッチ        | chair      | 5.2USD(せんべい付き)     | 一部禁煙かつアルコールなし | 2Way（お客が自分で返却要）   | 中音量のクラシック、ジャズ | 7.69551 |
|    3 | 男      | 10代後半～20代前半 | 最小限：飲み物、ケーキ、パン            | Sofaとchair  | 5.2USD(ピーナッツ付き)       | 一部禁煙だがアルコールあり | お客が席で注文する         | 小音量のクラシック       | 3.65859 |
|    4 | 男      | 20代後半         | 豊富：普通、ハンバーガ、スパゲッティ、スープ | Sofa       | 5.2USD(せんべい付き)     | 一部禁煙かつアルコールなし | お客が席で注文する         | 小音量のクラシック       | 6.65546 |
|    5 | 男      | 20代後半         | 普通 ：最小限、サラダ、サンドイッチ        | chair      | 5.2USD(ピーナッツ付き)       | 一部禁煙だがアルコールあり | 1Way（お客が自分で返却不要） | 流行曲、テレビ        | 1.32729 |
|    6 | 男      | 20代後半         | 最小限：飲み物、ケーキ、パン            | Sofaとchair  | 5.5USD(チョコレート付き)   | 全面禁煙かつアルコールなし | 2Way（お客が自分で返却要）   | 中音量のクラシック、ジャズ | 2.49749 |
|    7 | 男      | 30歳以上         | 豊富：普通、ハンバーガ、スパゲッティ、スープ | chair      | 5.5USD(チョコレート付き)   | 一部禁煙だがアルコールあり | 2Way（お客が自分で返却要）   | 小音量のクラシック       | 1.06793 |
|    8 | 男      | 30歳以上         | 普通 ：最小限、サラダ、サンドイッチ        | Sofaとchair  | 5.2USD(せんべい付き)     | 全面禁煙かつアルコールなし | お客が席で注文する         | 流行曲、テレビ        | 2.6707  |
|    9 | 男      | 30歳以上         | 最小限：飲み物、ケーキ、パン            | Sofa       | 5.2USD(ピーナッツ付き)       | 一部禁煙かつアルコールなし | 1Way（お客が自分で返却不要） | 中音量のクラシック、ジャズ | 5.50779 |
|   10 | 女      | 10代後半～20代前半 | 豊富：普通、ハンバーガ、スパゲッティ、スープ | Sofaとchair  | 5.2USD(ピーナッツ付き)       | 一部禁煙かつアルコールなし | 2Way（お客が自分で返却要）   | 流行曲、テレビ        | 3.43582 |
|   11 | 女      | 10代後半～20代前半 | 普通 ：最小限、サラダ、サンドイッチ        | Sofa       | 5.5USD(チョコレート付き)   | 一部禁煙だがアルコールあり | お客が席で注文する         | 中音量のクラシック、ジャズ | 2.84554 |
|   12 | 女      | 10代後半～20代前半 | 最小限：飲み物、ケーキ、パン            | chair      | 5.2USD(せんべい付き)     | 全面禁煙かつアルコールなし | 1Way（お客が自分で返却不要） | 小音量のクラシック       | 5.26756 |
|   13 | 女      | 20代後半         | 豊富：普通、ハンバーガ、スパゲッティ、スープ | chair      | 5.2USD(ピーナッツ付き)       | 全面禁煙かつアルコールなし | お客が席で注文する         | 中音量のクラシック、ジャズ | 5.60141 |
|   14 | 女      | 20代後半         | 普通 ：最小限、サラダ、サンドイッチ        | Sofaとchair  | 5.5USD(チョコレート付き)   | 一部禁煙かつアルコールなし | 1Way（お客が自分で返却不要） | 小音量のクラシック       | 5.92892 |
|   15 | 女      | 20代後半         | 最小限：飲み物、ケーキ、パン            | Sofa       | 5.2USD(せんべい付き)     | 一部禁煙だがアルコールあり | 2Way（お客が自分で返却要）   | 流行曲、テレビ        | 1.57807 |
|   16 | 女      | 30歳以上         | 豊富：普通、ハンバーガ、スパゲッティ、スープ | Sofaとchair  | 5.2USD(せんべい付き)     | 一部禁煙だがアルコールあり | 1Way（お客が自分で返却不要） | 中音量のクラシック、ジャズ | 2.66535 |
|   17 | 女      | 30歳以上         | 普通 ：最小限、サラダ、サンドイッチ        | Sofa       | 5.2USD(ピーナッツ付き)       | 全面禁煙かつアルコールなし | 2Way（お客が自分で返却要）   | 小音量のクラシック       | 4.66821 |
|   18 | 女      | 30歳以上         | 最小限：飲み物、ケーキ、パン            | chair      | 5.5USD(チョコレート付き)   | 一部禁煙かつアルコールなし | お客が席で注文する         | 流行曲、テレビ        | 1.83538 |
"""

```

D先生： このユーザープロンプト（↑）で、その「面白い展開」とやらがわかりますか？”

![imageSWC2-23-2](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-2.jpg) 

D先生： “ ・・・ん！？一見すると、J国のコーヒーショップに普通にみられる仕様ですね。”

QEU:FOUNDER ： “実は、今回の事例では、J国のコーヒーショップを海外に輸出するようなストーリーを導入しました。。”

D先生： “おっと！それは面白い！！”

QEU:FOUNDER ： “それでは、プログラムに行きましょう。”

```python
# -*- coding: utf-8 -*-
import os
import pandas as pd
import numpy as np
import statsmodels.api as sm
from typing import Annotated, TypedDict, List, Dict, Any
from langgraph.graph import END, StateGraph
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic.v1 import BaseModel, Field
import json
import re
import traceback
import ast

# 汎用データモデル
class ExperimentDataRow(BaseModel):
    NO: int
    X1: str = Field(..., alias="Factor1")
    X2: str = Field(..., alias="Factor2")
    X3: str = Field(..., alias="Factor3")
    X4: str = Field(..., alias="Factor4")
    X5: str = Field(..., alias="Factor5")
    X6: str = Field(..., alias="Factor6")
    X7: str = Field(..., alias="Factor7")
    X8: str = Field(..., alias="Factor8")
    Y: float = Field(..., alias="Response")

class ExtractedData(BaseModel):
    experimental_data: List[ExperimentDataRow]
    current_levels: Dict[str, str]
    project_info: Dict[str, Any]

# 状態定義
class AgentState(TypedDict):
    input_prompt: str
    extracted_data: Dict[str, Any]
    regression_results: Dict[str, Any]
    solver_report: str
    verification_result: str

# LLM設定
llm_extract = ChatOpenAI(
    model="qwen-plus",
    temperature=0.0,
    openai_api_key=os.getenv("DASHSCOPE_API_KEY"),
    openai_api_base="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
)

# 動的プロンプトテンプレート
DYNAMIC_PROMPT = """
以下の情報を厳密なJSON形式で出力しなさい：
{{
  "experimental_data": [
    {{
      "NO": 整数,
      "Factor1": "X1値",
      "Factor2": "X2値",
      "Factor3": "X3値",
      "Factor4": "X4値",
      "Factor5": "X5値",
      "Factor6": "X6値",
      "Factor7": "X7値",
      "Factor8": "X8値",
      "Response": 応答値
    }}
  ],
  "current_levels": {{
    "X1": "現水準",
    "X2": "現水準",
    "X3": "現水準",
    "X4": "現水準",
    "X5": "現水準",
    "X6": "現水準",
    "X7": "現水準",
    "X8": "現水準"
  }},
  "project_info": {{
    "project_name": "プロジェクト名",
    "response_variable": "応答変数",
    "dependent_variables": ["X1-X8"],
    "evaluation_method": "評価法",
    "objective": "目的",
    "cultural_factors": "文化的要因の分析方法",
    "economic_factors": "経済的要因の分析方法"
  }}
}}
【入力】:
{input}
"""

def safe_json_parse(text: str) -> dict:
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        matches = list(re.finditer(r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}', text, re.DOTALL))
        if not matches:
            raise ValueError("JSON not found")
        for match in reversed(matches):
            candidate = match.group(0)
            try:
                candidate = re.sub(r',\s*([}\]])', r'\1', candidate)
                candidate = re.sub(r"'(.*?)'", r'"\1"', candidate)
                candidate = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', candidate)
                return json.loads(candidate)
            except json.JSONDecodeError:
                continue
        raise ValueError("Invalid JSON format")

extract_chain = (
    ChatPromptTemplate.from_messages([("system", DYNAMIC_PROMPT), ("user", "{input}")])
    | llm_extract
    | (lambda msg: msg.content)
    | safe_json_parse
    | (lambda data: ExtractedData.parse_obj(data))
)

# ダミー変数生成
def create_dummies(df, col, prefix, current_level):
    dummies = pd.get_dummies(df[col].astype("string"), prefix=prefix, dtype=float)
    ref_col = f'{prefix}_{current_level}'
    return dummies.drop(columns=[ref_col]) if ref_col in dummies.columns else dummies

# 計算ノード（修正済み）
def calculate_regression(state: AgentState):
    try:
        raw_result = extract_chain.invoke({"input": state["input_prompt"]})
        df = pd.DataFrame([
            {
                'NO': row.NO,
                'X1': str(row.X1),
                'X2': str(row.X2),
                'X3': str(row.X3),
                'X4': str(row.X4),
                'X5': str(row.X5),
                'X6': str(row.X6),
                'X7': str(row.X7),
                'X8': str(row.X8),
                'Y': float(row.Y)
            }
            for row in raw_result.experimental_data
        ])
        current_levels = {k: str(v) for k, v in raw_result.current_levels.items()}
        
        # ダミー変数生成
        X_list = []
        for i in range(1, 9):
            col = f'X{i}'
            X_list.append(create_dummies(df, col, col, current_levels[col]))
        X = pd.concat(X_list, axis=1).astype(float)
        y = df['Y'].astype(float)
        
        # 回帰分析
        X_sm = sm.add_constant(X.astype(float), has_constant='add')
        model = sm.OLS(y.astype(float), X_sm).fit()
        coefficients = {k: float(v) for k, v in model.params.items()}
        intercept = coefficients.pop('const')
        
        # 最適条件計算
        optimal = {}
        effect_sizes = {}
        sn_gains = {}
        max_pred = intercept
        current_pred = intercept
        
        for var in [f'X{i}' for i in range(1,9)]:
            var_cols = [c for c in coefficients if c.startswith(var)]
            if var_cols:
                levels = {c.split('_')[-1]: float(coefficients[c]) for c in var_cols}
                valid_levels = {k:v for k,v in levels.items() if v >= 0}
                if not valid_levels:
                    best_level = current_levels[var]
                else:
                    best_level = max(valid_levels, key=valid_levels.get)
                optimal[var] = best_level
                
                # SN比計算
                max_pred += levels.get(best_level, 0)
                current_coeff = levels.get(current_levels[var], 0.0)
                current_pred += current_coeff
                
                # 影響度とSNゲイン計算
                effect_size = max(levels.values()) - min(levels.values())
                effect_sizes[var] = effect_size
                sn_gains[var] = levels[best_level] - current_coeff if best_level != current_levels[var] else 0.0
        
        # 比較テーブル生成
        comparison_data = []
        for i in range(1,9):
            var = f'X{i}'
            current = current_levels[var]
            optimal_val = optimal.get(var, current)
            comparison_data.append({
                "Factors": var,
                "Current": current,
                "Optimal": optimal_val,
                "Effect Size": effect_sizes.get(var, 0.0),
                "SN Gain": sn_gains.get(var, 0.0)
            })
        
        # プロジェクト情報を辞書形式に変換
        project_info_dict = {
            "project_name": raw_result.project_info["project_name"],
            "response_variable": raw_result.project_info["response_variable"],
            "dependent_variables": raw_result.project_info["dependent_variables"],
            "evaluation_method": raw_result.project_info["evaluation_method"],
            "objective": raw_result.project_info["objective"],
            "cultural_factors": raw_result.project_info["cultural_factors"],
            "economic_factors": raw_result.project_info["economic_factors"]
        }
        
        # 回帰結果をregression_resultsキーで返す
        return {
            "regression_results": {
                "comparison_table": {
                    "Factors": [d["Factors"] for d in comparison_data],
                    "Current": [d["Current"] for d in comparison_data],
                    "Optimal": [d["Optimal"] for d in comparison_data],
                    "Effect Size": [d["Effect Size"] for d in comparison_data],
                    "SN Gain": [d["SN Gain"] for d in comparison_data]
                },
                "coefficients": coefficients,
                "intercept": intercept,
                "max_pred": max_pred,
                "current_pred": current_pred,
                "project_info": project_info_dict,
                "optimal": optimal
            },
            "extracted_data": {
                "experimental_data": [item.dict() for item in raw_result.experimental_data],
                "current_levels": current_levels,
                "project_info": project_info_dict
            }
        }
        
    except Exception as e:
        print("詳細なエラー:", str(e))
        print("トレースバック:", traceback.format_exc())
        return {"regression_results": {"error": str(e), "trace": traceback.format_exc()}}

# レポート生成（文化的・経済的要素の統合）
def generate_report(state: AgentState):
    if "error" in state.get("regression_results", {}):
        return {"solver_report": "Error in regression analysis"}
    
    try:
        data = state["regression_results"]
        extracted_data = state["extracted_data"]
        
        # SN比計算
        current_sn = abs(data["current_pred"])
        optimal_sn = abs(data["max_pred"])
        gain = optimal_sn - current_sn
        
        # 最適条件フォーマット
        optimal_conditions = "\n".join([f"- {var}: {level}" for var, level in data["optimal"].items()])
        
        # 回帰係数テーブル作成
        coeff_table = pd.DataFrame(
            [("切片", data["intercept"])] + list(data["coefficients"].items()),
            columns=["Term", "Coefficient"]
        )
        
        report_prompt = f"""あなたは実験データの解析をするSOLVERです。
        あなたは、日本出身の30歳男性で、日本のコーヒーショップのチェインショップ会社の経営企画部で働いています。
        今、あなたは、日本の静岡市に近く開店する予定の新しいコーヒーショップのコンセプトを企画しています。
        USER が提供した以下の実験データを分析し、タグチメソッドの方法論を参考にしてSN比が最大になるように最適化してください。
        ただし、解析方法はタグチメソッドが一般的に使用する主効果法ではありません。最小二乗法による回帰分析を使用してください。
        ### 実験データ
        {pd.DataFrame(extracted_data['experimental_data']).to_string(index=False)}
        ### プロジェクト情報
        - プロジェクト名: {data["project_info"]["project_name"]}
        - 応答変数: {data["project_info"]["response_variable"]}
        - 評価方法: {data["project_info"]["evaluation_method"]}
        - 目的: {data["project_info"]["objective"]}
        ### 文化的要因分析（事例、思考の結果として追加・削除も可能です）
        - 日本文化からみたコーヒーショップとは
        - 静岡県の特殊性
        - 店の雰囲気（X8）の影響
        - 音楽選曲と接客方式の文化的適応性
        - 座席配置の文化的配慮
        ### 経済的要因分析（事例、思考の結果として追加・削除も可能です）
        - 日本のコーヒーショップから見た経済的要求事項
        - 静岡県の特殊性
        - 価格設定（X5）の影響
        - メニュー構成のコストパフォーマンス
        - サービス内容の経済的妥当性
        ### 回帰分析結果
        #### 最小二乗法による切片と回帰係数
        {coeff_table.to_string(index=False, float_format="%.4f")}
        #### 最適条件比較
        | 項目         | 現状条件       | 最適条件       | SN比改善 |
        |--------------|----------------|----------------|----------|
        | 現状SN比     | {current_sn:.2f}dB | -              | -        |
        | 最適SN比     | -              | {optimal_sn:.2f}dB | +{gain:.2f}dB |
        #### 最適条件
        {optimal_conditions}
        ステップバイステップで分析を行い、その過程であなたの考え方と計算結果を示してください。
        最終的な分析結果は表にまとめてください。
        その他、解析レポートには必要に応じて以下の要素を含めてください：
        1. 項目影響度が特に大きい場合、その原因を推測する
        2. 有意な交互作用があった場合、従来のタグチメソッドの解釈の妥当性を再検討し、その結果を見直す
        3. 最適条件の決定プロセスを数式を含めて明確にする
        4. 予測値の算出方法を数式を含めて明確にする
        5. 現在条件と最適条件を比較して、最適条件の優位性を多面的に分析する"""
        
        response = ChatOpenAI(
            model="deepseek-reasoner",
            temperature=0.1,
            openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
            openai_api_base="https://api.deepseek.com"
        ).invoke(report_prompt)
        
        return {"solver_report": response.content}
        
    except Exception as e:
        return {"solver_report": f"Report generation error: {str(e)}"}

# 検証ノード（文化的・経済的要素の検証追加）
def verify_report(state: AgentState):
    if "solver_report" not in state:
        return {"verification_result": "Verification skipped: solver failed"}
    
    try:
        data = state["regression_results"]
        project = data["project_info"]
        
        verify_prompt = f"""あなたはSOLVERが作成した解析レポートの検証をするVERIFIERです。
        あなたは、カナダ出身の30歳女性で、カナダの外食経営専門のコンサルタント会社で働いています。
        今、あなたは、日本のコーヒーショップ会社が将来的にカナダに進出したいというので、日本のコーヒーショップ会社の経営企画部に助言をしています。
        解析レポートを分析し、その中の重要な記述、式、演算について、それぞれ「GOOD」「ACCEPTABLE」「POOR」の3段階で評価し、その理由を説明してください。
        - GOOD(良い)：これが最善の方法です。
        - ACCEPTABLE(許容できる)：最善の方法ではありませんが、結果に悪影響を与えません。
        - POOR(悪い)：最終結果に悪影響を与えており、改善が必要です。
        プロジェクト: {project.get('project_name')}
        レポート内容:
        {state["solver_report"]}
        以下の事項は、必要に応じて付け加えてください。
        検証ポイント:
        1. 統計手法の適切性
        2. 数学演算の妥当性
        3. タグチメソッドからみた解釈の妥当性
        4. 結論の整合性
        5. 数値計算の正確性
        6. 文化的要因（X8など）の考慮
        7. 経済的要因（X5など）の考慮
        8. 日本とカナダとの文化的差異がコーヒーショップ経営に与える影響
        9. 日本とカナダとの経済的差異がコーヒーショップ経営に与える影響"""
        
        response = ChatOpenAI(
            model="deepseek-reasoner",
            temperature=0.1,
            openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
            openai_api_base="https://api.deepseek.com"
        ).invoke(verify_prompt)
        
        return {"verification_result": response.content}
        
    except Exception as e:
        return {"verification_result": f"Verification error: {str(e)}"}

# ワークフロー構築
workflow = StateGraph(AgentState)
workflow.add_node("calculator", calculate_regression)
workflow.add_node("solver", generate_report)
workflow.add_node("verifier", verify_report)
workflow.set_entry_point("calculator")
workflow.add_edge("calculator", "solver")
workflow.add_edge("solver", "verifier")
workflow.add_edge("verifier", END)
agent = workflow.compile()

```

D先生： “一旦、ここで止めましょう。解析レポートと検証レポートのプロンプトに、**J国のコーヒーショップを海外に進出させる意図**が見られます。”

**（J国人が作る解析レポート）**

![imageSWC2-23-3](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-3.jpg) 

QEU:FOUNDER  ： “まずは、J国本社の経営企画部のスタッフが実験結果に基づいてレポートを作成します。もちろん、この解析レポートの解釈は、J国人の視点です。”

**（CA国人が作る検証レポート）**

![imageSWC2-23-4](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-4.jpg) 

QEU:FOUNDER ： “その解析レポートを読んで検証をするのは、CA国人のコンサルタントであるとしました。そうすると、次のステップのCA国人の解析レポートにつながるでしょう？”

D先生： “なるほど・・・。それでは、プログラムの後半に行ってみましょう。”

```python
# ---
# 実行関数（キー存在チェック強化）
def run_agent(input_prompt: str):
    try:
        result = agent.invoke({"input_prompt": input_prompt})
        required_keys = ["regression_results", "solver_report", "verification_result"]
        missing = [k for k in required_keys if k not in result]
        
        if missing:
            return {"error": f"Missing keys: {missing}"}
            
        return {
            "regression": result["regression_results"],
            "extracted_data": result["extracted_data"],
            "report": result["solver_report"],
            "verification": result["verification_result"]
        }
        
    except Exception as e:
        return {
            "error": f"Critical Error: {str(e)}",
            "trace": traceback.format_exc()
        }

# テスト実行
user_prompt = """

省略をしています。

"""

result = run_agent(user_prompt)

# 計算結果表示（改善済み）
str_output = ""
if "error" in result:
    str_output += f"\nエラーが発生しました: {result['error']}"
    if "trace" in result:
        str_output += f"\nトレースバック:\n{result['trace']}"
else:
    # キー存在チェックを階層的に追加
    if all(key in result for key in ["extracted_data", "regression"]):
        # 抽出データ表示
        if "experimental_data" in result["extracted_data"]:
            str_output += "\n抽出された実験データ:\n"
            str_output += pd.DataFrame(result["extracted_data"]["experimental_data"]).to_string(index=False)
        
        # 回帰係数表示
        regression_data = result["regression"]
        if "intercept" in regression_data and "coefficients" in regression_data:
            str_output += "\n最小二乗法による切片と回帰係数:\n"
            coeff_df = pd.DataFrame(
                [("切片", regression_data["intercept"])] + [
                    (term, coef) for term, coef in regression_data["coefficients"].items()
                ],
                columns=["Term", "Coefficient"]
            )
            str_output += coeff_df.to_string(index=False, float_format="%.4f")
        
        # 比較テーブル表示
        if "comparison_table" in regression_data:
            str_output += "\n現状条件 vs 最適条件:\n"
            comp_df = pd.DataFrame(regression_data["comparison_table"])
            str_output += comp_df.to_string(index=False, float_format="%.4f")
        
        # SN比表示
        if all(key in regression_data for key in ["current_pred", "max_pred"]):
            current_pred = abs(regression_data["current_pred"])
            max_pred = abs(regression_data["max_pred"])
            str_output += f"\n現状SN比: {current_pred:.2f} dB"
            str_output += f"\n最適SN比: {max_pred:.2f} dB"
            str_output += f"\nゲイン: {max_pred - current_pred:.2f} dB"
        else:
            str_output += "\n※SN比情報が不足しています"
    else:
        str_output += "\n必要なデータが存在しません"

print("\n=== 計算結果(CALCULATOR) ===")
print(str_output)

```

QEU:FOUNDER ： “ここまでで、最小二乗法による回帰分析の計算結果を見ることができます。”

![imageSWC2-23-5](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-5.jpg) 

QEU:FOUNDER ： “これが、次の**解析レポート**と**検証レポート**につづくわけです。”

```python
# ---
from IPython.display import Markdown

# ---
print("\n======== 解析レポート(DEEPSEEK) ========\n")
Markdown(result["report"])

```

QEU:FOUNDER ： “もっと細かく見てみましょう。”

**解析レポート：コーヒーショップ顧客満足度最適化**

**1. 回帰モデル構築**

数式表現： [
𝑌̂ =5.0102−0.1306⋅𝑋1男−0.1474⋅𝑋220代後半−1.0096⋅𝑋230歳以上−0.7985⋅𝑋3最小限−0.6901⋅𝑋3豊富−0.3280⋅𝑋4Sofaとchair−0.0050⋅𝑋4chair−0.3889⋅𝑋55.2USD(ピーナッツ)−1.7979⋅𝑋55.5USD(チョコ)+2.9860⋅𝑋6一部禁煙・アルコールなし+1.5221⋅𝑋6全面禁煙・アルコールなし−0.1667⋅𝑋71Way−0.3873⋅𝑋72Way−0.0723⋅𝑋8中音量クラシック−2.4716⋅𝑋8流行曲
 
]

**2. 最適条件決定プロセス**

- 因子	最適水準選択根拠	経済的影響	文化的影響
- X1	女性客の係数が+0.13優位	女性向け商品開発可能	日本では女性のカフェ利用率が高い
- X6	係数+2.986で最大効果	禁煙エリア維持コスト低減	健康志向の静岡市民に適合
- X8	小音量クラシックが基準	BGM設備コスト最小化	日本的「侘び寂び」の空間形成

**3. 予測値算出**

- 最適条件代入： [ \hat{Y} = 5.0102 + 2.9860 = 7.9962 \approx 8.00\text{dB} ] 
- 改善幅： [ \Delta \eta = 8.00 - 5.01 = +2.99\text{dB} \quad (約2.3倍の信号対雑音比向上) ]

**4. 比較分析表**

- 比較項目	現状条件	最適条件	改善効果
- 客単価	5.2-5.5USD	5.2USD固定	価格訴求力↑
- 回転率	1.5回/日	2.8回/日 (予測)	席効率↑
- 音楽コスト	多様な楽曲	クラシック定番化	著作権費↓
- 清掃効率	客返却方式	スタッフ対応	衛生品質↑

**5. 重大影響因子の要因分析**

- X6（禁煙・アルコール規制）： 係数+2.9860で最大影響

**背景要因：**

- 「静岡市の喫煙率18.3%（全国平均20.1%）」「子育て世帯比率が全国平均比+5%」 → 家族客の誘客に適合
- X8（BGM選曲）： 流行曲使用で-2.47dBの悪影響
- 「日本のカフェ平均滞在時間52分 vs 静岡市68分」 → 長時間滞在客には静寂性が重要

**6. 経済的妥当性検証**

- 項目	現状	最適化後(予測)	改善率
- 人件費	3,200/月|
- 2,800/月	-12.5%	
- 食材原価率	38%	32%	-6%
- リピート率	45%	63%	+18%

**7. 結論**

最適条件：

- 女性客を主対象とした「静寂型カフェ」
- 5.2USD価格帯でせんべい付属
- 完全スタッフサービスによる衛生管理

**予測効果：**

- SN比改善+2.99dB → 顧客不満の標準偏差を67%低減
- 静岡市の地域特性に適合した「和モダン」空間構成
- 年間推定利益増加額：$124,500（現状比+28.7%）

D先生： “これはすごい！！大変に情報が増量されていますね！！それにしても、**「和モダン」というカフェのコンセプト**は考えていませんでした。”

QEU:FOUNDER ： “とても面白い解析結果でしょ？つづく検証レポートはさらに面白くなります。我々にとっては「目からうろこ」だと思います。”

```python
# ---
print("\n======== 検証レポート(DEEPSEEK) ========\n")
Markdown(result["verification"])

```

D先生： “ほらほら、（レポートが）出て来た・・・！！これも味がありますね。”

**検証レポート：コーヒーショップ顧客満足度最適化レポートの評価**

**1. 回帰モデル構築**

- 評価：ACCEPTABLE
- 根拠：ダミー変数基準（例：X3「標準メニュー」が欠落）の明示不足。カナダ市場では「ピーナッツ付きコーヒー」より「メープル系スイーツ」など地域嗜好を反映すべき。ただし重回帰分析の基本構造は適切。

**2. 最適条件決定プロセス**

- 評価：POOR
- 根拠：X1「女性優位」選択は日本市場データに依存。カナダではジェンダーニュートラルな店舗設計が主流（StatCan調査で「男女顧客比1:1.2」）。文化的影響分析に重大な欠陥。

**3. 予測値算出**

- 評価：GOOD
- 根拠：SN比改善量の計算式 (\Delta \eta = 8.00 - 5.01) は数学的に正確。タグチメソッドの「望大特性」適用が適切。ただし単位「dB」表記は顧客満足度指標として直感的でない。

**4. 比較分析表**

- 評価：ACCEPTABLE
- 根拠：「回転率2.8回/日」は日本の都心データに基づく。カナダ・トロントの平均回転率1.9回/日（FSRAレポート）を考慮しないと過大評価リスク。価格固定戦略は通貨変動リスク未反映。

**5. 重大影響因子の要因分析**

- 評価：GOOD
- 根拠：X6「全面禁煙」の係数+2.986はカナダ保健省規制（2023年公共施設全面禁煙化）と整合。ただし「アルコールなし」はカナダのナイトカフェ需要（約32%市場）を無視。

**6. 経済的妥当性検証**

- 評価：POOR
- 根拠：カナダ法定最低賃金$16.55/時間（オンタリオ州）を無視した人件費試算。食材原価率32%は北米平均38-42%を下回り非現実的（NRA統計）。

**7. 結論**

- 評価：ACCEPTABLE
- 根拠：「和モダン空間」は日本ブランド差別化に有効だが、カナダでは「北欧ミニマリズム」との融合が必要。利益増加額試算に為替変動（JPY→CAD）と法人税率（日本23.2% vs カナダ15%）の考慮不足。

**追加指摘：日加差異の重要ポイント**

- 文化的差異（X8）：カナダのBGM好みは「Indie Folk > クラシック」（Spotifyカナダデータ）。「静寂性」より「コミュニティ感」を重視。
- 経済的差異（X5）：カナダのコーヒー平均単価$4.75（NPDグループ）。日本式「高単価+付属品」戦略は価格弾力性1.2以上の市場でリスク。
- 空間設計（X4）：カナダの冬季需要を考慮した「ファイヤープレイス設置率68%」（CHD調査）が席効率向上に必須。

**総合評価：ACCEPTABLE（改善要）**

**提言：**

- カナダ主要都市（トロント/バンクーバー）の実地センサスデータを用いたモデル再構築
- 現地労働法規・消費税（GST/HST）を組み込んだ経済シミュレーション
- 「日本らしさ」と「北米適応性」のバランス設計（例：抹茶ラテとメープルシロップの融合メニュー）
- 本レポートは日本市場分析としては優れているが、カナダ進出には最低30%のパラメータ調整が必要。特に「禁煙戦略」と「音楽選好」の地域適応が成否を分ける。

QEU:FOUNDER ： “う～ん・・・。我々には絶対に出てこないアイデアですね。”

D先生： “このアイデア群を、CA国のコーヒーショップの設計に生かすとどのようになるのかが気になりますね。ノードを追加するんですよね？”

![imageSWC2-23-6](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-6.jpg) 

QEU:FOUNDER ： “次回に続く。次回は、ちょっと楽にやりますよ。”


## ～ まとめ ～

QEU:FOUNDER ： “あくまで個人的な意見ですが、そうとも思いません。別に、昔の精神論的な管理手法が品質や生産性を押し上げる時代でもないですから・・・。科学技術が進めば、**どこで作っても同じレベルになる**のではないでしょうか。むしろ、**国によって「搾取の構造」が異なる**ので、そこらへんが最終的に影響するとおもいます。”

[![MOVIE1](http://img.youtube.com/vi/9YtHJjmvN6w/0.jpg)](http://www.youtube.com/watch?v=9YtHJjmvN6w "宮台真司氏、白井聡氏出演！古谷経衡チャンネルSP「2024年 年末床屋政談」")

C部長： “どういうこと？”

![imageSWC2-23-7](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-7.jpg) 

QEU:FOUNDER ： “品質低下じゃなくて、売れるモノを作る力がなくなる。だから、皆がお上に寄り掛かる。それにしても、**このタイプの搾取（↑）はありえん**わな・・・。ちなみに、ここの主語は変わる可能性があります（笑）。”

C部長 : “どういう意味？”

![imageSWC2-23-8](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-8.jpg) 

QEU:FOUNDER ： “なりふり構っていないから、その主語（↑）は自由自在にかわるんですよ。”

![imageSWC2-23-9](/2025-05-05-QEUR23_SIWC23/imageSWC2-23-9.jpg) 

QEU:FOUNDER ： “スケープゴートにも、なりふり構っていない。”

C部長 : “ふ～ん、**真実**ねえ・・・。”

[![MOVIE2](http://img.youtube.com/vi/e8JqePhcRn4/0.jpg)](http://www.youtube.com/watch?v=e8JqePhcRn4 "【隠された真実】が大好きな立花孝志信者は、漏れなくバカであることを解説")

QEU:FOUNDER ： “すまん。小生は真実には興味がないんです。”
