---
title: QEUR23_SIWC13 - TAGUCHI用データベースを操作したい(右側DB書き込み)
date: 2025-04-19
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_SIWC13 - TAGUCHI用データベースを操作したい(右側DB書き込み)

## ～ DeepSeekは、やはりすごかった・・・ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER （設定年齢65歳）： “Alibaba_cloudのLLMに改造を依頼すると、一発で完了です！驚いたことに、まったくエラーがでませんでした。超優秀なLLMですよ、Qwen-plusって・・・。”

![imageSWC2-13-1](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-1.jpg) 

D先生（設定年齢65歳）： “今回、やっとマイルストーンに来ました。次への「たたき台」が出来たわけです。 “

![imageSWC2-13-2](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-2.jpg) 

QEU:FOUNDER ： “つぎは、いよいよ本実験に入りましょう。もちろん、今後も、かなり多くのプログラム変更が入ってきます。今回もLLMサービスのお世話になります。”

![imageSWC2-13-3](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-3.jpg) 

QEU:FOUNDER  ： “いやあ・・・。**DEEPSEEKはいいわあ**・・・。”

D先生 ： “おっさん・・・。さっきまで、「Qwen-plusがいい」って、力説していたじゃないですか。すぐ態度を変えちゃって・・・。”

QEU:FOUNDER  ： “テーマ次第なのかな・・・。Qwenを使っていたら、途中で「にっちもさっちもいかない」状態になっちゃった・・・（笑）。そこで、Deepseekでやってみた所、素直にコードを改造できるようになった。結局のところ、**複数のツールを持っていなければいけない**ようですね。じゃあ、プログラムをドン！！”

```python
##############################
# 出力変換用（DB入力を含む）
##############################
# ---
import pandas as pd
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
import os
import sqlite3
from typing import List, Dict

# 設定クラスの拡張
class AppSettings:
    def __init__(
        self,
        db_name='sample_2nd.db',
        table_name='experiment_no1',
        input_file='testB.xlsx',
        signal_factor=2,
        error_factor=2,
        m_values=None,
        n_values=None
    ):
        self.db_name = db_name
        self.table_name = table_name
        self.input_file = input_file
        self.signal_factor = signal_factor
        self.error_factor = error_factor
        self.m_values = m_values or {"M1": 50, "M2": 100}
        self.n_values = n_values or {"N1": -0.01, "N2": 0.01}

# Pydanticモデルで出力構造を定義
class ProcessedOutput(BaseModel):
    records: List[Dict] = Field(description="実験結果のレコードリスト")
    m_values: Dict[str, int] = Field(description="信号因子Mの数値マッピング")
    signal_factor_count: int = Field(description="信号因子の数")
    error_factor_count: int = Field(description="誤差因子の数")

# ExcelデータをMarkdown形式に変換する関数
def excel_to_markdown(file_path):
    df = pd.read_excel(file_path, header=None)
    num_rows, num_cols = df.shape

    # 列ラベル（因子M）と行ラベル（NO/因子N）を生成
    factor_m_labels = []
    factor_n_labels = []
    for i in range(1, (num_cols - 1) // 2 + 1):
        factor_m_labels.extend([f"M{i}", f"M{i}"])
        factor_n_labels.extend(["N1", "N2"])

    # Markdown 表のヘッダーを作成
    header = "| 因子M | " + " | ".join(factor_m_labels) + " |"
    subheader = "| --- | " + " | ".join(["---"] * len(factor_m_labels)) + " |"
    no_factor_n_header = "| NO/因子N | " + " | ".join(factor_n_labels) + " |"

    markdown_table = [header, subheader, no_factor_n_header, subheader]
    for i in range(2, num_rows):
        row_data = df.iloc[i, 1:].tolist()
        row_str = "| {} |".format(int(df.iloc[i, 0])) + " | ".join(map(str, row_data)) + " |"
        markdown_table.append(row_str)

    return "\n".join(markdown_table)

# Structured Outputを活用したデータ変換関数の修正
def transform_data_with_structured_output(prompt_template, input_prompt):
    llm = ChatOpenAI(
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
        model="qwen-plus",
        temperature=0
    )

    parser = PydanticOutputParser(pydantic_object=ProcessedOutput)
    
    prompt = PromptTemplate(
        template=prompt_template + "\n{format_instructions}",
        input_variables=["input_data"],
        partial_variables={
            "format_instructions": parser.get_format_instructions()
        }
    )

    # 新しいチェーン構築方法
    chain = prompt | llm | parser  # RunnableSequenceを使用
    
    try:
        # 新しい実行方法
        parsed = chain.invoke({"input_data": input_prompt})
        return parsed
    except Exception as e:
        print(f"Error during processing: {e}")
        return None

# 出力フォーマット関数の改良
def format_output(settings: AppSettings, processed_data: ProcessedOutput):
    output_template = """
### 入力EXCELシート： {file_name}
### Sqlite DBファイル名 : {db_name}
### DBテーブル名 : {table_name}
### 信号因子数 ： {signal_count}
### 信号因子水準 M： {m_values}
### 誤差因子数 ： {error_count}
### 同一実験NOの実験数 ： {experiment_count}
### 誤差因子水準 N： {n_values} 単位：mm
### 表： 実験結果(変換後)
| 実験NO | 因子M(数値) | 因子N（水準） | 出力（数値） |
| --- | --- | --- | --- | 
{output_data}
"""

    formatted = []
    current_no = None
    
    for record in processed_data.records:
        if current_no and current_no != record['experiment_no']:
            formatted.append("| --- | --- | --- | --- |")
        formatted.append(
            f"| {record['experiment_no']} | {record['m_value']} | {record['n_level']} | {record['output']} |"
        )
        current_no = record['experiment_no']

    return output_template.format(
        file_name=settings.input_file,
        db_name=settings.db_name,
        table_name=settings.table_name,
        signal_count=processed_data.signal_factor_count,
        error_count=processed_data.error_factor_count,
        experiment_count=processed_data.signal_factor_count * processed_data.error_factor_count,
        m_values=", ".join(f"{k}={v}N" for k,v in processed_data.m_values.items()),
        n_values=f"強制変位（{', '.join(f'{k}={v}' for k,v in settings.n_values.items())})",
        output_data="\n".join(formatted)
    )

# SQLiteデータベース操作関数の改良
def save_to_database(settings: AppSettings, processed_data, final_output):
    conn = sqlite3.connect(settings.db_name)
    cursor = conn.cursor()
    
    create_table_sql = f"""
    CREATE TABLE IF NOT EXISTS {settings.table_name} (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        project TEXT,
        expno INTEGER,
        signal REAL,
        error TEXT,
        result REAL,
        description TEXT
    )
    """
    cursor.execute(create_table_sql)
    
    insert_sql = f"""
    INSERT INTO {settings.table_name} (project, expno, signal, error, result, description)
    VALUES (?, ?, ?, ?, ?, ?)
    """
    
    for record in processed_data.records:
        params = (
            settings.input_file,
            record['experiment_no'],
            record['m_value'],
            record['n_level'],
            record['output'],
            final_output.strip()
        )
        cursor.execute(insert_sql, params)
    
    conn.commit()
    conn.close()

# プロンプトテンプレートの改良
structured_prompt_template = """
入力データを解析し、以下の要件に従って構造化データを生成してください：

1. 実験データを個別レコードに分解
2. 信号因子Mの数値マッピング
3. 信号因子数と誤差因子数を入力から抽出

入力データ:
{input_data}

出力形式:
- JSON形式で以下を含む:
{{
  "records": [
    {{
      "experiment_no": 実験番号,
      "m_label": 因子Mラベル,
      "m_value": 数値,
      "n_level": 因子N水準,
      "output": 出力値
    }}
  ],
  "m_values": {{"M1": 数値}},
  "signal_factor_count": 信号因子数,
  "error_factor_count": 誤差因子数
}}
"""

```

D先生： “いやあ、これは複雑なプログラムだなあ。これは、我々では絶対に作れないや・・・。簡単なEXCELファイルを入力するだけで、あとはAIが処理をしてくれるんだから・・・。”

![imageSWC2-13-4](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-4.jpg) 

QEU:FOUNDER ： “LLMにコードを作らせる。今はやりの言葉で**「Vibe Coding」**っていうんだっけ・・・。今後はプログラミングの主流になるって確信しました。さて、コードは続きます。”

```python
# メイン処理の改良
def main_process(settings: AppSettings):
    print("\n=== 処理開始 ===")

    # ExcelからMarkdown変換
    markdown_data = excel_to_markdown(settings.input_file)

    # 入力プロンプトの動的生成
    input_prompt = f"""
### 入力EXCELシート： {settings.input_file}
### Sqlite DBファイル名 : {settings.db_name}
### DBテーブル名 : {settings.table_name}
### 信号因子数 ： {settings.signal_factor}
### 信号因子 M： 入力（{', '.join(f'{k}={v}' for k,v in settings.m_values.items())}）単位: N
### 誤差因子数 ： {settings.error_factor}
### 誤差因子 N： 強制変位（{', '.join(f'{k}={v}' for k,v in settings.n_values.items())}）単位：mm
### 表： 実験結果
{markdown_data}
"""

    print("=== 中間出力 ===")
    print(input_prompt.strip())

    # データ変換処理
    processed = transform_data_with_structured_output(structured_prompt_template, in-put_prompt)

    if processed:
        # 最終出力生成
        final = format_output(settings, processed)
        print("\n=== 最終出力 ===")
        print(final.strip())
        
        # データベース保存
        save_to_database(settings, processed, final)
    else:
        print("Processing failed")

    print("\n=== 処理完了 ===")

# 実行例
#if __name__ == "__main__":

# カスタム設定
custom_settings = AppSettings(
    db_name='taguchi13.db',
    table_name='experiments_13A',
    input_file='example13A.xlsx',
    signal_factor=2,
    error_factor=2,
    m_values={"M1": 50, "M2": 200},
    n_values={"N1": -0.01, "N2": 0.01}
)

# デフォルト設定で実行
# main_process(AppSettings())

# カスタム設定で実行
main_process(custom_settings)

```

D先生： “なるほど・・・。ユーザーの手間を省くために、データベース処理のユーザー設定を集中させたわけなんですね。”

QEU:FOUNDER ： “ちなみに、ここまで来るのに何回かLLMを動かしました。小生の指示を曲解することも多く、何回かの修正は不可避ですね。1回でできる、完全なプロンプトを作りようがないから・・・。”

D先生： “プロンプト・エンジニアリング次第なのかな？Reasoningモデルでは、モデルの学習データ次第になるかもしれません。どもあれ、LLMで処理した結果をみてみましょう。”

![imageSWC2-13-5](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-5.jpg) 

QEU:FOUNDER ： “まずは中間処理の自動化の結果です。入力したエクセルファイルの表データの内容を解析して、表フォーマットを別のタイプに変換したんです。この表型式の方が、次ステップの感度とSN比の計算に有利になります。”

D先生 ： “この表形式がレコードとなって、順次DBに入力されていますか？”

![imageSWC2-13-6](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-6.jpg) 

QEU:FOUNDER ： “もちろん！プログラム完了後に、簡単な別プログラムで、生成したDBファイルの内部を見てみました。ほら、ちゃんとデータが入っていますね。”

D先生： “そういえば、「Description」というコラムに文字列が入っていますね。どんな情報があるんですか？”

QEU:FOUNDER ： “中間処理の表示結果の文字列を入れています。ちなみに、そこまで大量のテキストを入れる必要はないですね。本当は、表データを削除したほうがいいと思います。”

![imageSWC2-13-7](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-7.jpg) 

D先生 ： “次は、**感度とSN比の計算**ですね。さらに、今回は表形式での入力なので連続して計算する必要があります。単純な「LLMによる一括処理」では不可能です。”

QEU:FOUNDER ： “別のテーブルを立ち上げる必要があります。何はともあれ、次回もかなり複雑なvibe codingになります。”


## ～ まとめ ～

C部長 : “例の件、盛り上がっています。悪い意味で・・・。”

![imageSWC2-13-8](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-8.jpg) 

QEU:FOUNDER ： “まあ、半年もすれば、何らかの形に落ち着くんじゃないですかね。それでも、この件（↓）は痛い！！これは後を引きますよ・・・。”

![imageSWC2-13-9](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-9.jpg) 

C部長: “うへえ・・・。これは痛い！！”

![imageSWC2-13-10](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-10.jpg) 

QEU:FOUNDER ： “この件、小生も全然知らなかったわ…。小生も大ショックです！！少なくとも、3年以内には、少なくとも**アジア地域でのブランド価値は失墜する**だろうなあ・・・。”

![imageSWC2-13-11](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-11.jpg) 

C部長: “そんなことが？仮に、そうなるとするとF国に大打撃です。”

[![MOVIE1](http://img.youtube.com/vi/faAiufElXko/0.jpg)](http://www.youtube.com/watch?v=faAiufElXko "週末の西湖風景区は大変混雑し、ボートに乗るために並ぶ観光客の列が長すぎて、列の終わりが見えません。西湖のほとりにあるショッピングモール、杭州は楽しいですか？")

QEU:FOUNDER ： “これは、とある有名な地域の散歩動画（↑）です。この付近に、ブランド店がどれだけあるかを調べてみてください。”

![imageSWC2-13-12](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-12.jpg) 

D先生： “あ～あ・・・。これから、ここに住んでいる大金持ちの人たちは、大枚はたいて**「昔の名前で出ています的、自称ブランド品（笑）」を買わない**だろうなあ・・・（溜息）。・・・でも、ASEANの人たちは、まだそのような感覚は持たないのではないでしょうか？”

![imageSWC2-13-13](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-13.jpg) 

QEU:FOUNDER ： “ほう・・・。そう思うかい？ホラ（↑）・・・。”

C部長： “あらあら・・・。V国は、もうC国側についたのですか？”

![imageSWC2-13-14](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-14.jpg) 

QEU:FOUNDER ： “V国も主権国家だから、A国とも仲良くできるよ。しかし、ここまでの**「時間軸」を考慮**に入れれば、**ASEANは大幅に「C国側に寄った」**と言えます。まあ、それはいいとして、**J国は大いに困る**と思うよ。”

D先生： “J国が？困りごとが？”

![imageSWC2-13-15](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-15.jpg) 

QEU:FOUNDER  ： “J国にとって、**TWの取り扱いが大いに難しくなります**。もともと、J国が「例の島」に対して取っている姿勢は**矛盾に満ちた**ものだった。J国はC国を非難していたでしょ？もともとは、**「TWが領有権を主張していること」が根源**だって・・・。”

![imageSWC2-13-16](/2025-04-19-QEUR23_SIWC13/imageSWC2-13-16.jpg) 

D先生： “ゲッ・・・。こんな愚かなこと（↑）を・・・。”

QEU:FOUNDER  ： “この愚行は、後々、**大いにJ国を苦しめる**と思うよ。”
