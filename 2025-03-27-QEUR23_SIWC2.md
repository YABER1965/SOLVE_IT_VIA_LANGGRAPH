## QEUR23_ SIWC2 - FIREWORKS_AIを使ってマルチエージェントを構築する

## ～ 前回よりも圧倒的に高性能、簡単！！ ～


### ・・・ 前回のつづきです ・・・


D先生（設定年齢65歳）： “グラフの定義に基づき、連続して種々のLLMエージェントを動かす、このタイプのシステムにはAPIサービスを使うしかないんでしょうね。ただし、どのようなAPIサービスでも良いとも思えません。いつものようにCohereを使いますか？”



      (imageSWC1-3-1)



QEU:FOUNDER（設定年齢65歳） ： “Cohereは、モデルのバリエーションが少ないし、ファインチューニングにも制約があります。ただし、あそこの強みはEmbeddingとRerankが強いところです。しかしながら、QwQ-32bモデルの事例を見ればわかるように、最近はプロプライエタリLLMとオープンLLMの実力差が小さくなってきているんです。オープンLLMにファインチューニングをして、あくまで自分用で使うのであれば、その差はごく僅かでしょう。”

D先生： “う～ん・・・。どのAPIがいいんだろう・・・。LangChainが、そのサービスをサポートしていないといけないし・・・。”



     (imageSWC1-3-2)


QEU:FOUNDER  ： “あれから、いろいろ調べました。その結論、**FIREWORK.AIはいいサービスだよ**。”



       (imageSWC1-3-3)



D先生： “おっと、この会社のBOARDING MEMBER（↑）は・・・。だから、**この会社はオープンLLMに強い**のか・・・。”

QEU:FOUNDER ： “その通りです。この会社の提供するモデルのほとんどがオープンLLMモデルです。小さいモデルから大きいパラメタまで、そのバラエティが圧倒的です。この会社が提供している、人気モデルの直近の動向を見てください。”



      (imageSWC1-3-4)



D先生： “へえ・・・。最近のトレンドは、こうなったのか・・・。DEEPSEEKとMANUSのリリース以降、人気モデルが大きく変わってきたんですね。これらのモデルがAPIを通じて手に入るのであれば、たいていのことはできるでしょうね。なるほど、あくまで自分用であれば、OPENAIやCohereの高価なモデルは、いらなそうですね。”

QEU:FOUNDER ： “さて、ここでプログラムをドン！！前回と、ほとんど同じコードです。**Fireworks用に推論部分が変わりました**。あと、せっかくだから、一般質問用とコード出力用でLLMモデルを変えました。”




```python

# ---
# Creating agents
from langchain import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_fireworks import ChatFireworks

# Creating the first analysis agent to check the prompt structure
def analyze_question(state):
    llm = ChatFireworks(model="accounts/fireworks/models/llama-v3p3-70b-instruct", tempera-ture=0.3)
    prompt = PromptTemplate.from_template("""
    You are an agent that needs to define if a question is a technical code one or a general one.

    Question : {input}

    Analyse the question. Only answer with "code" if the question is about technical development. If not just answer "general".

    Your answer (code or general ONLY!!) :
    """)
    chain = prompt | llm
    response = chain.invoke({"input": state["input"]})
    decision = response.content.strip().lower()
    return {"decision": decision, "input": state["input"]}

# Creating the code agent that could be way more technical
def answer_code_question(state):
    llm = ChatFireworks(model="accounts/fireworks/models/qwen2p5-coder-32b-instruct", tempera-ture=0.3)
    prompt = PromptTemplate.from_template(
        "You are a software engineer. Answer this question with step by steps details : {input}"
    )
    chain = prompt | llm
    response = chain.invoke({"input": state["input"]})
    return {"output": response}

# Creating the generic agent
def answer_generic_question(state):
    llm = ChatFireworks(model="accounts/fireworks/models/llama-v3p3-70b-instruct", tempera-ture=0.3)
    prompt = PromptTemplate.from_template(
        "Give a general and concise answer to the question: {input}"
    )
    chain = prompt | llm
    response = chain.invoke({"input": state["input"]})
    return {"output": response}

# Building the Graph
from langgraph.graph import StateGraph, END
from typing import Annotated, TypedDict

class AgentState(TypedDict):
    input: str
    output: str
    decision: str

def create_graph():
    workflow = StateGraph(AgentState)

    workflow.add_node("analyze", analyze_question)
    workflow.add_node("code_agent", answer_code_question)
    workflow.add_node("generic_agent", answer_generic_question)

    workflow.add_conditional_edges(
        "analyze",
        lambda x: x["decision"],
        {
            "code": "code_agent",
            "general": "generic_agent"
        }
    )

    workflow.set_entry_point("analyze")
    workflow.add_edge("code_agent", END)
    workflow.add_edge("generic_agent", END)

    return workflow.compile()


# ---
# Launching the Program
from langgraph.graph import StateGraph, END

class UserInput(TypedDict):
    input: str
    continue_conversation: bool

def get_user_input(state: UserInput) -> UserInput:
    user_input = input("\nEnter your question (or 'q' to quit) : ")
    return {
        "input": user_input,
        "continue_conversation": user_input.lower() != 'q'
    }

def process_question(state: UserInput):

	###
	# 途中はすべて省略します。
	###

    workflow.add_edge("process_question", "get_input")

    return workflow.compile()


# ---
# Inference
from IPython.display import Markdown, display

# ---
conversation_graph = create_conversation_graph()

response = conversation_graph.invoke({"input": "", "continue_conversation": True})
display(Markdown(f"<b>\n--- conversation_graph_answer ---</b>"))
display(Markdown(f"<b>{response.content}</b>"))

```


QEU:FOUNDER ： “さて、ここで一般質問をやってみましょう。”



     (imageSWC1-3-5)



QEU:FOUNDER ： “さすがに、32bモデルだけあってちゃんとJ語で返答してくれています。”

D先生： “出力のフォーマットは、CohereやAIを使った場合と同じですね。LangChainがプロトコルを調整してくれたのかな・・・。”

QEU:FOUNDER ： “そうです。そのために、LangChainでサポートされていることが絶対条件だったんです。それでは、次に、コードの出力をやってみましょう。ここでは、出力にMARKDOWN処理がなされて、より見やすくなっています。”


    (imageSWC1-3-6)


D先生： “さすがの、コード用LLMらしい出力結果で納得です。このマルチエージェントは、実用でも使えますね。”

QEU:FOUNDER  ： “最近、LangMANUSというフリーのシステムが提案されているのを知っている？”



      (imageSWC1-3-7)


D先生： “もうできたんですか？それにしても変なタイトルです。いったい、なんですか？「（J語はありがたい）」って・・・。”

QEU:FOUNDER  ： “このプロジェクトの開発の経緯は分からないが、結果としてREADMEには、**E語、C語に並んでJ語タグが配置されている**んです。ありがたいと思わん？いまどき、奇特な・・・。”



      (imageSWC1-3-8)



D先生： “この、ヨボヨボのJ国爺さんにリスペクトしてくれるんだ。ありがたや・・・。ここで、Qwenを標準モデルと設定しているということは、C国の若者が主体の開発プロジェクトのようです。MANUSの開発コミュニティがオープン版を作ったのであれば、このリリースの速さは納得できます。それにしても、ここではWeb検索エンジンとしてTavilyが提案されています。我々が、今後、Cohereの代わりにオープンLLMを使うのであれば、Web検索エンジンが必要になります。”


QEU:FOUNDER  ： “これから、ゆっくりと検討していきましょう。今後、BONSAI4も大幅に形を変えてBONSAI5になっていくかもしれないし・・・。”



## ～ まとめ ～

### ・・・ 前回のつづきです ・・・


QEU:FOUNDER ： “あの地方って「クセがある」んですよね。なんで、自分の商売の成功を一般化して、「哲学」にしようとするのか・・・。それも、「1社だけじゃない」んだよねえ・・・。どうして、あんなに多くの会社が「同じ傾向」をもつのか？”



       (imageSWC1-3-9)



C部長 : “これが地域文化なのでしょうね。しかし、**「勤勉、倹約、正直」を貴ぶ道徳教が、どうして近年になって、新自由主義とか搾取の正当化に移行してしまう**のか・・・。”


        (imageSWC1-3-10)


QEU:FOUNDER ： “通俗道徳って、ヤバいんですよね。もちろん、社会が安定していると、通俗道徳は社会に対してプラスに作用するのだが・・・。”



      (imageSWC1-3-11)



QEU:FOUNDER ： “人間の知識体系とか、行動規範は上記のような感じになっていると思うんです。ちなみに、これは小生の考え方ですよ。念のため・・・。この階層の上下というのは、ロジック（演繹）における前提が上になるという意味です。さて、この図の「？」に注目してください。あの地方では、「？」はなにかな？”


C部長 : “通俗道徳ですね。戦後の一時期に商売がうまく行ったのを慢心し、その時の考え方を「～哲学」とか「～WAY」とかに祭り上げていって、それを社会、強いては政治にまで押し付ける。たとえ、その後、世界が変わり社会が変わっても、**これが「哲学」であるかぎり、それは変わらず、その地域には存在し、人々を束縛しつづけます。**”



      (imageSWC1-3-12)



QEU:FOUNDER ： “悪いことに、それに対して、メディア（↑）も一枚乗っかると・・・。あの・・・、小生ね・・・。最近、この投稿（↓）を見て思ったんです。**「犬笛って、追い出し部屋のことか？」**って・・・。”


     (imageSWC1-3-13)


C部長 : “ぞっとしますね。ある種の会社の中で行われる「（優秀な）管理のスタイル」を、そのまま社会に展開すると「犬笛」になるんです。”


     (imageSWC1-3-14)





QEU:FOUNDER ： “このドラマ（↑）に「追い出し部屋」のシーンがあったでしょ？悪夢の平成時代でも、後半になると、さすがに「まずい・・・。」って、メディアも思ったんでしょうね。C国の若者はOpen-MUNUSを提案し、もう一方のJ国は犬笛に踊り狂う。”


movie1


QEU:FOUNDER ： “もう、手遅れだけど・・・。”





```python

```
