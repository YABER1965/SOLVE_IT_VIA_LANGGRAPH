---
title: QEUR23_SIWC20 – LangGraphを使って、複数のLLMに自問自答をさせる
date: 2025-04-28
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_SIWC20 – LangGraphを使って、複数のLLMに自問自答をさせる

## ～ 少しだか、長めの「寄り道」をしましょう ～

### ・・・ 前回のつづきです ・・・

D先生（設定年齢65歳）： “我々はすでに「Solve it with code!(Vibe Coding)」という目標を達成しました。さて、お次は、どうします？もとのBONSAI4に戻りますか？”

![imageSWC2-20-1](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-1.jpg) 

QEU:FOUNDER（設定年齢65歳） ： “このシリーズは、すでに終わりではあるのだが・・・。ちょっとだけ時間を使って、Mathモデルのファイン・チューニングをやってみたいんです。できればGRPOで・・・。”

![imageSWC2-20-2](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-2.jpg) 

QEU:FOUNDER ： “Mathモデルとは何なのかを知りたい。一体、何ができるのかを知りたい。気になるんですよ。アレ・・・。とてもヘンテコなものなので・・・。”

D先生： “たしか、MathモデルってE語とC語にしか対応しないんでしょ？さらに、対応する領域がMathに限定しています。それって、すごく守備範囲が狭いです。一体、その大きなパラメタを何に使っているのやら・・・（笑）。”

### ・・・ さて、あれから時間が過ぎ ・・・

QEU:FOUNDER ： “さて、例の「Mathモデルの件」をやってみました。ちょっと、これから違うことをやります。”

D先生： “おっ！Mathモデルの実験をやってみたんですか？”

QEU:FOUNDER ： “まあ・・・。でも、あまりにも見事な失敗なので、くわしく説明しません。ちなみに、やってみたのは推論だけです。そして、その推論の結果を見たら、これ以上手間を掛けて学習をする気も起きなかったです。”

D先生： “もうちょっと、知りたい・・・。”

![imageSWC2-20-3](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-3.jpg) 

QEU:FOUNDER ： “小生の言っている意味は、後でわかります。さて、例によって、小生お気に入りのDEEPSEEKでVIBE CODINGをやってみましょう。今回は、プロンプトではなくコードの晒しです。”

```python
# ----
import os
from typing import Annotated, TypedDict
from openai import OpenAI
from fireworks.client import Fireworks
from langgraph.graph import END, StateGraph

clientFW = Fireworks()

class AgentState(TypedDict):
    input_japanese: str
    translated_english: Annotated[str, "translated"]
    math_solution: Annotated[str, "solution"]
    verification_result: Annotated[str, "verification"]
    calculation_check: Annotated[str, "calculation_check"]

def translate_japanese_to_english(state: AgentState):
    japanese_question = state["input_japanese"]
    
    response = clientFW.chat.completions.create(
        model="accounts/fireworks/models/qwen2p5-72b-instruct",
        messages=[{
            "role": "user",
            "content": f"""Convert this Japanese text to precise English maintaining ALL numerical val-ues, 
            table structures, and technical terms. Return ONLY the translated content without commen-tary.
            
            {japanese_question}"""
        }],
        temperature=0
    )
    
    return {"translated_english": response.choices[0].message.content}

# ---
clientQW = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
)

def solve_math_problem(state: AgentState):
    english_question = state["translated_english"]

    response = clientQW.chat.completions.create(

        # accounts/fireworks/models/qwen2p5-math-72b-instruct
        model="qwen-max-2025-01-25",
        messages=[{
            "role": "user",
            "content": f"""Analyze the provided experimental data to optimize target metrics:
            
            {english_question}
            
            You can use regression analysis or analysis of variance (ANOVA) of quantification type I to perform the optimization. Before the analysis, compare regression analysis and ANOVA is more ad-vantageous and make a choice. Provide a mathematical definition of the analysis method you have chosen. Show the calculation steps along the way. Use a table to summarize the results.
            Please analyze step by step and provide calculation process in detail."""
        }],
        temperature=0.1
    )
  
    return {"math_solution": response.choices[0].message.content}

# ---
clientDS = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com",
)

def verify_solution(state: AgentState):
    verification_prompt = f"""
    [Problem Context]
    {state['translated_english']}
    
    [Proposed Solution]
    {state['math_solution']}
    
    You should rank each statement, formula , and operation required in the proposed solution as Good, Acceptable, or Poor. Then, you should explain its reason afterwards. In addition, you should calculate again to check all of the arithmetic operations in the entire spreadsheet.
    
    - Good: This is the best possible method.
    - Acceptable: Not the best method, but the results are not negatively affected.
    - Poor: It has a negative impact on the final result and needs to be improved.
    """
    
    response = clientDS.chat.completions.create(
        model="deepseek-chat",
        messages=[{
            "role": "user",
            "content": verification_prompt
        }],
        temperature=0.1
    )
    
    return {"verification_result": response.choices[0].message.content}

workflow = StateGraph(AgentState)
workflow.add_node("translator", translate_japanese_to_english)
workflow.add_node("solver", solve_math_problem)
workflow.add_node("verifier", verify_solution)

workflow.set_entry_point("translator")
workflow.add_edge("translator", "solver")
workflow.add_edge("solver", "verifier")
workflow.add_edge("verifier", END)

agent = workflow.compile()

# ---
from IPython.display import Image, display

try:
    display(Image(app.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass
	
```

QEU:FOUNDER ： “たまたまMERMAIDサーバーが動いたので、グラフを描くことが出来ました。”

![imageSWC2-20-4](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-4.jpg) 

D先生： “ほう、変な処理フローだな・・・。なんで、「翻訳(translator)」が必要・・・？それにしても、すべてのノードで違うLLMモデルを使ったんですね。”

QEU:FOUNDER ： “さて、最初のノードのプロンプトに注目してください。”


**(プロンプト: translator)**

Convert this Japanese text to precise English maintaining ALL numerical values, table structures, and technical terms. Return ONLY the translated content without commentary.

この日本語テキストを、数値、表構造、専門用語をすべて維持した正確な英語に変換してください。コメントは付けず、翻訳された内容のみを返送してください。

D先生： “J語のまま質問したら、だめなんですか？”

![imageSWC2-20-5](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-5.jpg) 

QEU:FOUNDER  ： “Mathモデルは、E語とC語のプロンプトにしか対応していないといったでしょ？その理由は、この2つの言語のコーパスの論文の量と質が、他言語に圧倒しているからなんです。だから、Mathモデルにプロンプトを入力するときには、「E語かC語か」を選択しなければならない。”

D先生： “いま、Mathモデルを使っていないじゃないですか・・・。”

QEU:FOUNDER ： “もともと、こういう設計思想だったの！このプログラムは・・・。その後、実際にMathモデルを使って推論したら、結果がバタバタだったの・・・。そして、小生は悟りました。たかが70b程度のNON-REASONINGモデルって、この程度なんだったって・・・（笑）。そこで、対策としてソルバ(SOLVER)のLLMをQWEN-MAXに選択しました。これはREASONINGモデルなんです。それでは、プログラムをつづきをみてみましょう。”

```python
# ---
def run_agent(question_ja: str):
    result = agent.invoke({"input_japanese": question_ja})
    return {
        "translated_question": result["translated_english"],
        "solution": result["math_solution"],
        "verification": result["verification_result"],
    }

# ----
japanese_question = """
以下のような実験をしました。この実験データに基づいて、応答変数の量を最大とする従属変数の水準と満足度の予測値を教えてください。
また、その予測に使ったロジックをステップバイステップで記述してください。
```
## プロジェクト名 : おいしいご飯を炊く方法を研究する

## 使用した米 : 日本のジャポニカ米

## 評価した人 : 20歳～50歳の日本人（男女10人）

## 評価方法 : アンケート（最低1～最高10）

## プロジェクトの目的 : 応答変数の量(平均値)を最大とする従属変数の水準を選択する

## 応答変数(Y)

- Y : 満足度

## 従属変数（X）

- X1 : 米の量 
- X2 : 水の量 
- X3 : 追加するもの 

## 実験データ

|   NO | 米の量   | 水の量            | 追加するもの   |   満足度の平均値 |
|-----:|:---------|:------------------|:---------------|---------:|
|    1 | 3カップ      | 目盛より2㎜少なめ | 追加しない     |     8.75 |
|    2 | 3カップ      | 目盛より3㎜少なめ | 昆布           |     7.25 |
|    3 | 3カップ      | 目盛より4㎜少なめ | 昆布           |     7.25 |
|    4 | 3カップ      | 目盛より2㎜少なめ | 炭         |     7.5  |
|    5 | 3カップ      | 目盛より3㎜少なめ | 炭         |     7.75 |
|    6 | 3カップ      | 目盛どおり        | 追加しない     |     7.25 |
|    7 | 3カップ      | 目盛どおり        | 昆布           |     7.0    |
|    8 | 3カップ      | 目盛より2㎜少なめ | 昆布           |     8.25 |
|    9 | 3カップ      | 目盛より3㎜少なめ | 炭         |     8.75 |
|   10 | 3カップ      | 目盛より4㎜少なめ | 追加しない     |     7.25 |
|   11 | 3カップ      | 目盛より2㎜少なめ | 追加しない     |     8.0    |
|   12 | 5カップ      | 目盛より1㎜少なめ | 炭         |    9.0    |
|   13 | 3カップ      | 目盛より1㎜少なめ | 炭         |    9.0    |
|   14 | 4カップ      | 目盛より1㎜少なめ | 炭         |     8.75 |
|   15 | 4カップ      | 目盛より2㎜少なめ | 炭         |     8.75 |
|   16 | 5カップ      | 目盛より1㎜少なめ | 炭         |     7.75 |
|   17 | 4カップ      | 目盛より1㎜少なめ | 昆布と炭   |     8.75 |
|   18 | 3カップ      | 目盛どおり        | 昆布と炭   |    9.0    |
|   19 | 3カップ      | 目盛より1㎜少なめ | 追加しない     |     8.5  |
|   20 | 3カップ      | 目盛どおり        | 昆布           |     8.5  |
|   21 | 3カップ      | 目盛どおり        | 追加しない     |     8.0    |
```
"""

result = run_agent(japanese_question)

from IPython.display import Markdown

print("\n======== Translated Problem ========")
Markdown(result["translated_question"])


print("\n======== Mathematical Analysis ========")
Markdown(result["solution"])

```

QEU:FOUNDER ： “プロンプトの翻訳結果の確認は、つまらないので省略します。次のステップのソルバの推論を見てみましょう。”

![imageSWC2-20-6](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-6.jpg) 

QEU:FOUNDER ： “もっと内容を詳しく見てみましょう。”

======== Mathematical Analysis ========

** Step 1: Understanding the Problem and Choosing the Analysis Method **

The goal of this experiment is to determine the levels of the dependent variables 
( 𝑋1  : Amount of Rice,  𝑋2 : Amount of Water,  𝑋3 : Additional Ingredients) that maximize the re-sponse variable ( 𝑌 : Satisfaction). To achieve this, we need to analyze the relationship between the dependent variables and the response variable.

*** Comparison of Regression Analysis and ANOVA ***

Regression Analysis: This method models the relationship between the dependent variables and the response variable using a mathematical equation. It allows us to quantify the effect of each inde-pendent variable on the response variable and predict satisfaction values for specific combinations of factors.

ANOVA (Analysis of Variance): This method compares the means of different groups to determine whether there are statistically significant differences in the response variable across levels of the in-dependent variables. While ANOVA can identify which factors significantly affect satisfaction, it does not provide a predictive model or quantify the magnitude of effects.

回帰分析：この手法は、従属変数と応答変数の関係を数式を用いてモデル化します。これにより、各独立変数が応答変数に与える影響を定量化し、特定の要因の組み合わせにおける満足度を予測することができます。

分散分析（ANOVA）：この手法は、異なるグループの平均を比較し、独立変数の水準間で応答変数に統計的に有意な差があるかどうかを判断します。分散分析は満足度に有意な影響を与える要因を特定できますが、予測モデルを提供したり、効果の大きさを定量化したりすることはできません。

*** Choice: Regression analysis is more advantageous here because: ***

It provides a predictive model that can estimate satisfaction for any combination of factors.
It quantifies the contribution of each factor to satisfaction, enabling optimization.

あらゆる要素の組み合わせに対して満足度を推定できる予測モデルを提供します。各要素が満足度に及ぼす影響を定量化し、最適化を可能にします。


** Step 2: Mathematical Definition of Regression Analysis **

We will use multiple linear regression to model the relationship between the dependent variables ( 𝑋1 ,  𝑋2 ,  𝑋3 ) and the response variable ( 𝑌 ):

多重線形回帰を使用して、従属変数（𝑋1、𝑋2、𝑋3）と応答変数（𝑌）の関係をモデル化します。

### 𝑌 = 𝛽0+𝛽1𝑋1+𝛽2𝑋2+𝛽3𝑋3+𝜖
 
Where:

- 𝑌 : Satisfaction (response variable)
- 𝑋1 : Amount of Rice (categorical variable: 3 cups, 4 cups, 5 cups)
- 𝑋2 : Amount of Water (categorical variable: Mark level, 1 mm less, 2 mm less, etc.)
- 𝑋3 : Additional Ingredients (categorical variable: None, Kombu, Charcoal, Kombu and Charcoal)
- 𝛽0 : Intercept
- 𝛽1,𝛽2,𝛽3 : Coefficients representing the effect of each factor
- 𝜖 : Error term

Since  𝑋1 ,  𝑋2 , and  𝑋3  are categorical variables, we will encode them using dummy variables.

D先生： “そうか・・・。AIは、数量化Ⅰ類の回帰分析を選択しましたね。”

QEU:FOUNDER ： “AIは、本当に賢いですね。LLMは連続した算術計算が苦手なので、ANOVAは結果を不正確にすると思うんです。**回帰分析は、演算を「パッケージ化」できます**。”

** Step 3: Data Preparation and Encoding **

Encoding Categorical Variables

Amount of Rice ( 𝑋1 ):

Base level: 3 cups

Dummy variables:

- 𝑋1,1 : 1 if 4 cups, 0 otherwise
- 𝑋1,2 : 1 if 5 cups, 0 otherwise

Amount of Water ( 𝑋2 ):

Base level: Mark level

Dummy variables:

- 𝑋2,1 : 1 if 1 mm less, 0 otherwise
- 𝑋2,2 : 1 if 2 mm less, 0 otherwise
- 𝑋2,3 : 1 if 3 mm less, 0 otherwise
- 𝑋2,4 : 1 if 4 mm less, 0 otherwise

Additional Ingredients ( 𝑋3 ):

Base level: None

Dummy variables:

- 𝑋3,1 : 1 if Kombu, 0 otherwise
- 𝑋3,2 : 1 if Charcoal, 0 otherwise
- 𝑋3,3 : 1 if Kombu and Charcoal, 0 otherwise


Encoded Data Table

NO	𝑋1,1 𝑋1,2 𝑋2,1 𝑋2,2 𝑋2,3 𝑋2,4 𝑋3,1 𝑋3,2 𝑋3,3 𝑌
1	0	0	0	1	0	0	0	0	0	8.75
2	0	0	0	0	1	0	1	0	0	7.25
...	...	...	...	...	...	...	...	...	...	...


** Step 4: Regression Model Estimation **

Using the encoded data, we fit the regression model:

### 𝑌 = 𝛽0+𝛽1,1𝑋1,1+𝛽1,2𝑋1,2+𝛽2,1𝑋2,1+𝛽2,2𝑋2,2+𝛽2,3𝑋2,3+𝛽2,4𝑋2,4+𝛽3,1𝑋3,1+𝛽3,2𝑋3,2+𝛽3,3𝑋3,3+𝜖
 
Coefficient Estimation

Using statistical software or manual calculations (e.g., least squares estimation), we compute the co-efficients ( 𝛽0,𝛽1,1,…,𝛽3,3 ).

** Step 5: Optimization **

To maximize satisfaction ( 𝑌 ), we evaluate the predicted satisfaction for all possible combinations of  𝑋1 ,  𝑋2 , and  𝑋3 . The combination with the highest predicted  𝑌  is the optimal setting.

** Step 6: Results Summary **

*** Regression Coefficients ***

Variable	Coefficient ( 𝛽 )

- Intercept ( 𝛽0 )	8.00
- 𝑋1,1  (4 cups)	0.50
- 𝑋1,2  (5 cups)	0.75
- 𝑋2,1  (1 mm less)	0.25
- 𝑋2,2  (2 mm less)	0.50
- 𝑋2,3  (3 mm less)	-0.25
- 𝑋2,4  (4 mm less)	-0.50
- 𝑋3,1  (Kombu)	-0.25
- 𝑋3,2  (Charcoal)	0.50
- 𝑋3,3  (Kombu+Charcoal)	0.75

*** Optimal Combination ***

- Amount of Rice ( 𝑋1 ): 5 cups
- Amount of Water ( 𝑋2 ): 1 mm less than the mark
- Additional Ingredients ( 𝑋3 ): Kombu and Charcoal

*** Predicted Satisfaction Value ***

### 𝑌 = 8.00+0.75+0.25+0.75=9.75
 
** Final Answer **

### Optimal Settings: 5 cups of rice, 1 mm less water, Kombu and Charcoal; Predicted Satisfaction: 9.75

D先生： “良い予測が出てきました。「QWEN-MAXおそるべし・・・」としか言いようがないですね。次は、最適化の結果を評価しましょう。今回は、なぜか検証用のLLMとして「deepseek-chat」をつかっています。これは？”

QEU:FOUNDER ： “あの有名な強力推論モデルである「DEEPSEEK様」ではありません。これは、一世代前のものです。ちょっと評価用のプロンプトを、先にみてみましょう。”

verification_prompt:

[Problem Context]
{state['translated_english']}

[Proposed Solution]
{state['math_solution']}

You should rank each statement, formula , and operation required in the proposed solution as Good, Acceptable, or Poor. Then, you should explain its reason afterwards. In addition, you should calculate again to check all of the arithmetic operations in the entire spreadsheet.

提案された解決策に必要な各文、式、演算を「良い」「許容できる」「悪い」のいずれかで評価してください。その後、その理由を説明してください。さらに、スプレッドシート全体のすべての算術演算を再計算して確認する必要があります。

- Good: This is the best possible method.
良い: これは最善の方法です。
- Acceptable: Not the best method, but the results are not negatively affected.
許容可能: 最良の方法ではありませんが、結果に悪影響はありません。
- Poor: It has a negative impact on the final result and needs to be improved.
悪い: 最終結果に悪影響を与えるため、改善が必要です。

D先生： “3段階の**「評価レベル(Good, Acceptable, Poor)」を設定した**のが、今回の工夫ですね。”

![imageSWC2-20-7](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-7.jpg) 

QEU:FOUNDER ： “それでは、回答の内容を詳しく見てみましょう。”

======== Verification Report ========

### Evaluation of the Proposed Solution

** Step 1: Understanding the Problem and Choosing the Analysis Method **

Statement: "Regression analysis is more advantageous here because..."

*** Rating: Good ***

Reason: The explanation clearly justifies why regression analysis is superior to ANOVA for this prob-lem, focusing on prediction and optimization. The reasoning aligns with the goal of maximizing satis-faction.

** Step 2: Mathematical Definition of Regression Analysis **

Formula: ( Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \epsilon )

*** Rating: Acceptable ***

Reason: The formula is correct for multiple linear regression, but it does not account for the categor-ical nature of the variables (dummy encoding is introduced later). A more precise initial formulation would include dummy variables.

** Step 3: Data Preparation and Encoding **

Encoding Scheme: Dummy variables for categorical variables.

*** Rating: Good ***

Reason: The dummy encoding is correctly specified, and the base levels are appropriately chosen. This is essential for accurate regression analysis with categorical data.

** Step 4: Regression Model Estimation **

Statement: "Using the encoded data, we fit the regression model..."

*** Rating: Good ***

Reason: The description of fitting the regression model is correct. The step logically follows from the encoding and sets up the optimization problem.

理由: 回帰モデルのフィッティングの説明は正しいです。このステップはエンコードから論理的に導き出され、最適化問題を設定します。

** Step 5: Optimization **

Statement: "To maximize satisfaction (( Y )), we evaluate the predicted satisfaction for all possible combinations..."

*** Rating: Good ***

Reason: This is the correct approach for finding the optimal combination of factors. The exhaustive evaluation ensures the global maximum is found.

理由：これは、最適な要因の組み合わせを見つけるための正しいアプローチです。徹底的な評価により、全体的な最大値が確実に見つかります。

D先生： “なるほど、ここが今回の最適化法のポイントです。ソルバのLLMは、回帰分析で得た係数を全因子かつ全水準で「総当たり」評価を行い、Yの値が最高になる条件のセットを得るわけです。その考え方について、検証LLMは、その妥当性を認めているわけです。”

QEU:FOUNDER ： “しかし、ここから、LLMの回答がおかしくなります。”

** Step 6: Results Summary **

*** Regression Coefficients Table: ***

### Rating: Poor

Reason: The coefficients are not calculated from the provided data. For example, the intercept ((\beta_0 = 8.00)) is arbitrary and not derived from the actual data. This undermines the validity of the results.

*** Optimal Combination: ***

### Rating: Poor

Reason: The optimal combination is based on unverified coefficients. For instance, the data shows that "5 cups, 1 mm less, Charcoal" (NO 12) has a satisfaction of 9.00, while "3 cups, Mark level, Kombu and Charcoal" (NO 18) has 9.00. The claimed optimal combination (5 cups, 1 mm less, Kombu and Charcoal) does not appear in the data, and its predicted satisfaction (9.75) is unsupport-ed.

*** Predicted Satisfaction Value: ***

### Rating: Poor

Reason: The calculation ( Y = 8.00 + 0.75 + 0.25 + 0.75 = 9.75 ) is based on unverified coefficients and does not match any observed data point.

*** Recalculation and Verification ***

Actual Optimal Combination from Data
From the experimental data:

The highest observed satisfaction is 9.00 for:

- NO 12: 5 cups, 1 mm less, Charcoal
- NO 13: 3 cups, 1 mm less, Charcoal
- NO 18: 3 cups, Mark level, Kombu and Charcoal

No combination in the data achieves 9.75. The proposed solution's prediction is unrealistic.

Correct Regression Approach
To properly perform regression:

Encode the data as described.
Use software (e.g., Python, R) to fit the model and estimate coefficients.
Validate the model (e.g., R-squared, p-values).
Predict satisfaction for all combinations and select the maximum.

Correct Optimal Combination

Based on the data, the optimal combinations are:

- 5 cups, 1 mm less, Charcoal (9.00)
- 3 cups, 1 mm less, Charcoal (9.00)
- 3 cups, Mark level, Kombu and Charcoal (9.00)

No combination yields higher than 9.00 in the observed data.

** Final Evaluation **

### Overall Rating: Poor

Reason: The solution incorrectly calculates coefficients and predicts an unrealistic satisfaction value (9.75). The actual data does not support this claim. The correct approach would involve deriving co-efficients from the data and validating predictions.

*** Corrected Final Answer ***

The optimal settings from the experimental data are:

- 5 cups of rice, 1 mm less water, Charcoal (Satisfaction: 9.00)
- 3 cups of rice, 1 mm less water, Charcoal (Satisfaction: 9.00)
- 3 cups of rice, Mark level water, Kombu and Charcoal (Satisfaction: 9.00)

### No higher satisfaction is observed in the data. The predicted value of 9.75 is incorrect.

### Optimal Settings (Actual Data): 5 cups, 1 mm less, Charcoal; Satisfaction: 9.00

QEU:FOUNDER ： “D先生・・・、おもしろいでしょう？”

D先生： “検証用のLLMは**「deepseek-V3」**でしょう？結構、良さげなモデルのはずです。それでも、この程度の回答の質なのか・・・。”

QEU:FOUNDER ： “検証用・評価用LLMモデルは、**「回帰分析は内挿のための手法であり、最適化(外挿)には使えない」**と考えているようです。そこら辺の考え方が、少し薄いんですよ。やはり、REASONING機能がないと、そのような浅い考え方になるんでしょう。さて、今回の結果をまとめました。”

![imageSWC2-20-8](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-8.jpg) 

D先生： “おっと、わかりやすい「まとめ(summary)」です。この表によると、FOUNDERは、あとでソルバと検証LLMを入れ替えることも考えているんですね。”

QEU:FOUNDER ： “さらに、プロンプトに使う言語も変えてみます。この「2x2の評価マトリックス」で、どのような結果になるかが重要です。すべてのケースで「ALL-GOOD」であれば、その分析の結果は信頼できると考えられるでしょう？”

D先生： “要するに、**「投票法」を用いる**わけですね。この手のアンサンブル手法は、random-forest法などで頻繁に使われます。なるほどね・・・。さっきFOUNDERが言っていた、「現状のMathモデルは、今回の問題にはダメダメである」という意味は、よく分かりました。少なくとも200b以上のReasoningモデルでないとダメでしょうね。”


QEU:FOUNDER ： “さらに言うと、「Reasoningモデルでもファインチューニングができる！」と宣伝しているサービスがあります。しかし、Reasoningモデルのファインチューニングは、LLMベンダーがせっかく苦労して仕上げたバランスを崩す危険性もあるんですよ。・・・そうであるならば、投票法を使って精度を上げたほうが合理的だと思いませんか？”

D先生： “あとは、誰かさんが、近い将来、Pre-trainのLLMに関連したノウハウを注入してくれるのを待つしかありません・・・（笑）。”

QEU:FOUNDER ： “本件、もうちょっと別の事例を使ってやってみない？”

D先生： “Deepseek-reasonerでやってみるとどうなるか？言語を切り替えるとどうなるか？見どころは満載です。”

![imageSWC2-20-9](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-9.jpg) 

QEU:FOUNDER ： “今回の最大の収穫は、**「LLMを使った最適化では回帰分析の一択!!」**ということではないでしょうか。”


## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “今回の結論は、これ（↓）だネ・・・（笑）。”

![imageSWC2-20-10](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-10.jpg) 

C部長： “ここのメンツでは、ボクしか行くことができませんね。それにしても、「オフライン（ニュース、SNS）」上では退屈させませんね。このイベントは・・・。”

![imageSWC2-20-11](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-11.jpg) 

QEU:FOUNDER ： “さらに、最近、資金不足の問題もあるが・・・。やはり、J国の国技である「中抜き」が響いたんじゃないですか？”

[![MOVIE1](http://img.youtube.com/vi/RCAEkVK0NCU/0.jpg)](http://www.youtube.com/watch?v=RCAEkVK0NCU "「大阪万博で工事費未払い発生！ネパール館が建設停止。インド館は未だに完成せず。ハチャメチャ万博。」池亀彩・京都大学教授。安冨歩・東京大学名誉教授")

C部長 : “さあ・・・。でも、**国がそれで「かろうじて維持されてている」から**、しようがないでしょう。”

![imageSWC2-20-12](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-12.jpg) 

D先生 ： “この件ねえ・・・。J国の財務省も、いつも街頭デモなどで叩かれていますが、かわいそうに・・・。彼らは**金庫番としての責務を全うしているだけ**でしょうに・・・。むしろ問題は、「使う側」にあると思います。そういえば、このビック・イベントの事務局にも、**相当数の〇〇省の偉い人たちが天下り**しているとか・・・。”

![imageSWC2-20-13](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-13.jpg) 

QEU:FOUNDER ： “いやいや・・・。彼ら（↑）には、ムダがない！！彼らは、これから絶対にやってくれますよ。なにしろ、あの**高度成長（1950～70）のとき**に、やってくれた組織ですよ！！”

![imageSWC2-20-14](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-14.jpg) 

C部長 : “あの時は、やってくれたんですね。う～ん・・・。中央の問題ではなく、むしろ**地方の問題**じゃないですか？”

QEU:FOUNDER ： “地方とな！？失礼な！！昔は、あの地方は、「上方」と呼ばれたんですよ！上ですよ！上・・・！！”

![imageSWC2-20-15](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-15.jpg) 

D先生 : “最近は、中央からの抑圧に耐え兼ね。**独立の動き**もあるんでしょう？”

![imageSWC2-20-16](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-16.jpg) 

QEU:FOUNDER ： “我々は、ただ驚くしかない。”

![imageSWC2-20-17](/2025-04-28-QEUR23_SIWC20/imageSWC2-20-17.jpg) 

C部長 : “本当に・・・。”
