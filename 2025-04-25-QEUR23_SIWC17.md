---
title: QEUR23_SIWC17 - TAGUCHI用データベースを操作したい(左側DB書き込みNO1)
date: 2025-04-25
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_SIWC17 - TAGUCHI用データベースを操作したい(左側DB書き込みNO1)

## ～ 「総合SN比」をさらに語る！ ～

### ・・・ 最初に、閑話休題の補足から始めます ・・・

D先生（設定年齢65歳）： “うへえ・・・。これは**「知識爆発」**だ！！！”

QEU:FOUNDER （設定年齢65歳）： “・・・でしょう？たかが、「TOY SCHEME」であるとはいえ、この方法には**「何かがある」**と思うでしょう？さらに、これらのデータが**LLMの中に大量に蓄積されると何か生まれる**か？”

![imageSWC2-17-1](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-1.jpg) 

D先生： “つまり、**DMAICSサイクルを回す**と、何が起こるのか？非常に興味がある話題ではありますが、先だってのAMAZON本のコメントが気になりますね。”

![imageSWC2-17-2](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-2.jpg) 

D先生： “タグチメソッドの動特性を使えないと面白みはありません。今回、我々が提案した**「簡易知識爆発法」**では、コメントの人（↑）の言うように**静特性しか扱えない**でしょうか？”

![imageSWC2-17-3](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-3.jpg) 

QEU:FOUNDER： “前回も言ったが、この本が推す数理的手法には全く問題はありません。問題は、**「基本機能(generic function)の選択」**に関してでしょう。はっきり言って、他の本を見ても基本機能の極意なんかはわからないです。人間でも、その調子なのだから、LLMにこれらの動特性の情報を入れても、LLMは理解できるのかは疑問です。一方、**望大、望小特性の情報であれば、LLMはすぐに理解してくれる**と思います。”

D先生： “FOUNDER・・・。ちょっと話が進みすぎです。まずは動特性の根幹である基本機能について説明しないと・・・。 “

![imageSWC2-17-4](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-4.jpg) 

QEU:FOUNDER ： “製品やプロセスの動特性を計測するには、信号値(M)と計測値(y)のペアを線形回帰ができるように複数個収集する必要があります。このとき、**理想的なプロセスやサービスを測定したとき、それらの情報が0点比例式にバラツキなく分布する**のが、タグチメソッドの動特性の大前提になります。”

D先生： “残念ながら、0点1次式に分布するような都合の良い特性が、やすやすと世の中に見つかるわけがないです。 “

![imageSWC2-17-5](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-5.jpg) 

QEU:FOUNDER ： “そのような**「無理筋」**な要求を、**失敗すると叩かれるサラリーマン・エンジニアたちに押し付けてきた**のが、暗黒の2010年代・・・。もうちょっと前からそうなのかな？令和なんだから、そんなことはやめましょう。・・・考えてみれば、**基本機能というのも「非線形多次元の当てはめ」が不可能な昭和世代の代替品**なのです。今ならば、QEUシステムが提唱する**「総合SN比（↓）」を使えばいい**です。”

![imageSWC2-17-6](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-6.jpg) 

QEU:FOUNDER ： “**総合SN比の信号値は「ディープラーニングによる多次元非線形当てはめ値」になります。**これならば、ほとんどすべてのプロセスや製品に対応ができます。そして、この総合SN比は、LLMにも相性がいいです。”

D先生： “従来の基本機能は、その**「曼荼羅的特性」**によりLLMとの相性が悪いことは分かります。それでは、なぜ総合SN比の場合にはLLMとの相性がいいのですか？”

![imageSWC2-17-7](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-7.jpg) 

QEU:FOUNDER ： “理由は、総合SN比のもつ、**「より筋の通った言語化が簡単だから」**という当たり前の特性です。ディープラーニング関数を構成している計測値（従属変数）群の定義と、その選定理由を述べればいいだけです。基本機能のような「キワモノ」感は全くありません。それらの言語が普通であればあるほど、**LLMの持つ「類推の能力（↑）」が発揮される**んですよ。それが知識爆発につながります。”

![imageSWC2-17-8](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-8.jpg) 

QEU:FOUNDER  ： “そして、今回の知識爆発のまとめになるが、今回のアプローチを「汎用技術構造」で一括して表現しました。コレ（↑）、一目でよくわかるでしょう？従来の品質工学の図と比較してください、最も大きなポイントは、**真ん中の図形が「データベース」になっています**。このように、人類が享受できる計算力が極めて大きくなったら、汎用技術構造は大きくかわるんです。”

D先生： “なるほど、ここまでの長い説明、ご苦労様でした。あとは、私が主体となって、今回の本テーマについて説明します。今回は、**汎用技術構造の左側のDB化**についてプログラムを解説しましょう。”

![imageSWC2-17-9](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-9.jpg) 

QEU:FOUNDER ： “今の語り方では、読者は「汎用技術構造」について混乱するでしょう。”

D先生： “確かに・・・。でも、すでに挙げた2つのタイプ**（ダイアグラム型とマトリックス型）**を、我々は同様に「汎用技術構造」と言っているので、しようがないですね。聞き手の皆さんは、あきらめて慣れてくださいな・・・（笑）。それでは、プログラムをドン！！ “

```python
##############################
# 汎用的な実験データ（汎用構造左側）のDB入力用プログラム
##############################
# ---
import pandas as pd
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
import os
import sqlite3
from typing import List, Dict, Optional

class AppSettings:
    def __init__(
        self,
        db_name: str = 'default.db',
        table_name: str = 'experiments',
        input_file: str = 'data.xlsx',
        control_factors: Dict[str, List[str]] = None,
        response_columns: List[str] = None,
        factor_mappings: Dict[str, Dict[str, float]] = None
    ):
        self.db_name = db_name
        self.table_name = table_name
        self.input_file = input_file
        self.control_factors = control_factors or {}
        self.response_columns = response_columns or []
        self.factor_mappings = factor_mappings or {}

class ExperimentRecord(BaseModel):
    experiment_no: int = Field(..., description="実験番号")
    factors: Dict[str, int] = Field(..., description="制御因子の値")
    responses: Dict[str, float] = Field(..., description="応答値")

class ProcessedOutput(BaseModel):
    records: List[ExperimentRecord] = Field(..., description="実験記録リスト")
    factor_levels: Dict[str, Dict[str, float]] = Field(..., description="因子水準マッピング")
    control_factor_count: int = Field(..., description="制御因子数")
    response_count: int = Field(..., description="応答値項目数")

def excel_to_markdown(file_path: str) -> str:
    df = pd.read_excel(file_path, header=None)
    return df.to_markdown(index=False, headers="keys")

def transform_data(prompt_template: str, input_prompt: str) -> Optional[ProcessedOutput]:
    llm = ChatOpenAI(
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
        model="qwen-plus",
        temperature=0
    )

    parser = PydanticOutputParser(pydantic_object=ProcessedOutput)
    
    prompt = PromptTemplate(
        template=prompt_template + "\n{format_instructions}",
        input_variables=["input_data"],
        partial_variables={"format_instructions": parser.get_format_instructions()}
    )

    chain = prompt | llm | parser
    
    try:
        return chain.invoke({"input_data": input_prompt})
    except Exception as e:
        print(f"処理エラー: {e}")
        return None

def generate_table_sql(settings: AppSettings) -> str:
    columns = ["id INTEGER PRIMARY KEY AUTOINCREMENT"]
    columns += ["experiment_no INTEGER", "project TEXT"]
    
    if settings.control_factors:
        for factor in settings.control_factors.get('names', []):
            columns.append(f"{factor} INTEGER")
    
    if settings.response_columns:
        for response in settings.response_columns:
            columns.append(f"{response} REAL")
    
    columns.append("description TEXT")
    return f"CREATE TABLE IF NOT EXISTS {settings.table_name} ({', '.join(columns)})"

# 修正後のsave_to_database関数
def save_to_database(settings: AppSettings, processed_data: ProcessedOutput):
    conn = sqlite3.connect(settings.db_name)
    cursor = conn.cursor()
    
    cursor.execute(generate_table_sql(settings))
    
    # カラム名リスト生成
    columns = [
        "experiment_no",
        "project",
        *settings.control_factors.get('names', []),
        *settings.response_columns,
        "description"
    ]
    
    insert_sql = f"""
    INSERT INTO {settings.table_name} 
    ({', '.join(columns)})
    VALUES ({', '.join(['?']*len(columns))})
    """
    
    for record in processed_data.records:
        values = [
            record.experiment_no,
            settings.input_file,
            *[record.factors.get(factor, 0) for factor in settings.control_factors.get('names', [])],
            *[record.responses.get(response, 0.0) for response in settings.response_columns],
            f"Processed {settings.input_file}"
        ]
        cursor.execute(insert_sql, values)
    
    conn.commit()
    
    # データ表示
    print("\nデータベース内容:")
    cursor.execute(f"SELECT {', '.join([c for c in columns if c != 'description'])} FROM {set-tings.table_name}")
    rows = cursor.fetchall()
    
    # 表形式表示
    from tabulate import tabulate
    print(tabulate(rows, headers=[c for c in columns if c != 'description'], tablefmt='psql'))
    
    conn.close()


# 修正後のstructured_prompt_template
structured_prompt_template = """
実験データを解析して構造化データを生成してください。以下の要素を含めてください：

1. 実験番号
2. 制御因子とその値
3. 応答値（sensitivity, SN_ratio）

入力データ:
{input_data}

出力形式:
- JSON形式で以下を含む:
{{
  "records": [
    {{
      "experiment_no": 実験番号,
      "factors": {{
        "A": 値,
        "B": 値,
        ...
      }},
      "responses": {{
        "sensitivity": 値,
        "SN_ratio": 値
      }}
    }}
  ],
  "factor_levels": {{"因子A": {{"1": 水準1, ...}}}},
  "control_factor_count": 制御因子数,
  "response_count": 応答値項目数
}}
"""

def main_process(settings: AppSettings):
    print("=== 処理開始 ===")
    
    # Excelデータ変換
    markdown_data = excel_to_markdown(settings.input_file)
    
    # 入力プロンプト生成
    input_prompt = f"""
### 入力ファイル: {settings.input_file}
### データベース: {settings.db_name}
### テーブル名: {settings.table_name}
### 制御因子: {', '.join(settings.control_factors.get('names', []))}
### 応答値: {', '.join(settings.response_columns)}
### 実験データ:
{markdown_data}
"""
    
    # データ処理
    processed = transform_data(structured_prompt_template, input_prompt)
    
    if processed:
        # データベース保存
        save_to_database(settings, processed)
        print("=== 処理成功 ===")
        return True
    
    print("=== 処理失敗 ===")
    return False

# 実行例
if __name__ == "__main__":
    # 設定例
    example_settings = AppSettings(
        db_name="taguchi13B.db",
        table_name="calculate_13A",
        input_file="summary13A.xlsx",
        control_factors={
            "names": ["A", "B", "C", "D", "F", "G", "H"],
            "levels": {
                "A": {"1": 1, "2": 2, "3": 3},
                # 他の因子も同様に定義可能
            }
        },
        response_columns=["sensitivity", "SN_ratio"]
    )
    
    main_process(example_settings)

```

D先生： “そして、このプログラムを動かした結果は以下の通りです。”

![imageSWC2-17-10](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-10.jpg) 

D先生： “何か、ご質問は？”

QEU:FOUNDER ： “DB上に、新しくテーブルが出来たんでしょう？どのようになったのですか？”

![imageSWC2-17-11](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-11.jpg) 

D先生： “SELECT文でテーブル内のデータを吐き出すと、このように（↑）なります。次のステップは、**前回の感度とSN比のデータをこのデータにUPDATEで注入する**ことです。”

QEU:FOUNDER ： “今回、我々が言いたかったことは「知識爆発は可能」ということです。たぶん・・・。このプログラムの生成は、**「Vibe Codingの実践」**程度の意味しかありません。気楽に行きましょう。”


## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “C部長の、その「錯覚」も、結局のところUSDを単位として評価しているからでしょう？それを**購買力(PPP)で評価しちゃう**と、C国と同じレベルになってしまうんじゃないの？”

![imageSWC2-17-12](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-12.jpg) 

D先生： “そういえば、最近、すごいニュースがありますからね。”

![imageSWC2-17-13](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-13.jpg) 

QEU:FOUNDER ： “いきなり、こうなった（↑）と思わないでくださいね。**長い努力の蓄積**があります。”

![imageSWC2-17-14](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-14.jpg) 

D先生：“あの半導体の世界でも、すでにここまで来ていたんですね。それにしても、**開発の「担い手」が特徴的です**。大学がおおいです。”

![imageSWC2-17-15](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-15.jpg) 

C部長：“あああ・・・。J国、スゴイ・・・。”

![imageSWC2-17-16](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-16.jpg) 

QEU:FOUNDER ： “J国って、基礎研究まで企業に任せようとするでしょ？企業って、すべからく**「研究にはあまり向いていない」**と思うんです。精神論が先走る懸念があります。”

[![MOVIE1](http://img.youtube.com/vi/YLmKhrlUeSM/0.jpg)](http://www.youtube.com/watch?v=YLmKhrlUeSM "アメリカVS中国！トランプ関税で中国との対立が激化！池亀彩・京都大学教授。安冨歩・東京大学名誉教授。")

C部長： “そんなことを言ったら、お先真っ暗じゃないですか？”

![imageSWC2-17-17](/2025-04-25-QEUR23_SIWC17/imageSWC2-17-17.jpg) 

QEU:FOUNDER ： “実際のところ、**「お先真っ暗」**ですが・・・（笑）。敢て、明るい話題を言えば、コレ（↑）かな・・・？企業も横着をせずに、大学の重要性を再確認して、より資本を使って活用すればいいのだと思います。早く、**「平成に取った政策の99％は大失敗」**と認めてさ・・・。”

