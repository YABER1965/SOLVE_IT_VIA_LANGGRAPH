---
title: QEUR23_SIWC22 - LangGraphでLLMプロセスに計算ノードを加える(別のプロンプト)
date: 2025-05-04
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_SIWC22 - LangGraphでLLMプロセスに計算ノードを加える(別のプロンプト)

## ～ LLMの妄想爆発！！ ～

### ・・・ 前回のつづきです ・・・

D先生（設定年齢65歳）： “それにしても、このプログラムはプロンプトを変えると動くんでしょうかね？”

QEU:FOUNDER （設定年齢65歳）： “多分、プロンプトが変わると動かないと思います。まあ、その時はVibe Codingで改善します。さらに、「もっとプログラムに柔軟性を設けてください」って・・・。Vibe Coding って、1つの事例だけでは、良いモノが出来ないのが難しいところだと思います。もうちょっと、システムの機能を拡張させてね・・・。これが、次のネタです。引用元は前回と同じです。”

![imageSWC2-22-1](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-1.jpg) 

D先生： “タイトルから察するに、望小特性ですね。何も言うことはないです。これもVibe Coding? 苦労しましたか？ “

QEU:FOUNDER ： “例によってすごく苦労しました。Reasoningモデルは賢いです。しかし、彼らは**やらなくても良いことをやる**んです。自分がせっかく装着した機能を、消すことはしょっちゅうあります。”

D先生： “そして、その消したバージョンが、うまく動くという・・・（笑）。“

QEU:FOUNDER ： “怒りのあまり絶叫を何回やったか・・・。もう止めようと思ったことが何回あったか・・・。まあ、いいや・・・。プログラムをドン！！”

```python
# -*- coding: utf-8 -*-
import os
import pandas as pd
import numpy as np
import statsmodels.api as sm
from typing import Annotated, TypedDict, List, Dict, Any
from langgraph.graph import END, StateGraph
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic.v1 import BaseModel, Field
import json
import re
import traceback

# 汎用データモデル
class ExperimentDataRow(BaseModel):
    NO: int
    X1: str = Field(..., alias="Factor1")
    X2: str = Field(..., alias="Factor2")
    X3: str = Field(..., alias="Factor3")
    X4: str = Field(..., alias="Factor4")
    X5: str = Field(..., alias="Factor5")
    X6: str = Field(..., alias="Factor6")
    X7: str = Field(..., alias="Factor7")
    Y: float = Field(..., alias="Response")

class ExtractedData(BaseModel):
    experimental_data: List[ExperimentDataRow]
    current_levels: Dict[str, str]
    project_info: Dict[str, Any]

# 状態定義
class AgentState(TypedDict):
    input_prompt: str
    extracted_data: Dict[str, Any]
    regression_results: Dict[str, Any]
    solver_report: str
    verification_result: str

# LLM設定
llm_extract = ChatOpenAI(
    model="qwen-plus",
    temperature=0.0,
    openai_api_key=os.getenv("DASHSCOPE_API_KEY"),
    openai_api_base="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
)

# 動的プロンプトテンプレート
DYNAMIC_PROMPT = """
以下の情報を厳密なJSON形式で出力：
{{
  "experimental_data": [
    {{
      "NO": 整数,
      "Factor1": "X1値",
      "Factor2": "X2値",
      "Factor3": "X3値",
      "Factor4": "X4値",
      "Factor5": "X5値",
      "Factor6": "X6値",
      "Factor7": "X7値",
      "Response": 応答値
    }}
  ],
  "current_levels": {{
    "X1": "現水準",
    "X2": "現水準",
    "X3": "現水準",
    "X4": "現水準",
    "X5": "現水準",
    "X6": "現水準",
    "X7": "現水準"
  }},
  "project_info": {{
    "project_name": "プロジェクト名",
    "response_variable": "応答変数",
    "dependent_variables": ["X1-X7"],
    "evaluation_method": "評価法",
    "objective": "目的"
  }}
}}
【入力】:
{input}
"""

def safe_json_parse(text: str) -> dict:
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        matches = list(re.finditer(r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}', text, re.DOTALL))
        if not matches:
            raise ValueError("JSON not found")
        for match in reversed(matches):
            candidate = match.group(0)
            try:
                candidate = re.sub(r',\s*([}\]])', r'\1', candidate)
                candidate = re.sub(r"'(.*?)'", r'"\1"', candidate)
                candidate = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', candidate)
                return json.loads(candidate)
            except json.JSONDecodeError:
                continue
        raise ValueError("Invalid JSON format")

extract_chain = (
    ChatPromptTemplate.from_messages([("system", DYNAMIC_PROMPT), ("user", "{input}")])
    | llm_extract
    | (lambda msg: msg.content)
    | safe_json_parse
    | (lambda data: ExtractedData.parse_obj(data))
)

# ダミー変数生成（型指定を追加）
def create_dummies(df, col, prefix, current_level):
    dummies = pd.get_dummies(df[col].astype("string"), prefix=prefix, dtype=float)
    ref_col = f'{prefix}_{current_level}'
    return dummies.drop(columns=[ref_col]) if ref_col in dummies.columns else dummies

# 計算ノード（型変換を追加）
def calculate_regression(state: AgentState):
    try:
        raw_result = extract_chain.invoke({"input": state["input_prompt"]})
        
        # データフレーム作成（型変換を明示）
        df = pd.DataFrame([
            {
                'NO': row.NO,
                'X1': str(row.X1),
                'X2': str(row.X2),
                'X3': str(row.X3),
                'X4': str(row.X4),
                'X5': str(row.X5),
                'X6': str(row.X6),
                'X7': str(row.X7),
                'Y': float(row.Y)
            }
            for row in raw_result.experimental_data
        ])
        
        current_levels = {k: str(v) for k, v in raw_result.current_levels.items()}
        
        # ダミー変数生成（型指定）
        X_list = []
        for i in range(1, 8):
            col = f'X{i}'
            X_list.append(create_dummies(df, col, col, current_levels[col]))
        
        X = pd.concat(X_list, axis=1).astype(float)
        y = df['Y'].astype(float)
        
        # 回帰分析（定数項追加）
        X_sm = sm.add_constant(X.astype(float), has_constant='add')
        model = sm.OLS(y.astype(float), X_sm).fit()
        
        # 結果抽出（型変換）
        coefficients = {k: float(v) for k, v in model.params.items()}
        intercept = coefficients.pop('const')
        
        # メイン効果の分離
        main_effects = {
            var: {k: v for k, v in coefficients.items() if k.startswith(var)}
            for var in [f'X{i}' for i in range(1,8)]
        }
        
        # 有意交互作用の抽出（p値0.1以下）
        sig_interactions = [
            (term, float(model.pvalues[term]))
            for term in X.columns
            if term in model.pvalues and model.pvalues[term] <= 0.1 and ':' in term
        ]
        
        # 最適条件探索
        optimal = {}
        current_pred = intercept  # 現状水準の予測値（切片）
        max_pred = current_pred
        
        for var in [f'X{i}' for i in range(1,8)]:
            var_cols = [c for c in coefficients if c.startswith(var)]
            if var_cols:
                levels = {c.split('_')[-1]: float(coefficients[c]) for c in var_cols}
                best_level = max(levels, key=levels.get)
                optimal[var] = best_level
                max_pred += levels[best_level]
        
        return {
            "extracted_data": {
                "experimental_data": df.to_dict(orient='records'),
                "current_levels": current_levels,
                "project_info": raw_result.project_info
            },
            "regression_results": {
                "intercept": intercept,
                "coefficients": coefficients,
                "main_effects": main_effects,
                "significant_interactions": sig_interactions,
                "optimal": optimal,
                "max_pred": max_pred,
                "current_pred": current_pred,
                "improvement": max_pred - current_pred,
                "project_info": raw_result.project_info
            }
        }
        
    except Exception as e:
        return {"error": str(e), "trace": traceback.format_exc()}

# レポート生成（エラーハンドリング追加）
def generate_report(state: AgentState):
    if "error" in state.get("regression_results", {}):
        return {"solver_report": "Error in regression analysis"}
    try:
        data = state["regression_results"]
        extracted_data = state["extracted_data"]
        
        # SN比計算
        current_sn = abs(data["current_pred"])
        optimal_sn = abs(data["max_pred"])
        gain = optimal_sn - current_sn
        
        # 最適条件フォーマット
        optimal_conditions = "\n".join([f"- {var}: {level}" for var, level in data["optimal"].items()])
        
        # 回帰係数テーブル作成（切片を含む）
        coeff_table = pd.DataFrame(
            [("切片", data["intercept"])] + list(data["coefficients"].items()),
            columns=["Term", "Coefficient"]
        )
        
        report_prompt = f"""あなたは実験データの解析をするSOLVERです。
        USER が提供した以下の実験データを分析し、タグチメソッドの方法論を参考にしてSN比が最大になるように最適化してください。
        ただし、解析方法はタグチメソッドが一般的に使用する主効果法ではありません。最小二乗法による回帰分析を使用してください。
        ### 実験データ
        {pd.DataFrame(extracted_data['experimental_data']).to_string(index=False)}
        ### プロジェクト情報
        - プロジェクト名: {data["project_info"]["project_name"]}
        - 応答変数: {data["project_info"]["response_variable"]}
        - 評価方法: {data["project_info"]["evaluation_method"]}
        - 目的: {data["project_info"]["objective"]}
        ### 回帰分析結果
        #### 最小二乗法による切片と回帰係数
        {coeff_table.to_string(index=False, float_format="%.4f")}
        #### 最適条件比較
        | 項目         | 現状条件       | 最適条件       | SN比改善 |
        |--------------|----------------|----------------|----------|
        | 現状SN比     | {current_sn:.2f}dB | -              | -        |
        | 最適SN比     | -              | {optimal_sn:.2f}dB | +{gain:.2f}dB |
        #### 最適条件
        {optimal_conditions}
        ステップバイステップで分析を行い、その過程であなたの考え方と計算結果を示してください。最終的な分析結果は表にまとめてください。
        その他、解析レポートには必要に応じて以下の要素を含めてください：
        1. 項目影響度の大きい順に要因を評価
        2. 有意な交互作用の工学的解釈
        3. 最適条件の決定プロセス
        4. 予測値の算出方法
        5. 現在設計条件との比較分析"""
        
        response = ChatOpenAI(
            model="deepseek-reasoner",
            temperature=0.1,
            openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
            openai_api_base="https://api.deepseek.com"
        ).invoke(report_prompt)
        
        return {"solver_report": response.content}
        
    except Exception as e:
        return {"solver_report": f"Report generation error: {str(e)}"}

# 検証ノード（エラーハンドリング追加）
def verify_report(state: AgentState):
    if "solver_report" not in state:
        return {"verification_result": "Verification skipped: solver failed"}
    
    try:
        data = state["regression_results"]
        project = data["project_info"]
        
        verify_prompt = f"""あなたはSOLVERが作成した実験レポートの検証をするVERIFIERです。
        ソルバーの解答における重要な記述、式、演算について、それぞれ「GOOD」「ACCEPTABLE」「POOR」の3段階で評価し、その理由を説明してください。
        - GOOD(良い)：これが最善の方法です。
        - ACCEPTABLE(許容できる)：最善の方法ではありませんが、結果に悪影響を与えません。
        - POOR(悪い)：最終結果に悪影響を与えており、改善が必要です。
        プロジェクト: {project.get('project_name')}
        レポート内容:
        {state["solver_report"]}
        検証ポイント:
        1. 統計手法の適切性
        2. 工学的解釈の妥当性
        3. 結論の整合性
        4. 数値計算の正確性"""
        
        response = ChatOpenAI(
            model="deepseek-reasoner",
            temperature=0.1,
            openai_api_key=os.getenv("DEEPSEEK_API_KEY"),
            openai_api_base="https://api.deepseek.com"
        ).invoke(verify_prompt)
        
        return {"verification_result": response.content}
        
    except Exception as e:
        return {"verification_result": f"Verification error: {str(e)}"}

# ワークフロー構築（エラーハンドリング追加）
workflow = StateGraph(AgentState)
workflow.add_node("calculator", calculate_regression)
workflow.add_node("solver", generate_report)
workflow.add_node("verifier", verify_report)
workflow.set_entry_point("calculator")
workflow.add_edge("calculator", "solver")
workflow.add_edge("solver", "verifier")
workflow.add_edge("verifier", END)
agent = workflow.compile()

# ---
from IPython.display import Image, display

try:
    display(Image(agent.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass

```

D先生： “グラフはコレ（↓）ですね。”

![imageSWC2-22-2](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-2.jpg) 

D先生： “グラフは、前回と同じですよね。違いは、なんですか？ “

QEU:FOUNDER ： “**ある程度の汎用性を手に入れました**。あとは、解析結果をみればわかってきますよ。”

```python
# ---
# 実行関数（キー名統一とエラーチェック強化）
def run_agent(input_prompt: str):
    try:
        result = agent.invoke({"input_prompt": input_prompt})
        
        # キー存在チェック強化
        required_keys = ["regression_results", "solver_report", "verification_result"]
        missing = [k for k in required_keys if k not in result]
        
        if missing:
            return {"error": f"Missing keys: {missing}"}
            
        return {
            "regression": result["regression_results"],
            "extracted_data": result["extracted_data"],
            "report": result["solver_report"],
            "verification": result["verification_result"]
        }
        
    except Exception as e:
        return {
            "error": f"Critical Error: {str(e)}",
            "trace": traceback.format_exc()
        }

# ---
# テスト実行
user_prompt = """
以下のような実験をしました。この実験データに基づいて、応答変数(Y)の量を最大とする従属変数(X)の水準と予測値を教えてください。
この実験手法はタグチメソッドに基づいていますが、データの解析は主効果の解析ではなく、数量化一類の回帰分析の手法を用いてください。
レポートの作成は、回帰分析を使った事以外はタグチメソッドのロジックに従ってください。
また、その予測とレポート作成に使ったロジックをステップバイステップで記述してください。
## プロジェクト名 : 半導体の抵抗の低減
## 製品名 : 当社の半導体
## 評価方法 : 種々の誤差因子（N1,N2）で得た計測値を、望小SN比の定義式で変換して、望小SN比を生成した
## プロジェクトの目的 : 半導体の抵抗の低減して、より高い性能の製品を製造する
## 応答変数(Y)
- Y : (望小)SN比
## 従属変数（X）
- X1 : ウエハの種類
- X2 : 膜厚
- X3 : 洗浄後放置時間
- X4 : 処理液種類
- X5 : 乾燥後放置時間 
- X6 : 熱処理温度
- X7 : 熱処理時間
## 現状の水準
- X1 : L
- X2 : 50nm
- X3 : 15min
- X4 : H液
- X5 : 30min 
- X6 : 400deg
- X7 : 30min
## 実験データ
|   NO | ウエハの種類  | 膜厚  | 洗浄後放置時間  | 処理液種類  | 乾燥後放置時間  | 熱処理温度  | 熱処理時間  |  SN比 |
|-----:|:----------|:-------|:---------|:--------|:---------|:--------|:--------|---------:|
|    1 | K      | 40nm  | 0min     | S液      | 5min     | 350deg      | 20min    |  9.25372 |
|    2 | K      | 40nm  | 15min    | H液      | 30min    | 400deg      | 30min    | 12.5927  |
|    3 | K      | 40nm  | 30min    | B液      | 60min    | 450deg      | 40min    | 12.5744  |
|    4 | K      | 50nm  | 0min     | S液      | 30min    | 400deg      | 40min    | 14.5237  |
|    5 | K      | 50nm  | 15min    | H液      | 60min    | 450deg      | 20min    | 16.303   |
|    6 | K      | 50nm  | 30min    | B液      | 5min     | 350deg      | 30min    | 15.5811  |
|    7 | K      | 60nm  | 0min     | H液      | 5min     | 450deg      | 30min    | 17.7715  |
|    8 | K      | 60nm  | 15min    | B液      | 30min    | 350deg      | 40min    | 19.071   |
|    9 | K      | 60nm  | 30min    | S液      | 60min    | 400deg      | 20min    | 17.8935  |
|   10 | L      | 40nm  | 0min     | B液      | 60min    | 400deg      | 30min    | 12.1993  |
|   11 | L      | 40nm  | 15min    | S液      | 5min     | 450deg      | 40min    | 10.9343  |
|   12 | L      | 40nm  | 30min    | H液      | 30min    | 350deg      | 20min    | 10.6741  |
|   13 | L      | 50nm  | 0min     | H液      | 60min    | 350deg      | 40min    | 18.044   |
|   14 | L      | 50nm  | 15min    | B液      | 5min     | 400deg      | 20min    | 14.9257  |
|   15 | L      | 50nm  | 30min    | S液      | 30min    | 450deg      | 30min    | 13.3242  |
|   16 | L      | 60nm  | 0min     | B液      | 30min    | 450deg      | 20min    | 18.9575  |
|   17 | L      | 60nm  | 15min    | S液      | 60min    | 350deg      | 30min    | 17.9914  |
|   18 | L      | 60nm  | 30min    | H液      | 5min     | 400deg      | 40min    | 18.292   |
"""

result = run_agent(user_prompt)

# ---
from IPython.display import Markdown

print("\n=== 最適化レポート(SOLVER) ===\n")
Markdown(result["report"])

```

D先生： “こんな結果が出て来た。**・・・ん！？**“

![imageSWC2-22-3](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-3.jpg) 

D先生： “なにこれ！？もっと細かく見せてください！！ “

=== 最適化レポート(SOLVER) ===

解析レポート：半導体抵抗低減プロジェクト

1. 回帰モデル構築と係数解釈

\hat{Y} = 15.9402 + \sum (係数 \times ダミー変数)

2. 項目影響度ランキング（絶対値基準）

- 順位	因子	最大影響幅	工学的解釈
- 1	X2	6.958 dB	薄膜厚さが抵抗に最も影響
- 2	X4	1.565 dB	溶液種類の選択が重要
- 3	X5	1.375 dB	反応時間の最適化必要
- 4	X7	0.905 dB	焼成時間の管理が有効
- 5	X3	0.579 dB	前処理時間は二次的要因

3. 最適条件決定プロセス

最適条件選択基準：

for 各因子 in 因子リスト:

   選択水準 = 係数最大値を持つ水準

   制約条件：実現可能な工学的範囲

4. 予測値算出方法

\hat{Y}_{opt} = 切片 + \sum (最適水準の係数)
= 15.9402 + (0.0247) + (2.8792) + (-0.1781) + (-0.0614) 
+ (0.9771) + (0.0314) + (0.6632)
= 20.28 dB

5. 比較分析結果

- 比較項目	現状条件	最適条件	改善効果
- SN比	            15.94 dB	 20.28 dB	 +27.2%
- 推定抵抗値	基準値の100%    基準値の62.1%	    37.9%低減
- 安定性	σ=2.1 dB	σ=1.4 dB	33%改善

6. 交互作用分析

現モデルでは有意な交互作用は検出されていません。ただし、X2（薄膜厚さ）とX4（溶液種類）の組み合わせについて、今後の実験で詳細検証を推奨します。

7. 最適化結果サマリー表

- 因子	現状水準	最適水準	選択根拠	     係数寄与
- X1	K	    K	        係数差が微小（0.0247）	      +0.0247
- X2	50nm	    60nm	最大正係数（+2.8792）	      +2.8792
- X3	15min	    0min	負影響最小化（-0.1781）	       -0.1781
- X4	H液	    B液	        中性液で安定性確保	                   -0.0614
- X5	30min	    60min	長時間処理効果（+0.9771）	       +0.9771
- X6	400deg    350deg	低温で均一性向上	+0.0314
- X7	30min	    40min	焼成時間延長効果（+0.6632）	+0.6632

8. リスク評価

- X2の60nm化：薄膜形成装置の精度限界に近い
- X5の60min処理：生産サイクルタイム増加（+30%）
- 対策案：X2の55nmでの再実験、X5の連続処理システム導入検討

9. 検証実験提案

- 最適条件の3回反復実験
- X2（50-70nm）のステップワイズ実験
- X4とX5の交互作用検証実験

10. 経済効果試算

- 項目	現状	最適化後	改善率
- 歩留まり率	82%	89%	+7%
- 生産速度	100 units/hr	93 units/hr	-7%
- 品質保証コスト	$1.2M/月 | $0.8M/月	-33%	
- 年間総コスト削減額	-	$4.8M	-

※ 生産速度低下分は設備増強で対応可能と判断

**結論：提案最適条件はSN比4.34dB改善を達成し、年間約480万ドルのコスト削減が期待できる。ただし薄膜厚さの工程管理強化が必須条件となる。**

D先生： “**いい味がですぎ**でしょうに・・・。どうして、こんな経済性効果の試算ができるんですか？“

![imageSWC2-22-4](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-4.jpg) 

QEU:FOUNDER ： “たぶんLLMの中に、似たような議論の展開があったんでしょうね。DMAICSサイクルを活用して、LLMの学習を続けると、近い将来に大きな発展が期待できますよね。”

D先生： “確かに、そういう考え方もできます。じゃあ、次に検証レポートをみてみましょう。これは、DEEPSEEKにやらせたのですか？ “

QEU:FOUNDER ： “はい。実を言うと、解析も検証もDEEPSEEK R1がやりました。他のモデルにやらせるのも面白いですよ。それでは、内容を見てみましょう。”


**（コード）**

```python
# ---
print("\n=== 検証結果(VERIFIER) ===\n")
Markdown(result["verification"])

```

**（外観）**

![imageSWC2-22-5](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-5.jpg) 

D先生： “これも味があるなあ・・・。もうちょっと詳しく見せてください。”

=== 検証結果(VERIFIER) ===

検証結果

1. 回帰モデル構築

評価: ACCEPTABLE

理由: 主効果のみを考慮したモデルで、変数選択や交互作用の検証が明記されていない。ただし、工学的に事前要因選択されている可能性があるため許容範囲。

2. 因子影響度ランキング

評価: GOOD

理由: カテゴリカル変数の最大影響幅（係数差）を基準にしたランキングは統計的に適切。X2の6.958dBなど、工学的影響度と整合。

3. 最適条件決定プロセス

評価: GOOD

理由: SN比最大化を目的とした係数最大値の水準選択は理論的に正しい。X3の0分選択（係数-0.1781回避）など具体例も適切。

4. 予測値計算

評価: GOOD

理由: 切片15.9402 + 最適係数の総和計算（20.28dB）は数値的に正確。小数点以下四捨五入も適切。

5. SN比-抵抗値換算

評価: POOR

理由: SN比4.34dB改善から62.1%抵抗低減を導出した計算に矛盾。理論値（約60.5%）との乖離が工学的判断を歪めるリスク。

6. 交互作用分析

評価: POOR

理由: 「有意な交互作用なし」の根拠不明。交互作用項をモデルに含めていない場合、この結論は統計的に無効。

7. X4（溶液種類）の水準選択

評価: POOR

理由: X4の最大影響幅1.565dBに対し、選択水準B液の係数-0.0614は矛盾。工学的解釈と係数値が整合せず最適選択の信頼性低下。

8. リスク評価

評価: GOOD

理由: X2の薄膜形成精度リスクやX5のサイクルタイム増加への対処案（55nm再実験など）が現実的。

9. 経済効果試算

評価: ACCEPTABLE

理由: 生産速度低下を設備増強で補うとの前提はやや楽観的だが、歩留まり改善と品質コスト削減のトレードオフ判断は合理的。

D先生： “数個だけ、重要な視点を拾ってきて、それらを簡潔に検証しているスタイルが良さげです。「えっ？55nm再実験って！？」など、変な話が飛び出てくるのも、LLMの醍醐味です。回帰分析の生データも観たいです。”

QEU:FOUNDER ： “すまない。データを見せるのを忘れていました。”

```python
# ---
str_output = ""
str_output += "\n抽出された実験データ:\n"
str_output += pd.DataFrame(result["extracted_data"]["experimental_data"]).to_string(index=False)
    
str_output += "\n最小二乗法による切片と回帰係数:\n"

coeff_df = pd.DataFrame(
	[("切片", result["regression"]["intercept"])] + [
		(term, coef) for term, coef in result["regression"]["coefficients"].items()
	],
	columns=["Term", "Coefficient"]
)
str_output += coeff_df.to_string(index=False, float_format="%.4f")
    
current_pred = abs(result["regression"]["current_pred"])
max_pred = abs(result["regression"]["max_pred"])
current_pred = abs(result["regression"]["current_pred"])
str_output += f"\n現状SN比: {current_pred} dB"
str_output += f"\n最適SN比: {max_pred} dB"
str_output += f"\nゲイン: {max_pred - current_pred} dB"
    
str_output += "\n最適条件:\n"

for var, level in result["regression"]["optimal"].items():
	str_output += f"{var}: {level} "

print("\n=== 計算結果(CALCULATOR) ===\n")
print(str_output)

```

D先生： “これが、生データですね。”

=== 計算結果(CALCULATOR) ===

抽出された実験データ:

 NO X1   X2    X3 X4    X5     X6    X7        Y
 
  1  K 40nm  0min S液  5min 350deg 20min  9.25372
  
  2  K 40nm 15min H液 30min 400deg 30min 12.59270
  
  3  K 40nm 30min B液 60min 450deg 40min 12.57440
  
  4  K 50nm  0min S液 30min 400deg 40min 14.52370
  
  5  K 50nm 15min H液 60min 450deg 20min 16.30300
  
  6  K 50nm 30min B液  5min 350deg 30min 15.58110
  
  7  K 60nm  0min H液  5min 450deg 30min 17.77150
  
  8  K 60nm 15min B液 30min 350deg 40min 19.07100
  
  9  K 60nm 30min S液 60min 400deg 20min 17.89350
  
 10  L 40nm  0min B液 60min 400deg 30min 12.19930
 
 11  L 40nm 15min S液  5min 450deg 40min 10.93430
 
 12  L 40nm 30min H液 30min 350deg 20min 10.67410
 
 13  L 50nm  0min H液 60min 350deg 40min 18.04400
 
 14  L 50nm 15min B液  5min 400deg 20min 14.92570
 
 15  L 50nm 30min S液 30min 450deg 30min 13.32420
 
 16  L 60nm  0min B液 30min 450deg 20min 18.95750
 
 17  L 60nm 15min S液 60min 350deg 30min 17.99140
 
 18  L 60nm 30min H液  5min 400deg 40min 18.29200

最小二乗法による切片と回帰係数:

     Term  Coefficient
	 
       切片      15.9402
	   
     X1_K       0.0247
	 
  X2_40nm      -4.0789
  
  X2_60nm       2.8792
  
  X3_0min      -0.1781
  
 X3_30min      -0.5798
 
    X4_B液      -0.0614
	
    X4_S液      -1.6261
	
  X5_5min      -0.3975
  
 X5_60min       0.9771
 
X6_350deg       0.0314

X6_450deg      -0.0937

 X7_20min      -0.2421
 
 X7_40min       0.6632

現状SN比: 15.94024888888889 dB

最適SN比: 20.27635222222224 dB

ゲイン: 4.33610333333335 dB

最適条件:

X1: K X2: 60nm X3: 0min X4: B液 X5: 60min X6: 350deg X7: 40min 

QEU:FOUNDER ： “普通の最小二乗法です。この情報を解析用LLMに投げると、解析レポートを作ってくれるんです。”

D先生： “便利だなあ・・・。これで終わりですか？せっかく、検証で有用なアドバイスをいただいたのですから、ここで**再度レポートを作るべき**だと思いますが・・・。”

QEU:FOUNDER ： “それも、おもしろそうですね。解析LLMが発狂するのではないでしょうか。”

## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “やっぱり、熱心なファンがやると、**彼らの強烈な「推し」がショーの出来栄えに効く**んです。”

![imageSWC2-22-6](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-6.jpg) 

C部長 : “そうねえ・・・。”

![imageSWC2-22-7](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-7.jpg) 

QEU:FOUNDER ： “このビック・イベントを見ていて、本当に勉強になっています。だから、目が離せないんです。今回、小生が勉強したことは、大きなイベントをまとめるときには、「大人数をまとめるための推しが必要だ」ということです。崩壊前のソ連のように、**すべてのメンバが「言われたからやりました」と動くイベントだとダメなんです**。今後にさらに注目しています。まさに、これは想像以上です。”

D先生：“すいません、つっこんで・・・。FOUNDERのいう、「推し」とは？”

![imageSWC2-22-8](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-8.jpg) 

QEU:FOUNDER ： “ビジネスマンがいう安易な表現では「コミットメント」・・・。要は**主体性のこと**ですね。「推し」の反対が、上記の記事では**「ギャンブルモード」**です。だから、あのイベントでは展示物が粗悪になっていく。”

D先生：“つまり、**「やりにげ」ということ**ですね（笑）。”

![imageSWC2-22-9](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-9.jpg) 

QEU:FOUNDER ： “下品な・・・（笑）。主体性は、教育指導要領の改訂により、J国そのものから少しづつ消えていったんです。主体性って結局は自分が考え、勉強しないと身につかないから・・・。当初の理念である**「生きる力を育む」が完全に裏目に来た**んです。これが、とてつもなく痛かった・・・。”

![imageSWC2-22-10](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-10.jpg) 

D先生： “「もはやこれまで」なんでしょうか？”

### 古い(平成)おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」
 
### 古い(平成)オッサン（＠車中、N社検査不正について）： 「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」
 
### 古い(平成)オッサン（海外工場のあいさつにて、なんと201X年のセリフじゃ！）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

QEU:FOUNDER ： “あくまで個人的な意見ですが、そうとも思いません。別に、昔の精神論的な管理手法（↑）が品質や生産性を押し上げる時代でもないですから・・・。科学技術が進めば、どこでも同じレベルになるのではないでしょうか。むしろ、**国によって「搾取の構造」が異なる**ので、そこらへんが最終的に影響するとおもいます。”

[![MOVIE1](http://img.youtube.com/vi/MyOGrrDGxMM/0.jpg)](http://www.youtube.com/watch?v=MyOGrrDGxMM "白井聡氏出演！『2025年日本の諸問題に切り込む！』")

C部長： “どういうこと？”

![imageSWC2-22-11](/2025-05-04-QEUR23_SIWC22/imageSWC2-22-11.jpg) 

QEU:FOUNDER ： “品質低下じゃなくて、**売れるモノを作る力が「亡くなる」**。だからお上に寄り掛かる。それにしても、このタイプの搾取（↑）はありえんわな・・・。ちなみに、ここの主語は変わる可能性があります（笑）。”

