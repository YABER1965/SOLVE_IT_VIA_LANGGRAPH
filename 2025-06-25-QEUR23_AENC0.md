---
title: QEUR23_AENC0 - 異常検出のためのAutoencoder
date: 2025-06-25
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_AENC0 - 異常検出のためのAutoencoder

## ～ 「念のために」やっておこう・・・ ～

QEU:FOUNDER（設定年齢65歳） ： “これから、AUTOENCODERをやるよ～！”

D先生（設定年齢65歳） ： “また、いきなり道草（方向転換ですか）！？まあいいや、一応聞きます・・・。なんでまた？”

![imageANC0-1-1](/2025-06-25-QEUR23_AENC0/imageANC0-1-1.jpg) 

QEU:FOUNDER（設定年齢65歳） ： “ちょっと、MT法の周辺を再評価したい。いや・・・、今回の場合は、MT法そのものではないんだが・・・。”

![imageANC0-1-2](/2025-06-25-QEUR23_AENC0/imageANC0-1-2.jpg) 

D先生： “あれ？アナタ、昔、MT法なんぞは、異常検出や、（外観）検査手法としては全く無意味だと言ってませんでした？その意見には、それなりに納得（↑）はします。・・・では、いまさら方向転換を？”

![imageANC0-1-3](/2025-06-25-QEUR23_AENC0/imageANC0-1-3.jpg) 

QEU:FOUNDER ： “QEUシステムにおける異常管理と外観検査のレイヤをもうちょっと分厚くしたい。小生は常に、検査が第一！検査のための選択肢が多ければ多いほどいいです。”

![imageANC0-1-4](/2025-06-25-QEUR23_AENC0/imageANC0-1-4.jpg) 

D先生： “じゃあ、今回のシステムは、ViT(Vision Transformer)を越えられるんですか？もしも、少ないリソースで同等のことができるのであれば、確かに、それはとてもありがたいことです。 “

QEU:FOUNDER ： “さすがに、それほど正確かつ豪華な手法はありえないです。今回は、**AUTOENCODER**をやります。これは、昔から気にはなっていたんだけど、やりたくなかったんだな。それでは、いきなりプログラムをドン・・・。”

```python
# ---
import numpy as np
import matplotlib.pyplot as plt
from skimage import draw
from tensorflow.keras import layers, models
from sklearn.metrics import confusion_matrix
import seaborn as sns
import tensorflow as tf

# GPU使用設定（必要に応じて）
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)

# -------------------------------
# 合成画像データの生成（修正版）
# -------------------------------
def generate_normal():
    """微小な揺らぎを持つ楕円を生成"""
    img = np.zeros((16, 16))
    center_x = 8 + int(np.random.uniform(-2, 2))
    center_y = 8 + int(np.random.uniform(-2, 2))
    radius_x = 5 + int(np.random.uniform(-1, 1))
    radius_y = 5 + int(np.random.uniform(-1, 1))
    orientation = np.random.uniform(-10, 10)  # 度数法で-10°~+10°に変更
    
    # 回転なしで楕円を生成
    rr, cc = draw.ellipse(center_y, center_x, radius_y, radius_x, shape=img.shape)
    img[rr, cc] = 1.0
    
    # 画像を回転（reshape -> resizeに修正）
    img = rotate(img, orientation, resize=False, order=0, mode='constant', cval=0)
    img = (img > 0.5).astype(np.float32)  # 二値化
    return img

def generate_anomaly():
    """微小な揺らぎを持つ長方形を生成"""
    img = np.zeros((16, 16))
    x_start = 4 + int(np.random.uniform(-2, 2))
    x_end = 12 + int(np.random.uniform(-2, 2))
    y_start = 4 + int(np.random.uniform(-2, 2))
    y_end = 12 + int(np.random.uniform(-2, 2))
    x_min = int(np.floor(x_start))
    x_max = int(np.ceil(x_end))
    y_min = int(np.floor(y_start))
    y_max = int(np.ceil(y_end))
    img[y_min:y_max, x_min:x_max] = 1.0
    angle = np.random.uniform(-10, 10)
    # 画像を回転（reshape -> resizeに修正）
    img = rotate(img, angle, resize=False, order=0, mode='constant', cval=0)
    img = (img > 0.5).astype(np.float32)  # 二値化
    return img

# -------------------------------
# データ生成
# -------------------------------
# 訓練データ（正常）
num_normal_train = 1000
X_train_normal = np.array([generate_normal() for _ in range(num_normal_train)])
X_train_normal = X_train_normal.reshape(-1, 16, 16, 1)

# テストデータ（正常 + 異常）
num_normal_test = 500
num_anomaly_test = 500
X_test_normal = np.array([generate_normal() for _ in range(num_normal_test)])
X_test_anomaly = np.array([generate_anomaly() for _ in range(num_anomaly_test)])
X_test_normal = X_test_normal.reshape(-1, 16, 16, 1)
X_test_anomaly = X_test_anomaly.reshape(-1, 16, 16, 1)

# -------------------------------
# 例画像の表示
# -------------------------------
plt.figure(figsize=(10, 5))
for i in range(4):
    plt.subplot(2, 4, i+1)
    plt.imshow(X_train_normal[i].reshape(16, 16), cmap='gray')
    plt.title('Normal')
    plt.axis('off')
for i in range(4):
    plt.subplot(2, 4, i+5)
    plt.imshow(X_test_anomaly[i].reshape(16, 16), cmap='gray')
    plt.title('Anomaly')
    plt.axis('off')
plt.suptitle('Example Images (Normal vs Anomaly)', fontsize=14)
plt.tight_layout()
plt.show()

```

QEU:FOUNDER ： “ここまでがテスト、学習用画像群の準備用のコードです。それらの画像に対して、若干の**「歪み」**を入れています。”

![imageANC0-1-5](/2025-06-25-QEUR23_AENC0/imageANC0-1-5.jpg) 

C部長： “シフト、回転、サイズを与えたことにより、形状が少し変わっていますね。ともあれ、正常状態が中実円形であるとし、異常状態を四角形としています。”

QEU:FOUNDER ： “次に行きましょう。いよいよAUTOENCODERモデルの構築です。”

```python
# -------------------------------
# 2D CNN オートエンコーダーの構築
# -------------------------------
def build_cnn_autoencoder(input_shape):
    model = models.Sequential()

    # Encoder
    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))
    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))
    model.add(layers.Conv2D(16, (3, 3), padding='same', activation='relu'))
    model.add(layers.MaxPooling2D(pool_size=(2, 2), padding='same'))

    # Decoder
    model.add(layers.Conv2D(16, (3, 3), padding='same', activation='relu'))
    model.add(layers.UpSampling2D(size=(2, 2)))
    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))
    model.add(layers.UpSampling2D(size=(2, 2)))
    model.add(layers.Conv2D(1, (3, 3), padding='same', activation='linear'))

    model.compile(optimizer='adam', loss='mse')
    return model

input_shape = (16, 16, 1)
model = build_cnn_autoencoder(input_shape)

# -------------------------------
# 学習と損失の可視化
# -------------------------------
history = model.fit(X_train_normal, X_train_normal,
                    epochs=50, batch_size=32, validation_split=0.1)

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.grid(True)
plt.show()

```

QEU:FOUNDER ： “こんなに簡単なモデル設計でも、画像（2次元データ）のAUTOENCODERが出来るんだ、ほんとKerasは便利だねえ・・・。”

![imageANC0-1-6](/2025-06-25-QEUR23_AENC0/imageANC0-1-6.jpg) 

D先生 ： “モデルの学習は、うまく収束「は」、しています。あの・・・。これは、どんな原理でしたっけ？”

![imageANC0-1-7](/2025-06-25-QEUR23_AENC0/imageANC0-1-7.jpg) 

D先生： “これが、あのAUTOENCODERのモデル設計なのか・・・。INPUTとOUTPUTが同じサイズになるんですね。つまり、今回の場合には画像がインプットとなり、アウトプットも同じサイズの画像です。 “

QEU:FOUNDER ： “それでは、最初のアウトプットをやりましょう。**三種の画像**を比較します。”

```python
# -------------------------------
# 再構成誤差による異常検知
# -------------------------------
# 訓練データの再構成誤差
reconstructed_train = model.predict(X_train_normal)
mse_train = np.mean(np.power(X_train_normal - reconstructed_train, 2), axis=(1, 2, 3))
threshold = np.percentile(mse_train, 95)  # 95%の正常データを基準

# テストデータの再構成誤差
reconstructed_normal = model.predict(X_test_normal)
mse_normal = np.mean(np.power(X_test_normal - reconstructed_normal, 2), axis=(1, 2, 3))

reconstructed_anomaly = model.predict(X_test_anomaly)
mse_anomaly = np.mean(np.power(X_test_anomaly - reconstructed_anomaly, 2), axis=(1, 2, 3))

# 異常判定
pred_normal = (mse_normal > threshold)
pred_anomaly = (mse_anomaly > threshold)
print(pred_normal)

# -------------------------------
# 異常画像・再構成画像・二乗誤差画像の比較表示
# -------------------------------
# 表示する画像数を設定
num_display = 4

# 二乗誤差の計算
squared_error = (X_test_anomaly - reconstructed_anomaly) ** 2

plt.figure(figsize=(15, 10))
plt.suptitle('Anomaly Images vs Reconstructed Images vs Squared Error', fontsize=16)

for i in range(num_display):
    # 元の異常画像
    plt.subplot(3, num_display, i+1)
    plt.imshow(X_test_anomaly[i].reshape(16, 16), cmap='gray')
    plt.title(f'Original Anomaly\nSample {i+1}')
    plt.axis('off')
    
    # 再構成された異常画像
    plt.subplot(3, num_display, i+1+num_display)
    plt.imshow(reconstructed_anomaly[i].reshape(16, 16), cmap='gray')
    plt.title(f'Reconstructed\nSample {i+1}')
    plt.axis('off')
    
    # 二乗誤差画像（ヒートマップで表示）
    plt.subplot(3, num_display, i+1+2*num_display)
    plt.imshow(squared_error[i].reshape(16, 16), cmap='hot')
    plt.title(f'Squared Error\nSample {i+1}')
    plt.colorbar(fraction=0.046, pad=0.04)
    plt.axis('off')

plt.tight_layout()
plt.subplots_adjust(top=0.95)
plt.show()

```

QEU:FOUNDER ： “この学習したモデルで予測した画像を見ると、AUTOENCODERの考え方が、一気にわかりやすくなります。このモデルは、正常（円形）画像群をインプットして学習しています。そのモデルに異常（四角形）画像群を入力した予測結果が、真ん中の行の画像群です。下の行は、**上の画像と真ん中の画像の差異**です。”

![imageANC0-1-8](/2025-06-25-QEUR23_AENC0/imageANC0-1-8.jpg) 

C部長： “正常は円形、異常は四角形です。そうすると、多くの場合には角部が「差異」になります。確かに、下の行の画像は、差異の大きさの分布を表現しています。”

![imageANC0-1-9](/2025-06-25-QEUR23_AENC0/imageANC0-1-9.jpg) 

D先生 ： “AUTOENCODERを定性的に理解するには、その親戚にあたる「今はやりの」STABLE DIFFUSIONが参考になります。AUTOENCODERもSTABLE DIFFUSIONも、DECODERの中に大量の学習した画像を記憶しています。その記憶を呼び出すのが、AUTOENCODERの場合にはENCODERによって圧縮された特徴量ベクトルであり、STABLE DIFFUSIONの場合は、言語情報です。”

![imageANC0-1-10](/2025-06-25-QEUR23_AENC0/imageANC0-1-10.jpg) 

QEU:FOUNDER ： “だから、AUTOENCODERで外観検査をする場合には、検査画像と生成画像の差異をとるんです。”

C部長： “ほう。いいじゃないですか・・・。このやり方であれば、わが社の頭痛の種である黒点やしみなどの細かな欠陥を検出できそうです。”

D先生 ： “本当にそんな精密な検査ができると思う？さっきのグラフの画像の質を見ればわかるでしょう。”

QEU:FOUNDER ： “それが、小生が長い間AUTOENCODERに手が伸びなかった理由です。そんなに良い画像が出来るわけがない。もちろん、モデルとリソースがSTABLE DIFFUSION並みにリッチになれば、そのようなことができるかもしれません。さて、いよいよ最後の性能評価のステップに行ってみましょう。”

```python
# ---
# 混同行列の作成
y_true = [0]*len(X_test_normal) + [1]*len(X_test_anomaly)
y_pred = list(pred_normal.astype(int)) + list(pred_anomaly.astype(int))
conf_matrix = confusion_matrix(y_true, y_pred)

# -------------------------------
# 混同行列の表示
# -------------------------------
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=['Predicted Normal', 'Predicted Anomaly'],
            yticklabels=['Actual Normal', 'Actual Anomaly'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

print(f"Threshold: {threshold:.6f}")
print(f"True Positives (TP): {conf_matrix[1, 1]}")
print(f"False Positives (FP): {conf_matrix[0, 1]}")
print(f"False Negatives (FN): {conf_matrix[1, 0]}")
print(f"True Negatives (TN): {conf_matrix[0, 0]}")

```

D先生 ： “まあ、そこそこの検出性能が出ています。でもねえ・・・。”

![imageANC0-1-11](/2025-06-25-QEUR23_AENC0/imageANC0-1-11.jpg) 

QEU:FOUNDER ： “小生が、MT法やAUTOENCODERが嫌いな、もう一つの理由は、**判定に「しきい値（Threshold）がある」こと**なんですよ。検出不良でドツボにはまると、しきい値をひたすらいじるだけになりそうなのですよ。”

C部長： “今回、AUTOENCODERを使って検査の実験をするとして、MT法を使うんですか？”

![imageANC0-1-12](/2025-06-25-QEUR23_AENC0/imageANC0-1-12.jpg) 

QEU:FOUNDER ： “例えば、NSOART法で画像を圧縮したとしても検査対象の画素数が多すぎます。もし、MT法になると大変な学習情報が必要です。最低、ピクセル数の3倍ぐらいかな・・・。”

C部長： “ゲッ・・・。”

QEU:FOUNDER ： “用意できる（正常品）画像は、せいぜい100枚程度でしょう。ここまでの（リソース）制限の中で、どこまでのことがAUTOENCODER技術の枠組みでできるのか・・・。”

D先生 ： “いづれにしろ、使える技術の選択肢が増えるのはいいことです。”



## ～ まとめ ～

### ・・・ もうすぐ、未来がだいたい見えるでしょう ・・・

QEU:FOUNDER ： “ホント・・・。この件はねえ・・・。なぜ、こういうのが人気が出て・・・。”

[![MOVIE1](http://img.youtube.com/vi/Dk1ALgdXaDY/0.jpg)](http://www.youtube.com/watch?v=Dk1ALgdXaDY "「イスラエル支援デモ」の問題点とキリストの幕屋についての若干の補足")

D先生： “こういうのが、人気が下がるのか？私には、**「どっちもどっち」**としか思わないが・・・。”

![imageANC0-1-13](/2025-06-25-QEUR23_AENC0/imageANC0-1-13.jpg) 

D先生： “**「レベルが下がった」**のでしょうか・・・。”

[![MOVIE2](http://img.youtube.com/vi/7scn0B6cTqE/0.jpg)](http://www.youtube.com/watch?v=7scn0B6cTqE "【激ヤバ！】政策がスピオンリーで受かる都議選！全てはアレで決まる！【菅野完】切り抜き")

QEU:FOUNDER ： “ぶっちゃけ、そうじゃないの？悪いのは、オッサンどもで・・・。”

![imageANC0-1-14](/2025-06-25-QEUR23_AENC0/imageANC0-1-14.jpg) 

D先生： “支持政党の構成表を見ると、「何が起こった」か、だいたいのところは分かります。あそこの票があそこに流れたわけね・・・。”

![imageANC0-1-15](/2025-06-25-QEUR23_AENC0/imageANC0-1-15.jpg) 

QEU:FOUNDER ： “若い人は、とても賢いのだが、影響力がないんだよ。”

