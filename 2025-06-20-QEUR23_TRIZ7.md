---
title: QEUR23_TRIZ7 - Tavilyã‚’ä½¿ã£ãŸèª²é¡Œè§£æ±º(è¨€èªå¤‰æ›´NO2-çŸ›ç›¾æ¤œå‡ºã¾ã§)
date: 2025-06-20
tags: ["QEUã‚·ã‚¹ãƒ†ãƒ ", "ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚¹", "Pythonè¨€èª", "Unsloth", "LLM", "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", "BONSAI", "LangGraph"]
excerpt: ã‚ãŸã‚‰ã—ã„LLMã®å­¦ç¿’ä½“ç³»ã‚’ç¢ºç«‹ã™ã‚‹
---

## QEUR23_TRIZ7 - Tavilyã‚’ä½¿ã£ãŸèª²é¡Œè§£æ±º(è¨€èªå¤‰æ›´NO2-çŸ›ç›¾æ¤œå‡ºã¾ã§)

## ï½ è¤‡é›‘ã«ãªã£ãŸå•é¡Œã‚’è§£ãã»ã©ãï¼ ï½

QEU:FOUNDERï¼ˆè¨­å®šå¹´é½¢65æ­³ï¼‰ ï¼š â€œTRIZãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’è¦‹ã‚Œã°ã‚ã‹ã‚‹ã‚ˆã†ã«ã€1ã¤ã®çŸ›ç›¾ã«ã¯è¤‡æ•°ã®ç™ºæ˜åŸå‰‡ãŒå¯¾å¿œã—ã¾ã™ã€‚ä»Šå¾Œã¯Eèªã‚‚åŠ ã‚ã‚‹ã®ã§ã•ã‚‰ã«çŸ›ç›¾ã¯è¤‡é›‘åŒ–ã™ã‚‹ã§ã—ã‚‡ã†ã€‚ãã‚Œãªã‚‰ãŒã€**ã‚ˆã‚Šå¤šãã®çŸ›ç›¾ã«å½“ã¦ã¯ã¾ã‚‹ç™ºæ˜åŸå‰‡(40é …ç›®)ã ã‘ã‚’ä½¿ã£ã¦ã€ç™ºæ˜ã‚’ç«‹æ¡ˆã™ã‚Œã°ã‚ˆã„**ã¨æ€ã‚ãªã„ï¼Ÿâ€

![imageTRIZ0-8-1](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-1.jpg) 

Då…ˆç”Ÿï¼ˆè¨­å®šå¹´é½¢65æ­³ï¼‰ï¼š â€œå¤šæ§˜ãªæƒ…å ±ã«å…±é€šã™ã‚‹äº‹é …ã«å¯¾ç­–ã™ã‚‹ã‚ã‘ã§ã™ã€‚ãã‚Œã¯**ã€Œãƒ­ãƒã‚¹ãƒˆãªç™ºæ˜ã€**ã§ã™ã­ï¼ˆç¬‘ï¼‰ã€‚ â€œ

![imageTRIZ0-8-2](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-2.jpg) 

QEU:FOUNDER ï¼š â€œãã†ã§ã™ã€‚ã‚‚ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã®æ ¹å¹¹ãã®ã‚‚ã®ãŒãƒ­ãƒã‚¹ãƒˆã«ãªã‚Œã°ã€ã¹ã¤ã«**æè‘‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­è¨ˆã§ãƒãƒãƒãƒã—ãŸãƒ­ãƒã‚¹ãƒˆåŒ–ã‚’ã™ã‚‹ã“ã¨ã‚‚ã„ã‚‰ãªããªã‚‹**ã‚“ã§ã™ã‚ˆãƒ»ãƒ»ãƒ»ï¼ˆç¬‘ï¼‰ã€‚ã˜ã‚ƒã‚ã€ä»Šå›ã¯Eèªã§ã€å¤šæ§˜åŒ–ã‚’ã‚„ã‚Šã¾ã™ã€‚ãã‚Œã§ã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’æ™’ã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯å‰å›ã¨ã»ã¨ã‚“ã©åŒã˜ã§ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰ãˆã¦Eèªã®æƒ…å ±ã‚’é‡ç‚¹çš„ã«åé›†ã™ã‚‹ã“ã¨ã‚’é™¤ã‘ã°ã­ã€‚â€

```python
# ---
import os
import re
from langgraph.graph import END, StateGraph
from typing import Dict, List, TypedDict
import pandas as pd
from openai import OpenAI
from langchain_tavily import TavilySearch
import json
from difflib import SequenceMatcher
import logging
import time
from bs4 import BeautifulSoup  # HTMLè§£æç”¨
import html  # HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—è§£é™¤ç”¨

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Tavilyãƒ„ãƒ¼ãƒ«è¨­å®š ---
internet_search = TavilySearch(
    api_key=os.environ['TAVILY_API_KEY'],
    max_results=5,
    include_raw_content=True,  # ç”Ÿã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
    search_depth="advanced"    # è©³ç´°æ¤œç´¢ã‚’æœ‰åŠ¹åŒ–
)

# --- OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š ---
client_chat = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
)
client_reasoner = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com",
)

# --- HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º ---
def extract_text_from_html(html_content: str) -> str:
    """HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º"""
    try:
        # HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—è§£é™¤
        decoded_content = html.unescape(html_content)
        soup = BeautifulSoup(decoded_content, 'html.parser')
        
        # ä¸è¦ãªè¦ç´ ã‚’é™¤å»
        for element in soup(['script', 'style', 'header', 'footer', 'nav', 'aside', 'form']):
            element.decompose()
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã—ã¦æ•´å½¢
        text = soup.get_text()
        text = re.sub(r'\n\n', '\n', text)  # é€£ç¶šã™ã‚‹æ”¹è¡Œã‚’å‰Šé™¤
        text = re.sub(r'\s+', ' ', text)  # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’å‰Šé™¤
        text = re.sub(r'\[\d+\]', '', text)  # [1]ã®ã‚ˆã†ãªå¼•ç”¨ãƒãƒ¼ã‚¯ã‚’å‰Šé™¤
        return text.strip()
    except Exception as e:
        logging.error(f"HTMLè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
        return html_content  # å¤±æ•—æ™‚ã¯å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿”ã™

# --- é‡è¤‡é™¤å»é–¢æ•°ï¼ˆURLå¯¾å¿œç‰ˆï¼‰---
def remove_duplicates(items: List[dict], similarity_threshold=0.3) -> List[dict]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã¨URLã‚’çµ„ã¿åˆã‚ã›ã¦é‡è¤‡ã‚’é™¤å»
    å…¥åŠ›: [{"text": "å†…å®¹", "url": "URL"}, ...]
    å‡ºåŠ›: é‡è¤‡é™¤å»å¾Œã®ãƒªã‚¹ãƒˆ
    """
    unique_items = []
    for item in items:
        is_duplicate = False
        text = item["text"]
        url = item["url"]
        
        # åŒã˜URLã®å ´åˆã¯å®Œå…¨é‡è¤‡ã¨ã¿ãªã™
        for unique in unique_items:
            if url == unique["url"]:
                is_duplicate = True
                break
                
        # ç•°ãªã‚‹URLã§ã‚‚å†…å®¹ãŒéå¸¸ã«ä¼¼ã¦ã„ã‚‹å ´åˆ
        if not is_duplicate:
            for unique in unique_items:
                ratio = SequenceMatcher(None, text, unique["text"]).ratio()
                if ratio > similarity_threshold:
                    is_duplicate = True
                    break
                    
        if not is_duplicate:
            unique_items.append(item)
            
    return unique_items

# --- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹è¦ç´„é–¢æ•°ï¼ˆæ‹¡å¼µç‰ˆï¼‰---
def summarize_background(text: str, max_chars=2000) -> str:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦èƒŒæ™¯æƒ…å ±ã‚’è¦ç´„ã—æ–‡å­—æ•°ã‚’æ‹¡å……"""
    # ç°¡ä½“å­—ã¨ç¹ä½“å­—ä¸¡æ–¹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹
    keywords = ["é¢¨", "ã‚³ã‚¹ãƒˆ", "é¨’éŸ³", "ç”Ÿæ…‹ç³»", "å¸‚è¡—", "è¨­ç½®", "é›»æ°—", "å·¥å­¦", "è‡ªç„¶", "ç§‘å­¦", "æŠ€è¡“", "ç™ºé›»", "å†ç”Ÿå¯èƒ½", "ã‚¨ãƒãƒ«ã‚®ãƒ¼",
                "è‡ªæ²»ä½“", "é™éŸ³", "é¢¨è»Š", "æ¬§ç±³", "ä¸­å›½", "æ±å—ã‚¢ã‚¸ã‚¢", "æ±ã‚¢ã‚¸ã‚¢", "å¤ªå¹³æ´‹", "å¤§è¥¿æ´‹", "è“„é›»", "ã‚¹ãƒãƒ¼ãƒˆ", "å°å…¥", "åŠ¹ç‡",
                "ãƒ‡ãƒ³ãƒãƒ¼ã‚¯", "ãƒ•ãƒ©ãƒ³ã‚¹", "ã‚¢ãƒ¡ãƒªã‚«", "ã‚¤ã‚®ãƒªã‚¹", "ãƒ‰ã‚¤ãƒ„", "ã‚¹ã‚¦ã‚§ãƒ¼ãƒ‡ãƒ³", "æ—¥æœ¬", "éŸ“å›½", "åˆ¶å¾¡", "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰", "ã‚·ã‚¹ãƒ†ãƒ ",
                "ã‚¿ãƒ¼ãƒ“ãƒ³", "ç¾½æ ¹", "æ”¹å–„", "å¾ªç’°", "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯", "é‡‘å±", "ãƒ¡ã‚¿ãƒ«",
                "cost", "noise", "reduction", "innovation", "breakthrough", "wind", "energy", "technolo-gy", "China", "EU", 
                "USA", "sound", "bird", "Denmark", "battery", "AI", "intelligent", "efficiency", "net-work", "hybrid", 
                "China", "power", "magnet", "generation", "electric", "system", "urban", "city", "moun-tain", "ocean",
                "ecosystem", "installation", "electricity", "renewable", "vertical axis", "government", "turbine",
                "engineering", "nature", "smart", "control", "metal", "France", "Germany", "Denmark",
                "small-scale", "storage", "circulation", "offshore", "improvement", "solution", "feed-back",
                "é£", "æˆæœ¬", "èƒ½é‡", "å™ªéŸ³", "å™ªå£°", "ç”Ÿæ€", "ç”Ÿæ…‹", "é¸Ÿ", "é³¥", "æ”¹è¿›", "æ”¹é€²", 
                "å¸‚åŒº", "è®¾ç½®", "è¨­ç½®", "æŠ€æœ¯", "æŠ€è¡“", "å‘ç”µ", "ç™¼é›»", "æ¸¦è¼ª", "æ¶¡è½®", 
                "åœ°æ–¹", "æ”¿åºœ", "è‡ªæ²»ä½“", "é™éŸ³", "é£æœº", "é¢¨æ©Ÿ", "æ¬§ç¾", "æ­ç¾", 
                "ä¸­å›½", "ä¸­åœ‹", "ä¸œå—äºš", "æ±å—äº", "å‚¨èƒ½", "å„²èƒ½", "æ™ºèƒ½", "æ™ºæ…§", 
                "å¼•å…¥", "æ•ˆç‡", "æ³•å›½", "æ³•åœ‹", "ç¾å›½", "ç¾åœ‹", "è‹±å›½", "è‹±åœ‹", 
                "å¾·å›½", "å¾·åœ‹", "ç‘å…¸", "æ—¥æœ¬", "éŸ©å›½", "éŸ“åœ‹", "æ§åˆ¶", "ç³»ç»Ÿ", "ç³»çµ±", "è‡ªåŠ¨", "è‡ªå‹•",
                ]
    
    # æ–‡ç« ã‚’æ–‡å˜ä½ã§åˆ†å‰²
    sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ.!?\n])', text)
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€æ–‡ã‚’æŠ½å‡º
    relevant = [s for s in sentences if any(kw in s for kw in keywords)]
    
    # é–¢é€£æ–‡ãŒå°‘ãªã„å ´åˆã¯è¿½åŠ å‡¦ç†
    if len(relevant) < 10 or len(''.join(relevant)) < 500:
        # æœ€é•·ã®æ–‡ã‚’è¿½åŠ 
        longest = sorted(sentences, key=len, reverse=True)[:10]
        relevant.extend(longest)
    
    summarized = ' '.join(relevant)
    
    # æ–‡å­—æ•°ã‚’èª¿æ•´ï¼ˆä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯é–¢é€£æƒ…å ±ã‚’è¿½åŠ ï¼‰
    if len(summarized) < max_chars:
        # è¿½åŠ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
        prompt = f"""
        Expand the following text related to wind power to {max_chars - len(summarized)} characters in Japanese.
        Include:
        - Latest technology trends in wind power
        - International cases (Europe, America, Asia)
        - Cost reduction methods
        - Environmental impact countermeasures
        
        Original text:
        {summarized[:3000]}
        """
        try:
            response = client_reasoner.chat.completions.create(
                model="deepseek-reasoner",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=1000
            )
            additional = response.choices[0].message.content
            summarized += "\n" + additional
        except Exception as e:
            logging.error(f"è¿½åŠ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            # å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            summarized += ("è­¦å‘Š(WARNING) - è¿½åŠ æŠ€è¡“æƒ…å ±: é¢¨åŠ›ç™ºé›»æŠ€è¡“ã¯è¿‘å¹´æ€¥é€Ÿã«ç™ºå±•ã—ã¦ãŠã‚Šã€ç‰¹ã«å°å‹å‚ç›´è»¸é¢¨è»Šã®åŠ¹ç‡æ”¹å–„ã¨é¨’éŸ³ä½æ¸›æŠ€è¡“ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã¾ã™ã€‚"
                          "æ¬§å·ã®éƒ½å¸‚ã§ã¯è¨­ç½®äº‹ä¾‹ãŒå¢—åŠ ã—ã¦ãŠã‚Šã€ãƒ‰ã‚¤ãƒ„ã®ãƒ•ãƒ©ã‚¤ãƒ–ãƒ«ã‚¯å¸‚ã§ã¯å»ºç¯‰ä¸€ä½“å‹ã‚·ã‚¹ãƒ†ãƒ ã®è©¦é¨“ãŒè¡Œã‚ã‚Œã€"
                          "å¹´é–“ç™ºé›»é‡18MWhã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚æ—¥æœ¬ã®é•·å´çœŒã§ã¯æµ®ä½“å¼æ´‹ä¸Šé¢¨åŠ›ã®å®Ÿè¨¼å®Ÿé¨“ãŒé€²è¡Œä¸­ã§ã™ã€‚")
    
    return summarized[:max_chars]

# --- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¢æ•°ï¼ˆæ”¹é€ ç‰ˆï¼‰---
def filter_inappropriate_content(text: str) -> str:
    """ä¸é©åˆ‡ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å«ã‚€æ–‡ã‚’å®Œå…¨ã«å‰Šé™¤ã™ã‚‹"""
    # ç°¡ä½“å­—ã¨ç¹ä½“å­—ä¸¡æ–¹ã®ä¸é©åˆ‡èªã‚’å«ã‚€
    inappropriate_words = [
        "æš´åŠ›", "æ†æ‚ª", "å·®åˆ¥", "ãƒãƒ«ãƒ", "ã‚¢ãƒ€ãƒ«ãƒˆ", "ç’°å¢ƒç ´å£Š", "å…¬å®³", "åŒ–å­¦", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", "æ—¥æœ¬èª",
        "æœ‰å®³ç‰©è³ª", "çµ¶æ»…å±æƒ§ç¨®", "ç’°å¢ƒãƒ›ãƒ«ãƒ¢ãƒ³", "ç”Ÿæ…‹ç³»ç ´å£Š", "æ”¾å°„èƒ½", "æ´¥æ³¢", "æˆ¦äº‰", "è»äº‹", "ç´›äº‰",
        "KEYWORD", "SITEMAP", "http", "email", "e-mail", 
        "violence", "hate", "discrimination", "porn", "adult", "environmental destruction",
        "pollution", "hazardous substances", "endangered species", "radiation", "war",
        "military", "conflict", "keyword", "sitemap", "advertisement",
        "top page", "reference", "related article", "shopping", "table of contents",
        "ç›®æ¬¡", "åºƒå‘Š", "ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸", "ã‚µã‚¤ãƒˆãƒãƒƒãƒ—", "ãƒ‹ãƒ¥ãƒ¼ã‚¹", "å‚è€ƒæ–‡çŒ®", "é–¢é€£è¨˜äº‹", "ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°",
        "æ†æ¨", "ä»‡æ¨", "æ­§è§†", "æ­§è¦–", "è‰²æƒ…", "æˆäºº", "æˆäººå†…å®¹", 
        "ç¯å¢ƒæ±¡æŸ“", "ç’°å¢ƒæ±¡æŸ“", "å…¬å®³", "åŒ–å­¦æ±¡æŸ“", "åŒ–å­¸æ±¡æŸ“", 
        "æœ‰å®³ç‰©è´¨", "æœ‰å®³ç‰©è³ª", "æ¿’å±ç‰©ç§", "ç€•å±ç‰©ç¨®", "ç¯å¢ƒæ¿€ç´ ", "ç’°å¢ƒæ¿€ç´ ", 
        "ç”Ÿæ€ç³»ç»Ÿç ´å", "ç”Ÿæ…‹ç³»çµ±ç ´å£", "è¾å°„", "è¼»å°„", "æµ·å•¸", "æµ·å˜¯", "æˆ˜äº‰", "æˆ°çˆ­", "å†›äº‹", "è»äº‹", 
        "å†²çª", "è¡çª", "å…³é”®è¯", "é—œéµè©", "å…³é”®è¯",  "å‚è€ƒæ–‡çŒ®", "åƒè€ƒæ–‡ç»", 
        "é‚®ç®±", "ç›®å½•", "ç›®éŒ„", "å¹¿å‘Š", "å»£å‘Š", "é¦–é¡µ", "é¦–é ", "ç½‘ç«™", "ç¶²ç«™", "æ–°é—»", "æ–°è","ç›¸å…³æ–‡ç« ", "ç›¸é—œæ–‡ç« ", "è´­ç‰©", "è³¼ç‰©", "ç°¡ä½“", "ç¹ä½“"
    ]
    
    # æ–‡ã«åˆ†å‰²
    sentences = re.split(r'(?<=[ã€‚ï¼ï¼Ÿ.!?\n])', text)
    
    # ä¸é©åˆ‡ãªå˜èªã‚’å«ã¾ãªã„æ–‡ã®ã¿ã‚’ä¿æŒ
    filtered_sentences = []
    for sentence in sentences:
        # ä¸é©åˆ‡ãªå˜èªãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if not any(word in sentence for word in inappropriate_words):
            filtered_sentences.append(sentence)
    
    return ' '.join(filtered_sentences)

```

QEU:FOUNDER ï¼š â€œ3ã‹å›½èªã®ã‚µãƒãƒ¼ãƒˆã«ãªã‚‹ã®ã§ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒä¸€æ°—ã«å¢—ãˆã¡ã‚ƒã„ã¾ã—ãŸã­ã€‚ãã‚Œä»¥å¤–ã¯ã»ã¨ã‚“ã©å¤‰åŒ–ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚â€

Då…ˆç”Ÿï¼š â€œã‚‚ã†å°‘ã—ã‚³ãƒ¼ãƒ‰ã‚’å‰Šã£ã¦ã¯ï¼Ÿâ€

QEU:FOUNDER ï¼š â€œTRIZ_FEATURESã ã‘ã¯ã€é•·ã„ã®ã§æ¶ˆã—ã¦ã—ã¾ã„ã¾ã—ã‚‡ã†ã€‚ç¿»è¨³ã™ã¹ãç´°ã‹ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã€ã‚ã¡ã“ã¡ã«ã°ã‚‰ã‘ã¦ã„ã‚‹ã‚“ã§ã€æ€ã£ãŸã‚ˆã‚Šã‚‚ï¼ˆã‚³ãƒ¼ãƒ‰ã®ï¼‰çœç•¥ãŒå‡ºæ¥ãªã„ã‚“ã§ã™ã€‚â€

```python
# --- çŠ¶æ…‹å®šç¾© ---
class AnalysisState(TypedDict):
    input: str
    tavily_input: str
    problems: List[str]
    goals: List[str]
    contradictions: List[Dict[str, str]]
    background: Dict[str, List[dict]]  # å¤‰æ›´: å„ã‚¢ã‚¤ãƒ†ãƒ ã¯{"text": "å†…å®¹", "url": "URL"}å½¢å¼
    consolidated_background: Dict[str, str]

# TRIZ 39çŸ›ç›¾ç‰¹å¾´
#TRIZ_FEATURES = """
#çœç•¥ã—ã¾ã™

# --- èƒŒæ™¯æƒ…å ±ç”Ÿæˆï¼ˆè‹±èªæ¤œç´¢ç‰ˆï¼‰---
def generate_background(state: AnalysisState) -> AnalysisState:
    start_time = time.time()
    print("ğŸ” [ã‚¹ãƒ†ãƒƒãƒ—1/4] èƒŒæ™¯æƒ…å ±ã®ç”Ÿæˆã‚’é–‹å§‹...")
    logging.info("èƒŒæ™¯æƒ…å ±ã®ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™")
    user_input = state['tavily_input']

    # è‹±èªæ¤œç´¢ã‚¯ã‚¨ãƒªã«å¤‰æ›´
    categories = {
        "customer": f"{user_input} citizen concerns OR public opinion OR wind energy citizen",
        "organization": f"{user_input} implementation cases OR policies OR local government OR wind energy",
        "technology": f"{user_input} vertical axis wind turbine OR quiet OR small-scale OR energy storage technology",
        "cost": f"{user_input} cost OR investment OR maintenance cost OR efficiency",
        "legal": f"{user_input} environmental assessment OR regulations OR legal OR control OR sys-tem"
    }

    background = {
        "customer": [],
        "organization": [],
        "cost": [],
        "technology": [],
        "legal": []
    }

    for category, query in categories.items():
        logging.info(f"æ¤œç´¢ä¸­: {category} - {query}")
        try:
            print(f"  - {category}ã‚«ãƒ†ã‚´ãƒªã®æ¤œç´¢å®Ÿè¡Œ: {query[:80]}...")
            search_result = internet_search.invoke({"query": query})

            items = []  # {"text": "å†…å®¹", "url": "URL"}å½¢å¼ã®ãƒªã‚¹ãƒˆ
            for res in search_result["results"][:5]:
                # URLã‚’å–å¾—
                url = res.get("url", "URLä¸æ˜")

                # ç”ŸHTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
                raw_html = res.get("raw_content", "")
                if raw_html:
                    content = extract_text_from_html(raw_html)
                else:
                    content = res.get("content", "")

                # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨è¦ç´„
                filtered = filter_inappropriate_content(content)
                summarized = summarize_background(filtered, 2000)  # 2000æ–‡å­—ã¾ã§æ‹¡å……

                items.append({
                    "text": summarized,
                    "url": url
                })

            # URLã¨å†…å®¹ã‚’çµ„ã¿åˆã‚ã›ãŸé‡è¤‡é™¤å»
            unique_items = remove_duplicates(items)

            # æ–‡å­—æ•°ä¸è¶³ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’è£œå®Œ
            final_items = []
            for item in unique_items:
                if len(item["text"]) < 1500:
                    try:
                        prompt = f"Please expand the following text from the perspective of wind power gen-eration, adding technical details to make it 1200 to 1500 words:\n{item['text']}"
                        response = client_reasoner.chat.completions.create(
                            model="deepseek-reasoner",
                            messages=[{"role": "user", "content": prompt}],
                            temperature=0.3,
                            max_tokens=1500
                        )
                        expanded = response.choices[0].message.content
                        item["text"] = expanded[:1000]
                    except:
                        item["text"] += " " + ("WARNING - Details: Wind power generation technology has developed rapidly in recent years..." * 10)[:1500-len(item["text"])]
                final_items.append(item)

            background[category] = final_items
            avg_length = sum(len(item["text"]) for item in final_items) / len(final_items)
            print(f"    âœ… çµæœ: {len(final_items)}ä»¶ â†’ å¹³å‡æ–‡å­—æ•°: {avg_length:.0f}æ–‡å­—")
            print(f"    â”” ä»£è¡¨URL: {final_items[0]['url']}")

        except Exception as e:
            logging.error(f"{category}ã®æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            background[category] = [{"text": f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}", "url": "N/A"}]
            print(f"    â— ã‚¨ãƒ©ãƒ¼: {str(e)}")

    # çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
    print("\nğŸ“Š èƒŒæ™¯æƒ…å ±ç”Ÿæˆçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:")
    for cat, items in background.items():
        print(f"  - {cat}: {len(items)}ä»¶ã®æƒ…å ±")
        if items:
            avg_length = sum(len(item["text"]) for item in items) / len(items)
            print(f"    â”œ å¹³å‡æ–‡å­—æ•°: {avg_length:.0f}æ–‡å­—")
            print(f"    â”œ URLæ•°: {len(set(item['url'] for item in items))}å€‹")
            print(f"    â”” æœ€åˆã®URL: {items[0]['url']}")

    elapsed = time.time() - start_time
    print(f"âœ… [ã‚¹ãƒ†ãƒƒãƒ—1/4] èƒŒæ™¯æƒ…å ±ç”Ÿæˆå®Œäº† ({elapsed:.2f}ç§’)")
    logging.info("èƒŒæ™¯æƒ…å ±ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
    return {**state, "background": background}

# --- èƒŒæ™¯æƒ…å ±ã®æ•´ç†ã¨è¦ç´„ï¼ˆå¼·åŒ–ç‰ˆï¼‰---
def consolidate_background(state: AnalysisState) -> AnalysisState:
    start_time = time.time()
    print("\nğŸ“š [ã‚¹ãƒ†ãƒƒãƒ—2/4] èƒŒæ™¯æƒ…å ±ã®æ•´ç†ã‚’é–‹å§‹...")
    logging.info("èƒŒæ™¯æƒ…å ±ã®æ•´ç†ã‚’é–‹å§‹ã—ã¾ã™")
    background = state['background']

    # èƒŒæ™¯æƒ…å ±ã®çµ±è¨ˆè¡¨ç¤º
    total_items = sum(len(items) for items in background.values())
    total_chars = sum(len(item["text"]) for items in background.values() for item in items)
    unique_urls = len(set(item["url"] for items in background.values() for item in items))
    print(f"  - ç·æƒ…å ±é‡: {total_items}ä»¶, ç·æ–‡å­—æ•°: {total_chars}æ–‡å­—, ãƒ¦ãƒ‹ãƒ¼ã‚¯URLæ•°: {unique_urls}")

    combined_data = ""
    for category, items in background.items():
        category_name = cat_names.get(category, category)
        combined_data += f"ã€{category_name}ã€‘\n"
        for i, item in enumerate(items, 1):
            combined_data += f"{i}. {item['text']}\n"
        combined_data += "\n"

    # é•·ã™ãã‚‹å ´åˆã¯æœ€åˆã®8000æ–‡å­—ã‚’ä½¿ç”¨
    if len(combined_data) > 8000:
        combined_data = combined_data[:8000] + "\n... (ä»¥ä¸‹çœç•¥)"

    # æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆè‹±èªæƒ…å ±ã‚’åŸºã«æ—¥æœ¬èªã§è¦ç´„ï¼‰
    prompt = f"""
    Please summarize the following background information into 5 categories in Japanese.
    Each summary should be 800-1200 characters and include:
    - Technical details, numerical data, and specific cases
    - Priority to international cases (Europe, America, Asia)
    - Core information for each category
    
    ## Important: Output in JSON format in Japanese
    
    ## Background Information:
    {combined_data}
    
    ## Output Format (JSON):
    {{
        "customer": "è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ800-1200æ–‡å­—ï¼‰",
        "organization": "è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ800-1200æ–‡å­—ï¼‰",
        "technology": "è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ800-1200æ–‡å­—ï¼‰",
        "cost": "è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ800-1200æ–‡å­—ï¼‰",
        "legal": "è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ800-1200æ–‡å­—ï¼‰"
    }}
    """

    try:
        print("  - è©³ç´°è¦ç´„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
        response = client_reasoner.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {'role': 'system', 'content': 'You are an expert who summarized each category in 1200-1500 words while maintaining technical details'},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"},
            max_tokens=2000
        )
        consolidated = json.loads(response.choices[0].message.content)

        # è¦ç´„çµæœã®æ¤œè¨¼ã¨ä¿®æ­£
        for cat, summary in consolidated.items():
            current_length = len(summary)
            if current_length < 800:
                # æ–‡å­—æ•°ãŒä¸è¶³ã™ã‚‹å ´åˆã®è£œå®Œ
                prompt = f"Please add technical details and expand the following summary to more than 800 words, including specific data and cases:\n{summary}"
                try:
                    response = client_reasoner.chat.completions.create(
                        model="deepseek-reasoner",
                        messages=[
                            {'role': 'system', 'content': 'You are an expert who summarizes technical infor-mation in Japanese based on English sources'},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.2,
                        max_tokens=2000
                    )
                    expanded = response.choices[0].message.content
                    consolidated[cat] = expanded[:2000]
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                    consolidated[cat] = summary + (" Additional information: According to the European Renewable Energy Agency report, the cost of offshore wind power in 2023..." * 5)[:2000-len(summary)]

        # è¦ç´„çµæœã®è¡¨ç¤º
        print("\nğŸ“ è¦ç´„çµæœï¼ˆæ–‡å­—æ•°ï¼‰:")
        for cat, summary in consolidated.items():
            print(f"  - {cat_names.get(cat, cat)}: {len(summary)}æ–‡å­—")

        logging.info("èƒŒæ™¯æƒ…å ±ã®æ•´ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
        elapsed = time.time() - start_time
        print(f"âœ… [ã‚¹ãƒ†ãƒƒãƒ—2/4] èƒŒæ™¯æƒ…å ±æ•´ç†å®Œäº† ({elapsed:.2f}ç§’)")
        return {**state, "consolidated_background": consolidated}

    except Exception as e:
        logging.error(f"èƒŒæ™¯æƒ…å ±ã®æ•´ç†ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print(f"    â— ã‚¨ãƒ©ãƒ¼: {str(e)}")
        consolidated = {}
        for category in background.keys():
            # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦2000æ–‡å­—ã«è¦ç´„
            combined = ' '.join(item["text"] for item in background[category])
            text = summarize_background(combined, 2000)
            consolidated[category] = text
        elapsed = time.time() - start_time
        print(f"âš ï¸ [ã‚¹ãƒ†ãƒƒãƒ—2/4] ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº† ({elapsed:.2f}ç§’)")
        return {**state, "consolidated_background": consolidated}

```

Då…ˆç”Ÿï¼š â€œã‚ã‚Œï¼Ÿãƒãƒªã‚·ãƒ¼ã‚’å¤‰ãˆã¾ã—ãŸã‹ï¼ŸèƒŒæ™¯ã®è¦ç´„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æ—¥æœ¬èªã§å›ç­”ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã—ã¦ã„ã¾ã™ã­ã€‚ â€œ

![imageTRIZ0-8-3](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-3.jpg) 

QEU:FOUNDER ï¼š â€œçµè«–ã‹ã‚‰ã„ã†ã¨ã€ï¼ˆæ–‡ç« ã®JèªåŒ–ã«ï¼‰å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚æ€ã„åˆ‡ã£ã¦ã€Jèªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã™ã‚Œã°ã‚ˆã‹ã£ãŸã‚“ã§ã™ã€‚ã“ã®éš›ã€è¡¨ç¤ºã•ã‚Œã‚‹è¨€èªã¯ã©ã†ã§ã‚‚ã„ã„ã‘ã©ã­ã€‚ãã‚Œã§ã¯ã€ã‚³ãƒ¼ãƒ‰ã®æ™’ã—ã‚’ç¶šã‘ã¾ã™ã€‚â€

```python
# --- å•é¡Œã‚’æ˜ç¢ºåŒ–ã™ã‚‹ ---
def clarify_problem(state: AnalysisState) -> AnalysisState:
    start_time = time.time()
    print("\nğŸ” [ã‚¹ãƒ†ãƒƒãƒ—3/4] å•é¡Œã®æ˜ç¢ºåŒ–ã‚’é–‹å§‹...")
    logging.info("å•é¡Œã®æ˜ç¢ºåŒ–ã‚’é–‹å§‹ã—ã¾ã™")
    background_text = ""
    consolidated = state.get('consolidated_background', {})

    # è¦ç´„ã•ã‚ŒãŸèƒŒæ™¯æƒ…å ±ã®æ§‹ç¯‰
    if consolidated:
        logging.info("è¦ç´„ã•ã‚ŒãŸèƒŒæ™¯æƒ…å ±ã‚’ä½¿ç”¨ã—ã¾ã™")
        print("  - è¦ç´„èƒŒæ™¯æƒ…å ±ã‚’ä½¿ç”¨")
        for category, summary in consolidated.items():
            category_name = cat_names.get(category, category)
            background_text += f"### {category_name}:\n- {summary}\n"
    else:
        logging.warning("è¦ç´„èƒŒæ™¯æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç”Ÿã®èƒŒæ™¯æƒ…å ±ã‚’ä½¿ç”¨ã—ã¾ã™")
        print("  âš ï¸ è¦ç´„èƒŒæ™¯ãªã—ã€‚ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
        for category, items in state["background"].items():
            category_name = cat_names.get(category, category)
            background_text += f"### {category_name}:\n"
            for item in items:
                background_text += f"- {item['text']}\n"
            background_text += "\n"

    user_input = state['input']

    # èƒŒæ™¯æƒ…å ±ã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§ç°¡ç•¥åŒ–
    simplified_background = summarize_background(background_text, 2000)

    # JSONå½¢å¼ã§å‡ºåŠ›ã‚’æŒ‡å®šï¼ˆæ—¥æœ¬èªå‡ºåŠ›ï¼‰
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒã¤èª²é¡Œã‚’å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼å°å…¥ã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã€æ˜ç¢ºåŒ–ã•ã‚ŒãŸå•é¡Œç‚¹ã¨ç›®æ¨™ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

    ## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒã¤èª²é¡Œ:
    {user_input}

    ## èƒŒæ™¯æƒ…å ±ï¼ˆç°¡æ˜“ç‰ˆï¼‰:
    {simplified_background}

    ## å‡ºåŠ›å½¢å¼ï¼ˆJSON å½¢å¼ã®ã¿ï¼‰:
    {{
    "problems": [
    "å•é¡Œ 1 ã®è©³ç´°ãªèª¬æ˜",
    "å•é¡Œ 2 ã®è©³ç´°ãªèª¬æ˜",
    "å•é¡Œ 3 ã®è©³ç´°ãªèª¬æ˜"
    ],
    "goals": [
    "ç›®æ¨™ 1 ã®è©³ç´°ãªèª¬æ˜",
    "ç›®æ¨™ 2 ã®è©³ç´°ãªèª¬æ˜",
    "ç›®æ¨™ 3 ã®è©³ç´°ãªèª¬æ˜"
    ]
    }}
    
    ## æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    
    å•é¡Œé …ç›®ã”ã¨ã« 100ï½500 èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    ç›®æ¨™é …ç›®ã”ã¨ã« 100ï½200 èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """

    logging.info("å•é¡Œæ˜ç¢ºåŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡")
    print("  - å•é¡Œåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")

    try:
        response = client_reasoner.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {'role': 'system', 'content': 'TRIZæ‰‹æ³•ã«ç‰¹åŒ–ã—ãŸAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚JSONå½¢å¼ã®æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¾ã™ã€‚'},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        # JSONã‚’ç›´æ¥è§£æ
        output = response.choices[0].message.content
        result = json.loads(output)
        problems = result.get("problems", [])
        goals = result.get("goals", [])

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å•é¡Œ/ç›®æ¨™ãŒç©ºã®å ´åˆ
        if not problems or not goals:
            logging.warning("å•é¡Œ/ç›®æ¨™ãŒç©ºã€‚ä»£æ›¿æŠ½å‡ºã‚’è©¦è¡Œ")
            print("  âš ï¸ å•é¡Œ/ç›®æ¨™ãŒç©ºã€‚ä»£æ›¿æŠ½å‡ºã‚’å®Ÿè¡Œ")
            problems, goals = extract_fallback_problems(user_input, simplified_background)

        # å•é¡Œã¨ç›®æ¨™ã®è¡¨ç¤º
        print("\nğŸ“Œ ç‰¹å®šã•ã‚ŒãŸå•é¡Œ:")
        for i, problem in enumerate(problems, 1):
            print(f"  {i}. {problem[:100]}...")

        print("\nğŸ¯ ç‰¹å®šã•ã‚ŒãŸç›®æ¨™:")
        for i, goal in enumerate(goals, 1):
            print(f"  {i}. {goal[:100]}...")

        logging.info(f"å•é¡Œã‚’{len(problems)}å€‹ã€ç›®æ¨™ã‚’{len(goals)}å€‹ç‰¹å®šã—ã¾ã—ãŸ")
        elapsed = time.time() - start_time
        print(f"âœ… [ã‚¹ãƒ†ãƒƒãƒ—3/4] å•é¡Œã®æ˜ç¢ºåŒ–ã‚’å®Œäº†ã—ã¾ã—ãŸ ({elapsed:.2f}ç§’)")
        return {**state, "problems": problems, "goals": goals}

    except json.JSONDecodeError:
        logging.error("JSONè§£æã‚¨ãƒ©ãƒ¼ã€‚ä»£æ›¿æŠ½å‡ºã‚’è©¦è¡Œ")
        print("  â— JSONè§£æã‚¨ãƒ©ãƒ¼ã€‚ä»£æ›¿æŠ½å‡ºã‚’å®Ÿè¡Œ")
        problems, goals = extract_fallback_problems(user_input, simplified_background)
        elapsed = time.time() - start_time
        print(f"âš ï¸ [ã‚¹ãƒ†ãƒƒãƒ—3/4] ä»£æ›¿æŠ½å‡ºå®Œäº† ({elapsed:.2f}ç§’)")
        return {**state, "problems": problems, "goals": goals}
    except Exception as e:
        logging.error(f"å•é¡Œã®æ˜ç¢ºåŒ–ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print(f"  â— ã‚¨ãƒ©ãƒ¼: {str(e)}")
        problems, goals = extract_fallback_problems(user_input, simplified_background)
        elapsed = time.time() - start_time
        print(f"âš ï¸ [ã‚¹ãƒ†ãƒƒãƒ—3/4] ä»£æ›¿æŠ½å‡ºå®Œäº† ({elapsed:.2f}ç§’)")
        return {**state, "problems": problems, "goals": goals}

# --- ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å•é¡ŒæŠ½å‡º ---
def extract_fallback_problems(user_input: str, background: str) -> tuple:
    """JSONå¤±æ•—æ™‚ã®ä»£æ›¿æŠ½å‡ºæ–¹æ³•"""
    logging.info("WARNING-ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ã‚ˆã‚‹å•é¡ŒæŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™")
    print("  âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å•é¡ŒæŠ½å‡ºã‚’å®Ÿè¡Œã—ã¾ã™")

    # æ–¹æ³•1: è‡ªç”±å½¢å¼å‡ºåŠ›ã‹ã‚‰æŠ½å‡º
    try:
        prompt = f"""
        æ¬¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª²é¡Œã‹ã‚‰ã€æ˜ç¢ºåŒ–ã•ã‚ŒãŸå•é¡Œã¨ç›®æ¨™ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        {user_input}

        èƒŒæ™¯æƒ…å ±:
        {background}

        å‡ºåŠ›å½¢å¼ï¼š
        ### æ˜ç¢ºåŒ–ã•ã‚ŒãŸå•é¡Œï¼š
        - [å•é¡Œ 1]
        - [å•é¡Œ 2]

        ### è¨­å®šã•ã‚ŒãŸç›®æ¨™ï¼š
        - [ç›®æ¨™ 1]
        - [ç›®æ¨™ 2]

        ## æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

        å•é¡Œé …ç›®ã”ã¨ã«100ï½500èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        ç›®æ¨™é …ç›®ã”ã¨ã«100ï½200èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        """

        response = client_reasoner.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {'role': 'system', 'content': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èª²é¡Œã¨èƒŒæ™¯æƒ…å ±ã‹ã‚‰ã€æ˜ç¢ºåŒ–ã•ã‚ŒãŸå•é¡Œã¨ç›®æ¨™ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„'},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )
        output = response.choices[0].message.content
        problems = []
        goals = []
        current_section = None

        for line in output.split('\n'):
            clean_line = line.strip()
            if "æ˜ç¢ºåŒ–ã•ã‚ŒãŸå•é¡Œ" in clean_line:
                current_section = "problems"
            elif "è¨­å®šã—ãŸç›®æ¨™" in clean_line:
                current_section = "goals"
            if clean_line.startswith(('-', 'ãƒ»', '*', 'â—')):
                content = line.strip().lstrip('-*ãƒ»â— ').strip()
                if 100 <= len(content) <= 500:  # æ–‡å­—æ•°åˆ¶é™ã‚’ç·©å’Œ
                    if current_section == "problems":
                        problems.append(content)
                    elif current_section == "goals":
                        goals.append(content)

        if problems and goals:
            return problems, goals
    except Exception:
        pass

    # æ–¹æ³•2: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‹ã‚‰ç›´æ¥æŠ½å‡º
    logging.warning("è‡ªç”±å½¢å¼æŠ½å‡ºã‚‚å¤±æ•—ã€‚ç›´æ¥æŠ½å‡ºã‚’è©¦è¡Œ")
    print("  âš ï¸ ç›´æ¥æŠ½å‡ºã‚’å®Ÿè¡Œ")
    problems = [
        "å°å‹é¢¨åŠ›ç™ºé›»ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥ã‚³ã‚¹ãƒˆãŒé«˜ã„å•é¡Œ",
        "é¢¨åŠ›ã®ä¸å®‰å®šæ€§ã«ã‚ˆã‚‹é›»åŠ›ä¾›çµ¦ã®ä¸å®‰å®šã•",
        "éƒ½å¸‚ç’°å¢ƒã§ã®é¨’éŸ³å•é¡Œã¨è¨­ç½®åˆ¶é™"
    ]
    goals = [
        "å°å‹é¢¨åŠ›ã‚·ã‚¹ãƒ†ãƒ ã®ã‚³ã‚¹ãƒˆæœ€é©åŒ–",
        "ç”Ÿæ…‹ç³»ã¸ã®å½±éŸ¿ã‚’æœ€å°é™ã«ã™ã‚‹è¨­è¨ˆ",
        "éƒ½å¸‚ç’°å¢ƒã«é©å¿œã—ãŸç™ºé›»ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™º"
    ]
    return problems, goals

```

Då…ˆç”Ÿï¼š â€œã“ã“ã¾ã§ã¯ã€å•é¡Œã®æ˜ç¢ºåŒ–ã¨ç›®æ¨™ã®è¨­å®šã®æ®µéšã«ãªã‚Šã¾ã™ã€‚ã“ã“ã§ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯Jèªã«ã—ã¦ã„ã¾ã™ã­ã€‚ç´ ç›´ã«ã€ã“ã†ã™ã‚‹ã»ã†ãŒã‚ˆã‹ã£ãŸã§ã™ã­ã€‚â€

![imageTRIZ0-8-4](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-4.jpg) 

QEU:FOUNDER ï¼š â€œã‚„ã£ã±ã‚Šã€Jèªã®å›ç­”ã‚’å¾—ãŸã„ã®ã§ã‚ã‚Œã°ã€Jèªã§è³ªå•ã™ã¹ãã ã‚ˆã­ãƒ»ãƒ»ãƒ»ï¼ˆç¬‘ï¼‰ã€‚æœ€å¾Œã®çŸ›ç›¾ã®ç”Ÿæˆã¾ã§ã„ãã¾ã—ã‚‡ã†ã€‚â€

```python
# --- çŸ›ç›¾æŠ½å‡º ---
def identify_contradictions(state: AnalysisState) -> AnalysisState:
    start_time = time.time()
    print("\nâš–ï¸ [ã‚¹ãƒ†ãƒƒãƒ—4/4] çŸ›ç›¾ã®æŠ½å‡ºã‚’é–‹å§‹...")
    logging.info("çŸ›ç›¾ã®æŠ½å‡ºã‚’é–‹å§‹ã—ã¾ã™")
    
    # TRIZç‰¹å¾´è¾æ›¸ã‚’ä½œæˆ
    triz_dict = {}
    # æ­£è¦è¡¨ç¾ã§ç‰¹å¾´ã‚’æŠ½å‡º
    pattern = re.compile(r'^\|\s*(\d+)\s*\|\s*(.+?)\s*\|\s*(.+?)\s*\|')
    for line in TRIZ_FEATURES.split('\n'):
        match = pattern.match(line)
        if match:
            num = match.group(1).strip()
            feature = match.group(2).strip()
            explanation = match.group(3).strip()
            triz_dict[num] = feature
    
    # å•é¡Œ/ç›®æ¨™ãŒç©ºã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not state['problems'] or not state['goals']:
        logging.warning("å•é¡Œ/ç›®æ¨™ãŒç©ºã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçŸ›ç›¾ã‚’ç”Ÿæˆ")
        print("  âš ï¸ å•é¡Œ/ç›®æ¨™ãªã—ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆçŸ›ç›¾ã‚’ç”Ÿæˆ")
        elapsed = time.time() - start_time
        print(f"âœ… [ã‚¹ãƒ†ãƒƒãƒ—4/4] çŸ›ç›¾æŠ½å‡ºå®Œäº† ({elapsed:.2f}ç§’)")
        return {**state, "contradictions": [{
            "improving": "9",
            "worsening": "22",
            "explanation": "WARNING-ä»£æ›¿çŸ›ç›¾:é¢¨åŠ›ç™ºé›»ã®åŠ¹ç‡ã‚’ä¸Šã’ã‚‹ãŸã‚ã«é¢¨é€Ÿã‚’å¢—åŠ ã•ã›ã‚‹ã¨ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ­ã‚¹ãŒå¢—åŠ ã™ã‚‹ã¨ã„ã†çŸ›ç›¾"
        }]}
    
    problems_str = "\n- ".join(state['problems'])
    goals_str = "\n- ".join(state['goals'])
    
    # TRIZç‰¹å¾´ãƒªã‚¹ãƒˆã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
    triz_list = "\n".join([f"{num}: {feat}" for num, feat in triz_dict.items()])
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„
    prompt = f"""
    ä»¥ä¸‹ã®å•é¡Œã¨ç›®æ¨™ã‹ã‚‰TRIZçŸ›ç›¾ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    çŸ›ç›¾ç‰¹å¾´ã¯ç•ªå·ï¼ˆ1ã€œ39ï¼‰ã¨åå‰ã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
    æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
    
    ### TRIZ 39ã®çŸ›ç›¾ç‰¹å¾´:
    {triz_list}
    
    ### å•é¡Œ:
    {problems_str}
    
    ### ç›®æ¨™:
    {goals_str}
    
    ## å‡ºåŠ›å½¢å¼ï¼ˆJSONã®ã¿ï¼‰:
    {{
        "contradictions": [
            {{
                "improving": "æ”¹å–„ç‰¹å¾´ã®ç•ªå·",
                "improving_name": "æ”¹å–„ç‰¹å¾´ã®åå‰",
                "worsening": "æ‚ªåŒ–ç‰¹å¾´ã®ç•ªå·",
                "worsening_name": "æ‚ªåŒ–ç‰¹å¾´ã®åå‰",
                "explanation": "çŸ›ç›¾ã®èª¬æ˜ï¼ˆ300æ–‡å­—ä»¥ä¸Š500æ–‡å­—ä»¥å†…ï¼‰"
            }},
            ...ï¼ˆæœ€å¤§5ã¤ã¾ã§ï¼‰
        ]
    }}
    ç¹°ã‚Šè¿”ã—è¦æ±‚ã—ã¾ã™ã€‚å›ç­”ã¯æ—¥æœ¬èªã«ã—ã¦ãã ã•ã„ã€‚
    """
    
    try:
        print("  - çŸ›ç›¾åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
        response = client_reasoner.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {'role': 'system', 'content': 'TRIZçŸ›ç›¾ã‚’æŠ½å‡ºã—JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„'},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        output = response.choices[0].message.content
        result = json.loads(output)
        contradictions = result.get("contradictions", [])
        
        # çŸ›ç›¾ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        valid_contradictions = []
        for c in contradictions:
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            if (c.get("improving") and c.get("worsening") and c.get("explanation") and
                c["improving"].isdigit() and c["worsening"].isdigit() and
                1 <= int(c["improving"]) <= 39 and 1 <= int(c["worsening"]) <= 39):
                
                # ç‰¹å¾´åãŒæä¾›ã•ã‚Œã¦ã„ãªã„å ´åˆã¯è¾æ›¸ã‹ã‚‰å–å¾—
                improving_name = c.get("improving_name") or triz_dict.get(c["improving"], "ä¸æ˜")
                worsening_name = c.get("worsening_name") or triz_dict.get(c["worsening"], "ä¸æ˜")
                
                valid_contradictions.append({
                    "improving": c["improving"],
                    "improving_name": improving_name,
                    "worsening": c["worsening"],
                    "worsening_name": worsening_name,
                    "explanation": c["explanation"][:500]  # èª¬æ˜ã‚’500æ–‡å­—ä»¥å†…ã«åˆ¶é™
                })
        
        if not valid_contradictions:
            logging.warning("æœ‰åŠ¹ãªçŸ›ç›¾ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»£æ›¿ç”Ÿæˆã‚’è©¦è¡Œ")
            print("  âš ï¸ æœ‰åŠ¹ãªçŸ›ç›¾ãªã—ã€‚ä»£æ›¿ç”Ÿæˆã‚’å®Ÿè¡Œ")
            valid_contradictions = generate_fallback_contradictions(state, triz_dict)
        
        # çŸ›ç›¾çµæœã®è¡¨ç¤º
        print("\nğŸ”€ æŠ½å‡ºã•ã‚ŒãŸçŸ›ç›¾:")
        for i, c in enumerate(valid_contradictions, 1):
            print(f"  {i}. æ”¹å–„: #{c['improving']} {c['improving_name']}")
            print(f"     æ‚ªåŒ–: #{c['worsening']} {c['worsening_name']}")
            print(f"     â†’ {c['explanation'][:70]}...")
        
        logging.info(f"åˆè¨ˆ{len(valid_contradictions)}å€‹ã®çŸ›ç›¾ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
        elapsed = time.time() - start_time
        print(f"âœ… [ã‚¹ãƒ†ãƒƒãƒ—4/4] çŸ›ç›¾æŠ½å‡ºå®Œäº† ({elapsed:.2f}ç§’)")
        return {**state, "contradictions": valid_contradictions}
    
    except Exception as e:
        logging.error(f"çŸ›ç›¾ã®æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
        print(f"  â— ã‚¨ãƒ©ãƒ¼: {str(e)}")
        valid_contradictions = generate_fallback_contradictions(state, triz_dict)
        elapsed = time.time() - start_time
        print(f"âš ï¸ [ã‚¹ãƒ†ãƒƒãƒ—4/4] ä»£æ›¿çŸ›ç›¾ç”Ÿæˆå®Œäº† ({elapsed:.2f}ç§’)")
        return {**state, "contradictions": valid_contradictions}


# --- ä»£æ›¿çŸ›ç›¾ç”Ÿæˆ---
def generate_fallback_contradictions(state: AnalysisState, triz_dict: dict) -> List[Dict]:
    """å•é¡Œ/ç›®æ¨™ã‹ã‚‰çŸ›ç›¾ã‚’è«–ç†çš„ã«ç”Ÿæˆ"""
    fallbacks = []
    
    # ã‚³ã‚¹ãƒˆé–¢é€£ã®çŸ›ç›¾
    if any("ã‚³ã‚¹ãƒˆ" in p for p in state['problems']) and any("åŠ¹ç‡" in g for g in state['goals']):
        fallbacks.append({
            "improving": "39",
            "improving_name": triz_dict.get("39", "ç”Ÿç”£æ€§"),
            "worsening": "20",
            "worsening_name": triz_dict.get("20", "ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»"),
            "explanation": "WARNING-ä»£æ›¿çŸ›ç›¾:ç™ºé›»åŠ¹ç‡ã‚’ä¸Šã’ã‚‹ã¨è¨­å‚™ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã™ã‚‹çŸ›ç›¾"
        })
    
    # ç’°å¢ƒé–¢é€£ã®çŸ›ç›¾
    if any("ç’°å¢ƒ" in p for p in state['problems']) and any("è¨­ç½®" in g for g in state['goals']):
        fallbacks.append({
            "improving": "5",
            "improving_name": triz_dict.get("5", "ç§»å‹•ç‰©ä½“ã®é¢ç©"),
            "worsening": "31",
            "worsening_name": triz_dict.get("31", "ç‰©ä½“ãŒç™ºç”Ÿã™ã‚‹æœ‰å®³è¦å› "),
            "explanation": "WARNING-ä»£æ›¿çŸ›ç›¾:ç™ºé›»é¢ç©ã‚’å¢—ã‚„ã™ã¨ç’°å¢ƒã¸ã®æ‚ªå½±éŸ¿ãŒå¢—åŠ ã™ã‚‹çŸ›ç›¾"
        })
    
    # æŠ€è¡“çš„å®‰å®šæ€§ã®çŸ›ç›¾
    if any("ä¸å®‰å®š" in p for p in state['problems']) and any("å®‰å®š" in g for g in state['goals']):
        fallbacks.append({
            "improving": "13",
            "improving_name": triz_dict.get("13", "ç‰©ä½“ã®å®‰å®šæ€§"),
            "worsening": "21",
            "worsening_name": triz_dict.get("21", "ã‚¨ãƒãƒ«ã‚®ãƒ¼ä½¿ç”¨é‡"),
            "explanation": "WARNING-ä»£æ›¿çŸ›ç›¾:ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§ã‚’é«˜ã‚ã‚‹ã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»é‡ãŒå¢—åŠ ã™ã‚‹çŸ›ç›¾"
        })
    
    return fallbacks if fallbacks else [{
        "improving": "9",
        "improving_name": triz_dict.get("9", "é€Ÿåº¦"),
        "worsening": "22",
        "worsening_name": triz_dict.get("22", "ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ­ã‚¹"),
        "explanation": "WARNING-ä»£æ›¿çŸ›ç›¾:é¢¨åŠ›ç™ºé›»ã®åŠ¹ç‡å‘ä¸Šã¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ­ã‚¹å¢—åŠ ã®çŸ›ç›¾"
    }]

# --- LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹ç¯‰ ---
workflow = StateGraph(AnalysisState)
workflow.add_node("generate_background", generate_background)
workflow.add_node("consolidate_background", consolidate_background)
workflow.add_node("clarify_problem", clarify_problem)
workflow.add_node("identify_contradictions", identify_contradictions)
workflow.set_entry_point("generate_background")
workflow.add_edge("generate_background", "consolidate_background")
workflow.add_edge("consolidate_background", "clarify_problem")
workflow.add_edge("clarify_problem", "identify_contradictions")
workflow.add_edge("identify_contradictions", END)
app = workflow.compile()

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‹±èªã«å¤‰æ›´ ---
user_prompt = """Our city (population about 500,000, Pacific coast) plans to reduce its reliance on thermal and nuclear power and promote the use of renewable energy in regional units (about 3,000 households). Specifically, we are considering introducing large-scale small-scale wind power genera-tion, but we face the following challenges:
- **Advantages of wind power generation**: Occasionally strong winds near the coast (but the wind is unstable).
- **Residents' concerns**: High cost, environmental impact (noise, ecosystem impact), and difficulty in urban installation.
- **Technical limitations**: The mainstream horizontal axis type (large propeller) is noisy and dis-rupts airflow, which is not suitable for urban areas.

Please collect and analyze relevant information on this issue (including international cases) and pro-pose appropriate solutions. At least include the following information:
- Reduce installation costs (such as: initial investment, maintenance cost reduction, etc.)
- Deal with unstable wind (such as: energy storage, hybrid system, gyro-type vertical axis wind tur-bine, decentralized smart grid, etc.)
- Reduce noise and ecosystem considerations (such as: minimize the impact on birds, etc.)
- Environmental adaptability of urban installation (such as: discussion of alternatives such as small wind turbines)"""

# è‹±èªæ¤œç´¢ç”¨ã«ã‚¯ã‚¨ãƒªã‚’èª¿æ•´
tavily_prompt = "A medium-sized city (population approx. 500,000, Pacific coast) is considering in-troducing wind power. Residents generally support the plan but have concerns about costs, environ-mental and ecosystem impacts. We want to collect relevant information including international trends."

# --- ã‚«ãƒ†ã‚´ãƒªåãƒãƒƒãƒ”ãƒ³ã‚° ---
cat_names = {
    "customer": "å¸‚æ°‘è¦–ç‚¹",
    "organization": "è¡Œæ”¿è¦–ç‚¹",
    "technology": "æŠ€è¡“è¦–ç‚¹",
    "cost": "ã‚³ã‚¹ãƒˆè¦–ç‚¹",
    "legal": "æ³•è¦åˆ¶è¦–ç‚¹"
}

# --- å®Ÿè¡Œ ---
inputs = {
    "input": user_prompt,
    "tavily_input": tavily_prompt
}

print("="*50)
print("ğŸš€ TRIZåˆ†æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’é–‹å§‹ã—ã¾ã™")
print("="*50)

result = app.invoke(inputs)

print("\n" + "="*50)
print("ğŸ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†ï¼æœ€çµ‚çµæœ:")
print("="*50)
print(json.dumps(result, ensure_ascii=False, indent=2))

```

QEU:FOUNDER ï¼š â€œä»Šå›ã¯ã€**JP_CN_ENã®ä¸‰ã‹å›½èªã®çŸ›ç›¾æƒ…å ±ã‚’ã¾ã¨ã‚ãŸè¡¨**ã§ã™ã€‚â€

![imageTRIZ0-8-5](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-5.jpg) 

Då…ˆç”Ÿï¼š â€œå‰å›ã¨åŒæ§˜ã«ãƒãƒ©ãƒãƒ©ã«åˆ†å¸ƒã—ã¦ã„ã¾ã™ã‹ï¼Ÿâ€

QEU:FOUNDER ï¼š â€œãã†ãªã‚“ã§ã™ã€‚çŸ›ç›¾ã£ã¦å¾®å¦™ãªã®ã§ã™ã­ã€‚ã™ã”ãä¸æ€è­°ãªæ°—åˆ†ã§ã™ã€‚ãƒ­ãƒã‚¹ãƒˆãªç™ºæ˜ã‚’ã™ã‚‹ãŸã‚ã«ã€TRIZåŸå‰‡åˆ¥ã«ã¾ã¨ã‚ã¦ã„ã‹ãªã„ã¨ãªã‚‰ãªã„ã§ã™ã­ã€‚ãã“ã§ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ã€ä¾‹ã«ã‚ˆã£ã¦Vibe Codingã§ç”Ÿæˆã—ã¾ã—ãŸã€‚â€

```python
# ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Dict, Any

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
contradictions_df = pd.read_excel("contradictions_JPCNEN.xlsx")
triz_matrix = pd.read_excel("triz-39matrix.xlsx", index_col=0)
triz_principles_df = pd.read_excel("triz_principles_simple.xlsx")

# åŸå‰‡ã”ã¨ã®çŸ›ç›¾æƒ…å ±ã‚’åé›†ã™ã‚‹é–¢æ•°
def extract_principles_with_histogram():
    principles_dict = {}
    
    for idx, row in contradictions_df.iterrows():
        imp = row['è‰¯åŒ–ã™ã‚‹ç‰¹å¾´ç•ªå·']
        wors = row['æ‚ªåŒ–ã™ã‚‹ç‰¹å¾´ç•ªå·']
        
        try:
            principles_str = triz_matrix.iat[imp-1, wors-1]
        except (IndexError, ValueError):
            continue
            
        if pd.isna(principles_str) or not principles_str:
            continue
            
        principles_str = principles_str.replace(" ", "").replace("ã€", ",")
        principles = [p.strip() for p in principles_str.split(",") if p.strip().isdigit()]
        
        for p in principles:
            p_int = int(p)
            principle_info = triz_principles_df[triz_principles_df['NO'] == p_int]
            if not principle_info.empty:
                title = principle_info.iloc[0]['Title']
                example = principle_info.iloc[0]['Example']
                
                contradiction_info = {
                    'çŸ›ç›¾ç•ªå·': idx,
                    'æ”¹å–„ç‰¹å¾´': imp,
                    'æ‚ªåŒ–ç‰¹å¾´': wors,
                    'çŸ›ç›¾æ¦‚è¦': row['çŸ›ç›¾ã®æ¦‚è¦']
                }
                
                if p in principles_dict:
                    principles_dict[p]['related_contradictions'].append(contradiction_info)
                else:
                    principles_dict[p] = {
                        'principle_no': p,
                        'principle_title': title,
                        'principle_example': example,
                        'related_contradictions': [contradiction_info]
                    }
    
    # åŸå‰‡ã”ã¨ã®çŸ›ç›¾ä»¶æ•°ã‚’è¡¨ç¤ºï¼ˆãƒ•ã‚£ãƒ«ã‚¿å‰ï¼‰
    print("===== åŸå‰‡ã”ã¨ã®çŸ›ç›¾ä»¶æ•° =====")
    principle_counts = []
    for p, info in principles_dict.items():
        count = len(info['related_contradictions'])
        principle_counts.append((int(p), count, info['principle_title']))
    
    # ä»¶æ•°1ä»¥ä¸‹ã®æƒ…å ±ã‚’é™¤å¤–
    filtered_principle_counts = [pc for pc in principle_counts if pc[1] > 1]
    
    # ä»¶æ•°ãŒå¤šã„é †ã«ã‚½ãƒ¼ãƒˆ
    sorted_principle_counts = sorted(filtered_principle_counts, key=lambda x: x[1], reverse=True)
    
    # ã‚½ãƒ¼ãƒˆå¾Œã®è¡¨ç¤º
    for pc in sorted_principle_counts:
        print(f"åŸå‰‡ {pc[0]}: {pc[2]} - {pc[1]}ä»¶")
    
    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ç”Ÿæˆ
    principle_numbers = [pc[0] for pc in sorted_principle_counts]
    counts = [pc[1] for pc in sorted_principle_counts]
    titles = [pc[2] for pc in sorted_principle_counts]
    
    indices = np.arange(len(sorted_principle_counts))
    
    plt.figure(figsize=(15, 8))
    bars = plt.bar(indices, counts, color='skyblue')
    plt.xlabel('TRIZ Principle Number')
    plt.ylabel('Number of Contradictions')
    plt.title('Histogram of Contradictions per TRIZ Principle')
    plt.xticks(indices, principle_numbers, rotation=90)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    # ãƒãƒ¼ä¸Šã«ä»¶æ•°ã‚’è¡¨ç¤º
    for bar, count in zip(bars, counts):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                 f'{count}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('triz_principle_histogram.png')
    plt.show()
    
    return principles_dict

# å®Ÿè¡Œ
principles_data = extract_principles_with_histogram()

# åŸå‰‡ã”ã¨ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
print("\n===== åŸå‰‡ã”ã¨ã®è©³ç´°çŸ›ç›¾æƒ…å ± =====")
for p, info in principles_data.items():
    count = len(info['related_contradictions'])
    if count <= 1:
        continue
    print(f"\nåŸå‰‡ {info['principle_no']}: {info['principle_title']}")
    print(f"é©ç”¨ä¾‹: {info['principle_example']}")
    print(f"é–¢é€£çŸ›ç›¾ä»¶æ•°: {count}")
    for contr in info['related_contradictions']:
        print(f" - çŸ›ç›¾{contr['çŸ›ç›¾ç•ªå·']}: [æ”¹å–„{contr['æ”¹å–„ç‰¹å¾´']} vs æ‚ªåŒ–{contr['æ‚ªåŒ–ç‰¹å¾´']}]")
        print(f"   {contr['çŸ›ç›¾æ¦‚è¦']}")

# åŸå‰‡ã”ã¨ã®è©³ç´°çŸ›ç›¾æƒ…å ±ã‚’DataFrameã«å¤‰æ›
filtered_principles = {}
for p, info in principles_data.items():
    if len(info['related_contradictions']) > 1:
        filtered_principles[p] = info

data = []
seqno = 1
for p, info in filtered_principles.items():
    principle_no = info['principle_no']
    principle_example = info['principle_example']
    for contr in info['related_contradictions']:
        data.append({
            'SEQNO': seqno,
            'åŸå‰‡NO': principle_no,
            'åŸå‰‡ã®é©ç”¨ä¾‹': principle_example,
            'çŸ›ç›¾ç•ªå·': contr['çŸ›ç›¾ç•ªå·'],
            'æ”¹å–„ç‰¹å¾´NO vs æ‚ªåŒ–ç‰¹å¾´NO': f"{contr['æ”¹å–„ç‰¹å¾´']} vs {contr['æ‚ªåŒ–ç‰¹å¾´']}",
            'èª¬æ˜æ–‡': contr['çŸ›ç›¾æ¦‚è¦']
        })
        seqno += 1

df_details = pd.DataFrame(data)
#df_details

# ---
df_details.to_excel('triz_principle_details.xlsx', index=False)

```

QEU:FOUNDER ï¼š â€œã“ã‚Œï¼ˆâ†“ï¼‰ã‚’è¦‹ã‚Œã°ã€ä¸€ç›®ç­ç„¶ã§ã™ã­ã€‚å°‘æ•°ã®åŸå‰‡ã‚’é©ç”¨ã™ã‚‹ã ã‘ã§ã€ãƒ­ãƒã‚¹ãƒˆæ€§ã®ã‚ã‚‹ã®ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„ãŒã§ãã‚‹ã‚“ã§ã™ã€‚â€

![imageTRIZ0-8-6](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-6.jpg) 

Då…ˆç”Ÿï¼š â€œã„ã‚„ã‚ãƒ»ãƒ»ãƒ»ã€‚ã“ã‚Œã¯åˆ†ã‹ã‚Šã‚„ã™ã„ã€‚å¤§ä½“ã€ä»¶æ•°ãŒ4ä»¶ä»¥ä¸Šã®ã‚‚ã®ã«å¯¾ã—ã¦ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„ã™ã‚Œã°ã‚ˆã•ãã†ã§ã™ã­ã€‚ãã‚Œã«ã—ã¦ã‚‚ã€ä»¶æ•°ãƒˆãƒƒãƒ—ã®ã€ŒåŸå‰‡35:ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤‰æ›´ã€ã£ã¦ã€ä¸€ä½“ã€ãªã‚“ã ã‚ã†ï¼Ÿâ€

**ç‰©ä½“ã®çŠ¶æ…‹ã®é›†ç©åº¦ãƒ»æ¸©åº¦ã‚’å¤‰ãˆã‚‹ã€‚ç‰©ä½“ã®ç‰©ç†çš„çŠ¶æ…‹ï¼ˆæ°—ä½“ã€æ¶²ä½“ã€å›ºä½“ãªã©ï¼‰ã‚’å¤‰æ›´ã—ã¾ã™ã€‚æ±šã‚Œã¦ã­ã°ã­ãã—ãŸç†±ã„æ¶²ä½“ã‚’æ‰±ã†ä»£ã‚ã‚Šã«ã€è©°ã‚ç‰©ã®å…¥ã£ãŸã‚­ãƒ£ãƒ³ãƒ‡ã‚£ãƒ¼ã®ä¸­å¿ƒã®æ¶²ä½“ã‚’å‡ã‚‰ã›ã¦ã‹ã‚‰ã€æº¶ã‹ã—ãŸãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆã«æµ¸ã—ã¾ã™ã€‚ä½“ç©ã‚’æ¸›ã‚‰ã™ãŸã‚ã«ã€é…¸ç´ ã€çª’ç´ ã€çŸ³æ²¹ã‚¬ã‚¹ã‚’ã‚¬ã‚¹ã§ã¯ãªãæ¶²ä½“ã¨ã—ã¦è¼¸é€ã—ã¾ã™ã€‚æ¿ƒåº¦ã¾ãŸã¯ç²˜ç¨ åº¦ã‚’å¤‰æ›´ã—ã¾ã™ã€‚æŸ”è»Ÿæ€§ã®åº¦åˆã„ã‚’å¤‰æ›´ã—ã¾ã™ã€‚èª¿æ•´å¯èƒ½ãªãƒ€ãƒ³ãƒ‘ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€ã‚³ãƒ³ãƒ†ãƒŠã®å£ã®å‹•ãã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ³ãƒ†ãƒŠå†…ã«è½ã¡ã‚‹éƒ¨å“ã®é¨’éŸ³ã‚’ä½æ¸›ã—ã¾ã™ã€‚ã‚´ãƒ ã‚’åŠ ç¡«ã•ã›ã¦æŸ”è»Ÿæ€§ã¨è€ä¹…æ€§ã‚’å¤‰åŒ–ã•ã›ã¾ã™ã€‚æ¸©åº¦ã‚’ã‚­ãƒ¥ãƒªãƒ¼ç‚¹ä»¥ä¸Šã«ä¸Šã’ã‚‹ã¨ã€å¼·ç£æ€§ç‰©è³ªãŒå¸¸ç£æ€§ç‰©è³ªã«å¤‰åŒ–ã—ã¾ã™ã€‚é£Ÿå“ã®æ¸©åº¦ã‚’ä¸Šã’ã¦èª¿ç†ã—ã¾ã™ï¼ˆå‘³ã€é¦™ã‚Šã€é£Ÿæ„Ÿã€åŒ–å­¦çš„æ€§è³ªãªã©ãŒå¤‰ã‚ã‚Šã¾ã™ï¼‰ã€‚åŒ»ç™‚æ¨™æœ¬ã®æ¸©åº¦ã‚’ä¸‹ã’ã¦ã€å¾Œã§åˆ†æã§ãã‚‹ã‚ˆã†ã«ä¿å­˜ã—ã¾ã™ã€‚**

QEU:FOUNDER ï¼š â€œäº‹ä¾‹ã§è¡¨ç¾ã™ã‚‹ã¨ã€ã“ã†ï¼ˆâ†‘ï¼‰ãªã‚Šã¾ã™ã€‚ç›¸å¤‰åŒ–ã¨ã‹ã€è¨­è¨ˆï¼ˆè£½é€ ï¼‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ï¼Ÿã‚ã¨ã¯ã€EXCELãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚â€

![imageTRIZ0-8-7](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-7.jpg) 

QEU:FOUNDERï¼š â€œã‚ã¨ã¯ã€ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§èª­ã¿è¾¼ã¿ã€LLMæ¨è«–ã‚’ã™ã‚‹ã ã‘ã§ã™ã€‚â€

![imageTRIZ0-8-8](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-8.jpg) 

Då…ˆç”Ÿ ï¼š â€œæ–°ã—ã„æ™‚ä»£ã§ã™ã€‚ãªã«ã¯ã¨ã‚‚ã‚ã‚ŒASIã«èã„ã¦ã¿ã¾ã—ã‚‡ã†ã€‚â€



## ï½ ã¾ã¨ã‚ ï½

QEU:FOUNDER ï¼š â€œã›ã£ã‹ãã ã‹ã‚‰ã€ã“ã“ã§Vibe Coding ã«ã¤ã„ã¦ç·æ‹¬ã‚’ã—ã‚ˆã†ã‹ã€‚ã“ã®å‹•ç”»ï¼ˆâ†“ï¼‰ã‚’è¦‹ã‚Œã°ã‚ã‹ã‚‹ã€‚éå¸¸ã«åˆæ­©çš„ãªè¦³ç‚¹ã‹ã‚‰èª¬æ˜ã—ã¦ã„ã¦ã€æˆ‘ã€…ç´ äººé›†å›£ã‹ã‚‰ã¿ã¦ã‚‚ç´å¾—ã™ã‚‹ã¨ã“ã‚ã ã€‚â€

[![MOVIE1](http://img.youtube.com/vi/c7NIIvrzqpI/0.jpg)](http://www.youtube.com/watch?v=c7NIIvrzqpI "ã€AIé©å‘½ã€‘ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°çŸ¥è­˜0ã§å§‹ã‚ã‚‰ã‚Œã‚‹ãƒã‚¤ãƒ–ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°(Vibe Coding)ã®ã‚³ãƒ„ã‚’è§£èª¬")

Céƒ¨é•·ï¼š â€œ**ç°¡å˜ãªã‚‚ã®ã‚’ä½œã‚‹åˆ†ã«ã¯ã€ã¾ã£ãŸãå•é¡Œãªã„**ã¨ã„ã†ã“ã¨ã§ãƒ»ãƒ»ãƒ»ã€‚â€

![imageTRIZ0-8-9](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-9.jpg) 

QEU:FOUNDER ï¼š â€œãã†ã€åŸºæœ¬ã¯ç°¡å˜ãªã‚‚ã®ã‚’ä½œã‚‹ã¹ãã§ã™ã€‚ãã‚Œã§ã‚‚Vibe Codingã£ã¦ã€ãƒ„ãƒœã«å…¥ã‚‹ã¨ã€ã™ã”ã„ã‚³ãƒ¼ãƒ‰ã‚’ä½œã‚‹ã‚“ã§ã™ã‚ˆã€‚ä¸Šç´šãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã®å‡ºæ¥æ „ãˆã®ã‚‚ã®ã‚’ä½œã‚‹ã‚“ã§ã™ã€‚ãã®å½¼ã‚‰ã®ãƒ‘ãƒ¯ãƒ¼ã‚’ã€ã€Œã ã¾ã—ã ã¾ã—ã€ä½¿ã†ãƒ»ãƒ»ãƒ»ï¼ˆç¬‘ï¼‰ã€‚â€

Då…ˆç”Ÿï¼š â€œã ã¾ã—ã ã¾ã—ãƒ»ãƒ»ãƒ»ï¼Ÿâ€

![imageTRIZ0-8-10](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-10.jpg) 

Céƒ¨é•·ï¼š â€œDEEPSEEKæ§˜ã‚’ã ã¾ã™ã‚“ã§ã™ã‹ï¼Ÿâ€

QEU:FOUNDER ï¼š â€œã“ã®å‹•ç”»ã§ã‚‚èª¬æ˜ã—ã¦ã„ã‚‹ã§ã—ã‚‡ã†ï¼Ÿ**AIã‚’è¤‡æ•°èµ°ã‚‰ã›ãŸæ–¹ãŒè‰¯ã„**ã§ã™ã€‚æˆ‘ã€…ã®å ´åˆã€QWENã¨DEEPSEEKã‚’å¿…ãšä¸¦åˆ—ã—ã¦å®Ÿè¡Œã—ã¦ã„ã¾ã™ã€‚ãã—ã¦ã€å‡ºæ¥æ „ãˆãŒè‰¯ã„æ–¹ã‚’ä½¿ã†ã€‚å®Ÿè¡Œã—ã¦ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚ã€2ã¤ã®AIã«è§£æã•ã›ã€ãã—ã¦å†ã³å‡ºæ¥ã®è‰¯ã„ãƒ¢ãƒã‚’ä½¿ã†ã€‚â€

Céƒ¨é•·ï¼š â€œæ‰‹é–“ãŒã‹ã‹ã‚Šã¾ã™ã‚ˆã­ã€‚â€

QEU:FOUNDER ï¼š â€œã“ã†ã„ã†ã‚„ã‚Šã‹ãŸã¯ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ãŒå¤§å¤‰ã§ã™ã€‚AIã•ã‚“ãŒã€**ã€Œã‚„ã‚‰ã‚“ã§ã‚‚ã„ã„ã“ã¨ã€ã‚’ã™ã‚‹ã“ã¨ãŒã‚ã‚‹**ã‹ã‚‰ãƒ»ãƒ»ãƒ»ï¼ˆç¬‘ï¼‰ã€‚â€

![imageTRIZ0-8-11](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-11.jpg) 

QEU:FOUNDER ï¼š â€œ**ã‚¹ãƒ‹ãƒšãƒƒãƒˆç®¡ç†ãŒä¾¿åˆ©**ã§ã™ã‚ˆã­ã€‚ä½™è¨ˆãªéƒ¨åˆ†ã‚’å¤‰ãˆãªãã¦ã„ã„ã‹ã‚‰ã€‚â€

