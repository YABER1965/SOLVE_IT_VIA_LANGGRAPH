---
title: QEUR23_TRIZ7 - Tavilyを使った課題解決(言語変更NO2-矛盾検出まで)
date: 2025-06-20
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_TRIZ7 - Tavilyを使った課題解決(言語変更NO2-矛盾検出まで)

## ～ 複雑になった問題を解きほどく！ ～

QEU:FOUNDER（設定年齢65歳） ： “TRIZマトリックスを見ればわかるように、1つの矛盾には複数の発明原則が対応します。今後はE語も加わるのでさらに矛盾は複雑化するでしょう。それならが、**より多くの矛盾に当てはまる発明原則(40項目)だけを使って、発明を立案すればよい**と思わない？”

![imageTRIZ0-8-1](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-1.jpg) 

D先生（設定年齢65歳）： “多様な情報に共通する事項に対策するわけです。それは**「ロバストな発明」**ですね（笑）。 “

![imageTRIZ0-8-2](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-2.jpg) 

QEU:FOUNDER ： “そうです。もし、システムの根幹そのものがロバストになれば、べつに**枝葉のパラメータ設計でチマチマしたロバスト化をすることもいらなくなる**んですよ・・・（笑）。じゃあ、今回はE語で、多様化をやります。それでは、プログラムを晒します。コードは前回とほとんど同じです。プロンプトを変えてE語の情報を重点的に収集することを除けばね。”

```python
# ---
import os
import re
from langgraph.graph import END, StateGraph
from typing import Dict, List, TypedDict
import pandas as pd
from openai import OpenAI
from langchain_tavily import TavilySearch
import json
from difflib import SequenceMatcher
import logging
import time
from bs4 import BeautifulSoup  # HTML解析用
import html  # HTMLエスケープ解除用

# ロギング設定
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Tavilyツール設定 ---
internet_search = TavilySearch(
    api_key=os.environ['TAVILY_API_KEY'],
    max_results=5,
    include_raw_content=True,  # 生コンテンツを取得
    search_depth="advanced"    # 詳細検索を有効化
)

# --- OpenAIクライアント設定 ---
client_chat = OpenAI(
    api_key=os.getenv("DASHSCOPE_API_KEY"),
    base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
)
client_reasoner = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com",
)

# --- HTMLからテキスト抽出 ---
def extract_text_from_html(html_content: str) -> str:
    """HTMLからテキストコンテンツを抽出"""
    try:
        # HTMLエスケープ解除
        decoded_content = html.unescape(html_content)
        soup = BeautifulSoup(decoded_content, 'html.parser')
        
        # 不要な要素を除去
        for element in soup(['script', 'style', 'header', 'footer', 'nav', 'aside', 'form']):
            element.decompose()
        
        # テキストを取得して整形
        text = soup.get_text()
        text = re.sub(r'\n\n', '\n', text)  # 連続する改行を削除
        text = re.sub(r'\s+', ' ', text)  # 連続する空白を削除
        text = re.sub(r'\[\d+\]', '', text)  # [1]のような引用マークを削除
        return text.strip()
    except Exception as e:
        logging.error(f"HTML解析エラー: {str(e)}")
        return html_content  # 失敗時は元のコンテンツを返す

# --- 重複除去関数（URL対応版）---
def remove_duplicates(items: List[dict], similarity_threshold=0.3) -> List[dict]:
    """
    テキスト内容とURLを組み合わせて重複を除去
    入力: [{"text": "内容", "url": "URL"}, ...]
    出力: 重複除去後のリスト
    """
    unique_items = []
    for item in items:
        is_duplicate = False
        text = item["text"]
        url = item["url"]
        
        # 同じURLの場合は完全重複とみなす
        for unique in unique_items:
            if url == unique["url"]:
                is_duplicate = True
                break
                
        # 異なるURLでも内容が非常に似ている場合
        if not is_duplicate:
            for unique in unique_items:
                ratio = SequenceMatcher(None, text, unique["text"]).ratio()
                if ratio > similarity_threshold:
                    is_duplicate = True
                    break
                    
        if not is_duplicate:
            unique_items.append(item)
            
    return unique_items

# --- キーワードベース要約関数（拡張版）---
def summarize_background(text: str, max_chars=2000) -> str:
    """キーワードに基づいて背景情報を要約し文字数を拡充"""
    # 簡体字と繁体字両方のキーワードを含める
    keywords = ["風", "コスト", "騒音", "生態系", "市街", "設置", "電気", "工学", "自然", "科学", "技術", "発電", "再生可能", "エネルギー",
                "自治体", "静音", "風車", "欧米", "中国", "東南アジア", "東アジア", "太平洋", "大西洋", "蓄電", "スマート", "導入", "効率",
                "デンマーク", "フランス", "アメリカ", "イギリス", "ドイツ", "スウェーデン", "日本", "韓国", "制御", "ネットワーク", "ハイブリッド", "システム",
                "タービン", "羽根", "改善", "循環", "フィードバック", "金属", "メタル",
                "cost", "noise", "reduction", "innovation", "breakthrough", "wind", "energy", "technolo-gy", "China", "EU", 
                "USA", "sound", "bird", "Denmark", "battery", "AI", "intelligent", "efficiency", "net-work", "hybrid", 
                "China", "power", "magnet", "generation", "electric", "system", "urban", "city", "moun-tain", "ocean",
                "ecosystem", "installation", "electricity", "renewable", "vertical axis", "government", "turbine",
                "engineering", "nature", "smart", "control", "metal", "France", "Germany", "Denmark",
                "small-scale", "storage", "circulation", "offshore", "improvement", "solution", "feed-back",
                "风", "成本", "能量", "噪音", "噪声", "生态", "生態", "鸟", "鳥", "改进", "改進", 
                "市区", "设置", "設置", "技术", "技術", "发电", "發電", "渦輪", "涡轮", 
                "地方", "政府", "自治体", "静音", "风机", "風機", "欧美", "歐美", 
                "中国", "中國", "东南亚", "東南亞", "储能", "儲能", "智能", "智慧", 
                "引入", "效率", "法国", "法國", "美国", "美國", "英国", "英國", 
                "德国", "德國", "瑞典", "日本", "韩国", "韓國", "控制", "系统", "系統", "自动", "自動",
                ]
    
    # 文章を文単位で分割
    sentences = re.split(r'(?<=[。！？.!?\n])', text)
    
    # キーワードを含む文を抽出
    relevant = [s for s in sentences if any(kw in s for kw in keywords)]
    
    # 関連文が少ない場合は追加処理
    if len(relevant) < 10 or len(''.join(relevant)) < 500:
        # 最長の文を追加
        longest = sorted(sentences, key=len, reverse=True)[:10]
        relevant.extend(longest)
    
    summarized = ' '.join(relevant)
    
    # 文字数を調整（不足している場合は関連情報を追加）
    if len(summarized) < max_chars:
        # 追加コンテンツ生成
        prompt = f"""
        Expand the following text related to wind power to {max_chars - len(summarized)} characters in Japanese.
        Include:
        - Latest technology trends in wind power
        - International cases (Europe, America, Asia)
        - Cost reduction methods
        - Environmental impact countermeasures
        
        Original text:
        {summarized[:3000]}
        """
        try:
            response = client_reasoner.chat.completions.create(
                model="deepseek-reasoner",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=1000
            )
            additional = response.choices[0].message.content
            summarized += "\n" + additional
        except Exception as e:
            logging.error(f"追加コンテンツ生成エラー: {str(e)}")
            # 失敗時のフォールバック
            summarized += ("警告(WARNING) - 追加技術情報: 風力発電技術は近年急速に発展しており、特に小型垂直軸風車の効率改善と騒音低減技術が注目されています。"
                          "欧州の都市では設置事例が増加しており、ドイツのフライブルク市では建築一体型システムの試験が行われ、"
                          "年間発電量18MWhを達成しています。日本の長崎県では浮体式洋上風力の実証実験が進行中です。")
    
    return summarized[:max_chars]

# --- コンテンツフィルタリング関数（改造版）---
def filter_inappropriate_content(text: str) -> str:
    """不適切なコンテンツを含む文を完全に削除する"""
    # 簡体字と繁体字両方の不適切語を含む
    inappropriate_words = [
        "暴力", "憎悪", "差別", "ポルノ", "アダルト", "環境破壊", "公害", "化学", "キーワード", "日本語",
        "有害物質", "絶滅危惧種", "環境ホルモン", "生態系破壊", "放射能", "津波", "戦争", "軍事", "紛争",
        "KEYWORD", "SITEMAP", "http", "email", "e-mail", 
        "violence", "hate", "discrimination", "porn", "adult", "environmental destruction",
        "pollution", "hazardous substances", "endangered species", "radiation", "war",
        "military", "conflict", "keyword", "sitemap", "advertisement",
        "top page", "reference", "related article", "shopping", "table of contents",
        "目次", "広告", "トップページ", "サイトマップ", "ニュース", "参考文献", "関連記事", "ショッピング",
        "憎恨", "仇恨", "歧视", "歧視", "色情", "成人", "成人内容", 
        "环境污染", "環境污染", "公害", "化学污染", "化學污染", 
        "有害物质", "有害物質", "濒危物种", "瀕危物種", "环境激素", "環境激素", 
        "生态系统破坏", "生態系統破壞", "辐射", "輻射", "海啸", "海嘯", "战争", "戰爭", "军事", "軍事", 
        "冲突", "衝突", "关键词", "關鍵詞", "关键词",  "参考文献", "參考文獻", 
        "邮箱", "目录", "目錄", "广告", "廣告", "首页", "首頁", "网站", "網站", "新闻", "新聞","相关文章", "相關文章", "购物", "購物", "簡体", "繁体"
    ]
    
    # 文に分割
    sentences = re.split(r'(?<=[。！？.!?\n])', text)
    
    # 不適切な単語を含まない文のみを保持
    filtered_sentences = []
    for sentence in sentences:
        # 不適切な単語が含まれているかチェック
        if not any(word in sentence for word in inappropriate_words):
            filtered_sentences.append(sentence)
    
    return ' '.join(filtered_sentences)

```

QEU:FOUNDER ： “3か国語のサポートになるので、キーワードが一気に増えちゃいましたね。それ以外はほとんど変化はありません。”

D先生： “もう少しコードを削っては？”

QEU:FOUNDER ： “TRIZ_FEATURESだけは、長いので消してしまいましょう。翻訳すべき細かなプロンプトが、あちこちにばらけているんで、思ったよりも（コードの）省略が出来ないんです。”

```python
# --- 状態定義 ---
class AnalysisState(TypedDict):
    input: str
    tavily_input: str
    problems: List[str]
    goals: List[str]
    contradictions: List[Dict[str, str]]
    background: Dict[str, List[dict]]  # 変更: 各アイテムは{"text": "内容", "url": "URL"}形式
    consolidated_background: Dict[str, str]

# TRIZ 39矛盾特徴
#TRIZ_FEATURES = """
#省略します

# --- 背景情報生成（英語検索版）---
def generate_background(state: AnalysisState) -> AnalysisState:
    start_time = time.time()
    print("🔍 [ステップ1/4] 背景情報の生成を開始...")
    logging.info("背景情報の生成を開始します")
    user_input = state['tavily_input']

    # 英語検索クエリに変更
    categories = {
        "customer": f"{user_input} citizen concerns OR public opinion OR wind energy citizen",
        "organization": f"{user_input} implementation cases OR policies OR local government OR wind energy",
        "technology": f"{user_input} vertical axis wind turbine OR quiet OR small-scale OR energy storage technology",
        "cost": f"{user_input} cost OR investment OR maintenance cost OR efficiency",
        "legal": f"{user_input} environmental assessment OR regulations OR legal OR control OR sys-tem"
    }

    background = {
        "customer": [],
        "organization": [],
        "cost": [],
        "technology": [],
        "legal": []
    }

    for category, query in categories.items():
        logging.info(f"検索中: {category} - {query}")
        try:
            print(f"  - {category}カテゴリの検索実行: {query[:80]}...")
            search_result = internet_search.invoke({"query": query})

            items = []  # {"text": "内容", "url": "URL"}形式のリスト
            for res in search_result["results"][:5]:
                # URLを取得
                url = res.get("url", "URL不明")

                # 生HTMLからテキスト抽出
                raw_html = res.get("raw_content", "")
                if raw_html:
                    content = extract_text_from_html(raw_html)
                else:
                    content = res.get("content", "")

                # フィルタリングと要約
                filtered = filter_inappropriate_content(content)
                summarized = summarize_background(filtered, 2000)  # 2000文字まで拡充

                items.append({
                    "text": summarized,
                    "url": url
                })

            # URLと内容を組み合わせた重複除去
            unique_items = remove_duplicates(items)

            # 文字数不足のアイテムを補完
            final_items = []
            for item in unique_items:
                if len(item["text"]) < 1500:
                    try:
                        prompt = f"Please expand the following text from the perspective of wind power gen-eration, adding technical details to make it 1200 to 1500 words:\n{item['text']}"
                        response = client_reasoner.chat.completions.create(
                            model="deepseek-reasoner",
                            messages=[{"role": "user", "content": prompt}],
                            temperature=0.3,
                            max_tokens=1500
                        )
                        expanded = response.choices[0].message.content
                        item["text"] = expanded[:1000]
                    except:
                        item["text"] += " " + ("WARNING - Details: Wind power generation technology has developed rapidly in recent years..." * 10)[:1500-len(item["text"])]
                final_items.append(item)

            background[category] = final_items
            avg_length = sum(len(item["text"]) for item in final_items) / len(final_items)
            print(f"    ✅ 結果: {len(final_items)}件 → 平均文字数: {avg_length:.0f}文字")
            print(f"    └ 代表URL: {final_items[0]['url']}")

        except Exception as e:
            logging.error(f"{category}の検索でエラー: {str(e)}")
            background[category] = [{"text": f"検索エラー: {str(e)}", "url": "N/A"}]
            print(f"    ❗ エラー: {str(e)}")

    # 結果のプレビュー表示
    print("\n📊 背景情報生成結果プレビュー:")
    for cat, items in background.items():
        print(f"  - {cat}: {len(items)}件の情報")
        if items:
            avg_length = sum(len(item["text"]) for item in items) / len(items)
            print(f"    ├ 平均文字数: {avg_length:.0f}文字")
            print(f"    ├ URL数: {len(set(item['url'] for item in items))}個")
            print(f"    └ 最初のURL: {items[0]['url']}")

    elapsed = time.time() - start_time
    print(f"✅ [ステップ1/4] 背景情報生成完了 ({elapsed:.2f}秒)")
    logging.info("背景情報の生成が完了しました")
    return {**state, "background": background}

# --- 背景情報の整理と要約（強化版）---
def consolidate_background(state: AnalysisState) -> AnalysisState:
    start_time = time.time()
    print("\n📚 [ステップ2/4] 背景情報の整理を開始...")
    logging.info("背景情報の整理を開始します")
    background = state['background']

    # 背景情報の統計表示
    total_items = sum(len(items) for items in background.values())
    total_chars = sum(len(item["text"]) for items in background.values() for item in items)
    unique_urls = len(set(item["url"] for items in background.values() for item in items))
    print(f"  - 総情報量: {total_items}件, 総文字数: {total_chars}文字, ユニークURL数: {unique_urls}")

    combined_data = ""
    for category, items in background.items():
        category_name = cat_names.get(category, category)
        combined_data += f"【{category_name}】\n"
        for i, item in enumerate(items, 1):
            combined_data += f"{i}. {item['text']}\n"
        combined_data += "\n"

    # 長すぎる場合は最初の8000文字を使用
    if len(combined_data) > 8000:
        combined_data = combined_data[:8000] + "\n... (以下省略)"

    # 日本語プロンプト（英語情報を基に日本語で要約）
    prompt = f"""
    Please summarize the following background information into 5 categories in Japanese.
    Each summary should be 800-1200 characters and include:
    - Technical details, numerical data, and specific cases
    - Priority to international cases (Europe, America, Asia)
    - Core information for each category
    
    ## Important: Output in JSON format in Japanese
    
    ## Background Information:
    {combined_data}
    
    ## Output Format (JSON):
    {{
        "customer": "要約テキスト（800-1200文字）",
        "organization": "要約テキスト（800-1200文字）",
        "technology": "要約テキスト（800-1200文字）",
        "cost": "要約テキスト（800-1200文字）",
        "legal": "要約テキスト（800-1200文字）"
    }}
    """

    try:
        print("  - 詳細要約リクエストを送信中...")
        response = client_reasoner.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {'role': 'system', 'content': 'You are an expert who summarized each category in 1200-1500 words while maintaining technical details'},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"},
            max_tokens=2000
        )
        consolidated = json.loads(response.choices[0].message.content)

        # 要約結果の検証と修正
        for cat, summary in consolidated.items():
            current_length = len(summary)
            if current_length < 800:
                # 文字数が不足する場合の補完
                prompt = f"Please add technical details and expand the following summary to more than 800 words, including specific data and cases:\n{summary}"
                try:
                    response = client_reasoner.chat.completions.create(
                        model="deepseek-reasoner",
                        messages=[
                            {'role': 'system', 'content': 'You are an expert who summarizes technical infor-mation in Japanese based on English sources'},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.2,
                        max_tokens=2000
                    )
                    expanded = response.choices[0].message.content
                    consolidated[cat] = expanded[:2000]
                except:
                    # フォールバック処理
                    consolidated[cat] = summary + (" Additional information: According to the European Renewable Energy Agency report, the cost of offshore wind power in 2023..." * 5)[:2000-len(summary)]

        # 要約結果の表示
        print("\n📝 要約結果（文字数）:")
        for cat, summary in consolidated.items():
            print(f"  - {cat_names.get(cat, cat)}: {len(summary)}文字")

        logging.info("背景情報の整理が完了しました")
        elapsed = time.time() - start_time
        print(f"✅ [ステップ2/4] 背景情報整理完了 ({elapsed:.2f}秒)")
        return {**state, "consolidated_background": consolidated}

    except Exception as e:
        logging.error(f"背景情報の整理でエラー: {str(e)}")
        print(f"    ❗ エラー: {str(e)}")
        consolidated = {}
        for category in background.keys():
            # 生データを結合して2000文字に要約
            combined = ' '.join(item["text"] for item in background[category])
            text = summarize_background(combined, 2000)
            consolidated[category] = text
        elapsed = time.time() - start_time
        print(f"⚠️ [ステップ2/4] フォールバック処理完了 ({elapsed:.2f}秒)")
        return {**state, "consolidated_background": consolidated}

```

D先生： “あれ？ポリシーを変えましたか？背景の要約モジュールから日本語で回答するように指示していますね。 “

![imageTRIZ0-8-3](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-3.jpg) 

QEU:FOUNDER ： “結論からいうと、（文章のJ語化に）失敗しています。思い切って、J語のプロンプトにすればよかったんです。この際、表示される言語はどうでもいいけどね。それでは、コードの晒しを続けます。”

```python
# --- 問題を明確化する ---
def clarify_problem(state: AnalysisState) -> AnalysisState:
    start_time = time.time()
    print("\n🔎 [ステップ3/4] 問題の明確化を開始...")
    logging.info("問題の明確化を開始します")
    background_text = ""
    consolidated = state.get('consolidated_background', {})

    # 要約された背景情報の構築
    if consolidated:
        logging.info("要約された背景情報を使用します")
        print("  - 要約背景情報を使用")
        for category, summary in consolidated.items():
            category_name = cat_names.get(category, category)
            background_text += f"### {category_name}:\n- {summary}\n"
    else:
        logging.warning("要約背景情報が見つかりません。生の背景情報を使用します")
        print("  ⚠️ 要約背景なし。生データを使用")
        for category, items in state["background"].items():
            category_name = cat_names.get(category, category)
            background_text += f"### {category_name}:\n"
            for item in items:
                background_text += f"- {item['text']}\n"
            background_text += "\n"

    user_input = state['input']

    # 背景情報をキーワードベースで簡略化
    simplified_background = summarize_background(background_text, 2000)

    # JSON形式で出力を指定（日本語出力）
    prompt = f"""
    以下のユーザーの持つ課題を再生可能エネルギー導入の観点から分析し、明確化された問題点と目標を抽出してください。

    ## ユーザーの持つ課題:
    {user_input}

    ## 背景情報（簡易版）:
    {simplified_background}

    ## 出力形式（JSON 形式のみ）:
    {{
    "problems": [
    "問題 1 の詳細な説明",
    "問題 2 の詳細な説明",
    "問題 3 の詳細な説明"
    ],
    "goals": [
    "目標 1 の詳細な説明",
    "目標 2 の詳細な説明",
    "目標 3 の詳細な説明"
    ]
    }}
    
    ## 日本語で出力してください。
    
    問題項目ごとに 100～500 語で出力してください。
    目標項目ごとに 100～200 語で出力してください。
    """

    logging.info("問題明確化プロンプトを送信")
    print("  - 問題分析リクエスト送信中...")

    try:
        response = client_reasoner.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {'role': 'system', 'content': 'TRIZ手法に特化したAIアシスタントです。JSON形式の日本語で出力します。'},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        # JSONを直接解析
        output = response.choices[0].message.content
        result = json.loads(output)
        problems = result.get("problems", [])
        goals = result.get("goals", [])

        # フォールバック: 問題/目標が空の場合
        if not problems or not goals:
            logging.warning("問題/目標が空。代替抽出を試行")
            print("  ⚠️ 問題/目標が空。代替抽出を実行")
            problems, goals = extract_fallback_problems(user_input, simplified_background)

        # 問題と目標の表示
        print("\n📌 特定された問題:")
        for i, problem in enumerate(problems, 1):
            print(f"  {i}. {problem[:100]}...")

        print("\n🎯 特定された目標:")
        for i, goal in enumerate(goals, 1):
            print(f"  {i}. {goal[:100]}...")

        logging.info(f"問題を{len(problems)}個、目標を{len(goals)}個特定しました")
        elapsed = time.time() - start_time
        print(f"✅ [ステップ3/4] 問題の明確化を完了しました ({elapsed:.2f}秒)")
        return {**state, "problems": problems, "goals": goals}

    except json.JSONDecodeError:
        logging.error("JSON解析エラー。代替抽出を試行")
        print("  ❗ JSON解析エラー。代替抽出を実行")
        problems, goals = extract_fallback_problems(user_input, simplified_background)
        elapsed = time.time() - start_time
        print(f"⚠️ [ステップ3/4] 代替抽出完了 ({elapsed:.2f}秒)")
        return {**state, "problems": problems, "goals": goals}
    except Exception as e:
        logging.error(f"問題の明確化でエラー: {str(e)}")
        print(f"  ❗ エラー: {str(e)}")
        problems, goals = extract_fallback_problems(user_input, simplified_background)
        elapsed = time.time() - start_time
        print(f"⚠️ [ステップ3/4] 代替抽出完了 ({elapsed:.2f}秒)")
        return {**state, "problems": problems, "goals": goals}

# --- フォールバック問題抽出 ---
def extract_fallback_problems(user_input: str, background: str) -> tuple:
    """JSON失敗時の代替抽出方法"""
    logging.info("WARNING-フォールバックによる問題抽出を開始します")
    print("  ⚠️ フォールバック問題抽出を実行します")

    # 方法1: 自由形式出力から抽出
    try:
        prompt = f"""
        次のユーザーの課題から、明確化された問題と目標を抽出してください。
        {user_input}

        背景情報:
        {background}

        出力形式：
        ### 明確化された問題：
        - [問題 1]
        - [問題 2]

        ### 設定された目標：
        - [目標 1]
        - [目標 2]

        ## 日本語で出力してください。

        問題項目ごとに100～500語で出力してください。
        目標項目ごとに100～200語で出力してください。
        """

        response = client_reasoner.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {'role': 'system', 'content': 'ユーザーの課題と背景情報から、明確化された問題と目標を抽出してください'},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2
        )
        output = response.choices[0].message.content
        problems = []
        goals = []
        current_section = None

        for line in output.split('\n'):
            clean_line = line.strip()
            if "明確化された問題" in clean_line:
                current_section = "problems"
            elif "設定した目標" in clean_line:
                current_section = "goals"
            if clean_line.startswith(('-', '・', '*', '●')):
                content = line.strip().lstrip('-*・● ').strip()
                if 100 <= len(content) <= 500:  # 文字数制限を緩和
                    if current_section == "problems":
                        problems.append(content)
                    elif current_section == "goals":
                        goals.append(content)

        if problems and goals:
            return problems, goals
    except Exception:
        pass

    # 方法2: ユーザー入力から直接抽出
    logging.warning("自由形式抽出も失敗。直接抽出を試行")
    print("  ⚠️ 直接抽出を実行")
    problems = [
        "小型風力発電システムの導入コストが高い問題",
        "風力の不安定性による電力供給の不安定さ",
        "都市環境での騒音問題と設置制限"
    ]
    goals = [
        "小型風力システムのコスト最適化",
        "生態系への影響を最小限にする設計",
        "都市環境に適応した発電システムの開発"
    ]
    return problems, goals

```

D先生： “ここまでは、問題の明確化と目標の設定の段階になります。ここでは、プロンプトはJ語にしていますね。素直に、こうするほうがよかったですね。”

![imageTRIZ0-8-4](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-4.jpg) 

QEU:FOUNDER ： “やっぱり、J語の回答を得たいのであれば、J語で質問すべきだよね・・・（笑）。最後の矛盾の生成までいきましょう。”

```python
# --- 矛盾抽出 ---
def identify_contradictions(state: AnalysisState) -> AnalysisState:
    start_time = time.time()
    print("\n⚖️ [ステップ4/4] 矛盾の抽出を開始...")
    logging.info("矛盾の抽出を開始します")
    
    # TRIZ特徴辞書を作成
    triz_dict = {}
    # 正規表現で特徴を抽出
    pattern = re.compile(r'^\|\s*(\d+)\s*\|\s*(.+?)\s*\|\s*(.+?)\s*\|')
    for line in TRIZ_FEATURES.split('\n'):
        match = pattern.match(line)
        if match:
            num = match.group(1).strip()
            feature = match.group(2).strip()
            explanation = match.group(3).strip()
            triz_dict[num] = feature
    
    # 問題/目標が空の場合のフォールバック
    if not state['problems'] or not state['goals']:
        logging.warning("問題/目標が空。デフォルト矛盾を生成")
        print("  ⚠️ 問題/目標なし。デフォルト矛盾を生成")
        elapsed = time.time() - start_time
        print(f"✅ [ステップ4/4] 矛盾抽出完了 ({elapsed:.2f}秒)")
        return {**state, "contradictions": [{
            "improving": "9",
            "worsening": "22",
            "explanation": "WARNING-代替矛盾:風力発電の効率を上げるために風速を増加させると、エネルギーロスが増加するという矛盾"
        }]}
    
    problems_str = "\n- ".join(state['problems'])
    goals_str = "\n- ".join(state['goals'])
    
    # TRIZ特徴リストをプロンプトに追加
    triz_list = "\n".join([f"{num}: {feat}" for num, feat in triz_dict.items()])
    
    # プロンプトを改善
    prompt = f"""
    以下の問題と目標からTRIZ矛盾を抽出してください。
    矛盾特徴は番号（1〜39）と名前で指定してください。
    日本語で回答してください。
    
    ### TRIZ 39の矛盾特徴:
    {triz_list}
    
    ### 問題:
    {problems_str}
    
    ### 目標:
    {goals_str}
    
    ## 出力形式（JSONのみ）:
    {{
        "contradictions": [
            {{
                "improving": "改善特徴の番号",
                "improving_name": "改善特徴の名前",
                "worsening": "悪化特徴の番号",
                "worsening_name": "悪化特徴の名前",
                "explanation": "矛盾の説明（300文字以上500文字以内）"
            }},
            ...（最大5つまで）
        ]
    }}
    繰り返し要求します。回答は日本語にしてください。
    """
    
    try:
        print("  - 矛盾分析リクエスト送信中...")
        response = client_reasoner.chat.completions.create(
            model="deepseek-reasoner",
            messages=[
                {'role': 'system', 'content': 'TRIZ矛盾を抽出しJSON形式で出力してください'},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        output = response.choices[0].message.content
        result = json.loads(output)
        contradictions = result.get("contradictions", [])
        
        # 矛盾のバリデーション
        valid_contradictions = []
        for c in contradictions:
            # 必須フィールドのチェック
            if (c.get("improving") and c.get("worsening") and c.get("explanation") and
                c["improving"].isdigit() and c["worsening"].isdigit() and
                1 <= int(c["improving"]) <= 39 and 1 <= int(c["worsening"]) <= 39):
                
                # 特徴名が提供されていない場合は辞書から取得
                improving_name = c.get("improving_name") or triz_dict.get(c["improving"], "不明")
                worsening_name = c.get("worsening_name") or triz_dict.get(c["worsening"], "不明")
                
                valid_contradictions.append({
                    "improving": c["improving"],
                    "improving_name": improving_name,
                    "worsening": c["worsening"],
                    "worsening_name": worsening_name,
                    "explanation": c["explanation"][:500]  # 説明を500文字以内に制限
                })
        
        if not valid_contradictions:
            logging.warning("有効な矛盾が見つかりません。代替生成を試行")
            print("  ⚠️ 有効な矛盾なし。代替生成を実行")
            valid_contradictions = generate_fallback_contradictions(state, triz_dict)
        
        # 矛盾結果の表示
        print("\n🔀 抽出された矛盾:")
        for i, c in enumerate(valid_contradictions, 1):
            print(f"  {i}. 改善: #{c['improving']} {c['improving_name']}")
            print(f"     悪化: #{c['worsening']} {c['worsening_name']}")
            print(f"     → {c['explanation'][:70]}...")
        
        logging.info(f"合計{len(valid_contradictions)}個の矛盾を抽出しました")
        elapsed = time.time() - start_time
        print(f"✅ [ステップ4/4] 矛盾抽出完了 ({elapsed:.2f}秒)")
        return {**state, "contradictions": valid_contradictions}
    
    except Exception as e:
        logging.error(f"矛盾の抽出でエラー: {str(e)}")
        print(f"  ❗ エラー: {str(e)}")
        valid_contradictions = generate_fallback_contradictions(state, triz_dict)
        elapsed = time.time() - start_time
        print(f"⚠️ [ステップ4/4] 代替矛盾生成完了 ({elapsed:.2f}秒)")
        return {**state, "contradictions": valid_contradictions}


# --- 代替矛盾生成---
def generate_fallback_contradictions(state: AnalysisState, triz_dict: dict) -> List[Dict]:
    """問題/目標から矛盾を論理的に生成"""
    fallbacks = []
    
    # コスト関連の矛盾
    if any("コスト" in p for p in state['problems']) and any("効率" in g for g in state['goals']):
        fallbacks.append({
            "improving": "39",
            "improving_name": triz_dict.get("39", "生産性"),
            "worsening": "20",
            "worsening_name": triz_dict.get("20", "エネルギー消費"),
            "explanation": "WARNING-代替矛盾:発電効率を上げると設備コストが増加する矛盾"
        })
    
    # 環境関連の矛盾
    if any("環境" in p for p in state['problems']) and any("設置" in g for g in state['goals']):
        fallbacks.append({
            "improving": "5",
            "improving_name": triz_dict.get("5", "移動物体の面積"),
            "worsening": "31",
            "worsening_name": triz_dict.get("31", "物体が発生する有害要因"),
            "explanation": "WARNING-代替矛盾:発電面積を増やすと環境への悪影響が増加する矛盾"
        })
    
    # 技術的安定性の矛盾
    if any("不安定" in p for p in state['problems']) and any("安定" in g for g in state['goals']):
        fallbacks.append({
            "improving": "13",
            "improving_name": triz_dict.get("13", "物体の安定性"),
            "worsening": "21",
            "worsening_name": triz_dict.get("21", "エネルギー使用量"),
            "explanation": "WARNING-代替矛盾:システム安定性を高めるとエネルギー消費量が増加する矛盾"
        })
    
    return fallbacks if fallbacks else [{
        "improving": "9",
        "improving_name": triz_dict.get("9", "速度"),
        "worsening": "22",
        "worsening_name": triz_dict.get("22", "エネルギーロス"),
        "explanation": "WARNING-代替矛盾:風力発電の効率向上とエネルギーロス増加の矛盾"
    }]

# --- LangGraphワークフロー構築 ---
workflow = StateGraph(AnalysisState)
workflow.add_node("generate_background", generate_background)
workflow.add_node("consolidate_background", consolidate_background)
workflow.add_node("clarify_problem", clarify_problem)
workflow.add_node("identify_contradictions", identify_contradictions)
workflow.set_entry_point("generate_background")
workflow.add_edge("generate_background", "consolidate_background")
workflow.add_edge("consolidate_background", "clarify_problem")
workflow.add_edge("clarify_problem", "identify_contradictions")
workflow.add_edge("identify_contradictions", END)
app = workflow.compile()

# --- プロンプトを英語に変更 ---
user_prompt = """Our city (population about 500,000, Pacific coast) plans to reduce its reliance on thermal and nuclear power and promote the use of renewable energy in regional units (about 3,000 households). Specifically, we are considering introducing large-scale small-scale wind power genera-tion, but we face the following challenges:
- **Advantages of wind power generation**: Occasionally strong winds near the coast (but the wind is unstable).
- **Residents' concerns**: High cost, environmental impact (noise, ecosystem impact), and difficulty in urban installation.
- **Technical limitations**: The mainstream horizontal axis type (large propeller) is noisy and dis-rupts airflow, which is not suitable for urban areas.

Please collect and analyze relevant information on this issue (including international cases) and pro-pose appropriate solutions. At least include the following information:
- Reduce installation costs (such as: initial investment, maintenance cost reduction, etc.)
- Deal with unstable wind (such as: energy storage, hybrid system, gyro-type vertical axis wind tur-bine, decentralized smart grid, etc.)
- Reduce noise and ecosystem considerations (such as: minimize the impact on birds, etc.)
- Environmental adaptability of urban installation (such as: discussion of alternatives such as small wind turbines)"""

# 英語検索用にクエリを調整
tavily_prompt = "A medium-sized city (population approx. 500,000, Pacific coast) is considering in-troducing wind power. Residents generally support the plan but have concerns about costs, environ-mental and ecosystem impacts. We want to collect relevant information including international trends."

# --- カテゴリ名マッピング ---
cat_names = {
    "customer": "市民視点",
    "organization": "行政視点",
    "technology": "技術視点",
    "cost": "コスト視点",
    "legal": "法規制視点"
}

# --- 実行 ---
inputs = {
    "input": user_prompt,
    "tavily_input": tavily_prompt
}

print("="*50)
print("🚀 TRIZ分析ワークフローを開始します")
print("="*50)

result = app.invoke(inputs)

print("\n" + "="*50)
print("🏁 ワークフロー完了！最終結果:")
print("="*50)
print(json.dumps(result, ensure_ascii=False, indent=2))

```

QEU:FOUNDER ： “今回は、**JP_CN_ENの三か国語の矛盾情報をまとめた表**です。”

![imageTRIZ0-8-5](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-5.jpg) 

D先生： “前回と同様にバラバラに分布していますか？”

QEU:FOUNDER ： “そうなんです。矛盾って微妙なのですね。すごく不思議な気分です。ロバストな発明をするために、TRIZ原則別にまとめていかないとならないですね。そこで、以下のようなプログラムを、例によってVibe Codingで生成しました。”

```python
# ---
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Dict, Any

# データ準備
contradictions_df = pd.read_excel("contradictions_JPCNEN.xlsx")
triz_matrix = pd.read_excel("triz-39matrix.xlsx", index_col=0)
triz_principles_df = pd.read_excel("triz_principles_simple.xlsx")

# 原則ごとの矛盾情報を収集する関数
def extract_principles_with_histogram():
    principles_dict = {}
    
    for idx, row in contradictions_df.iterrows():
        imp = row['良化する特徴番号']
        wors = row['悪化する特徴番号']
        
        try:
            principles_str = triz_matrix.iat[imp-1, wors-1]
        except (IndexError, ValueError):
            continue
            
        if pd.isna(principles_str) or not principles_str:
            continue
            
        principles_str = principles_str.replace(" ", "").replace("、", ",")
        principles = [p.strip() for p in principles_str.split(",") if p.strip().isdigit()]
        
        for p in principles:
            p_int = int(p)
            principle_info = triz_principles_df[triz_principles_df['NO'] == p_int]
            if not principle_info.empty:
                title = principle_info.iloc[0]['Title']
                example = principle_info.iloc[0]['Example']
                
                contradiction_info = {
                    '矛盾番号': idx,
                    '改善特徴': imp,
                    '悪化特徴': wors,
                    '矛盾概要': row['矛盾の概要']
                }
                
                if p in principles_dict:
                    principles_dict[p]['related_contradictions'].append(contradiction_info)
                else:
                    principles_dict[p] = {
                        'principle_no': p,
                        'principle_title': title,
                        'principle_example': example,
                        'related_contradictions': [contradiction_info]
                    }
    
    # 原則ごとの矛盾件数を表示（フィルタ前）
    print("===== 原則ごとの矛盾件数 =====")
    principle_counts = []
    for p, info in principles_dict.items():
        count = len(info['related_contradictions'])
        principle_counts.append((int(p), count, info['principle_title']))
    
    # 件数1以下の情報を除外
    filtered_principle_counts = [pc for pc in principle_counts if pc[1] > 1]
    
    # 件数が多い順にソート
    sorted_principle_counts = sorted(filtered_principle_counts, key=lambda x: x[1], reverse=True)
    
    # ソート後の表示
    for pc in sorted_principle_counts:
        print(f"原則 {pc[0]}: {pc[2]} - {pc[1]}件")
    
    # ヒストグラム生成
    principle_numbers = [pc[0] for pc in sorted_principle_counts]
    counts = [pc[1] for pc in sorted_principle_counts]
    titles = [pc[2] for pc in sorted_principle_counts]
    
    indices = np.arange(len(sorted_principle_counts))
    
    plt.figure(figsize=(15, 8))
    bars = plt.bar(indices, counts, color='skyblue')
    plt.xlabel('TRIZ Principle Number')
    plt.ylabel('Number of Contradictions')
    plt.title('Histogram of Contradictions per TRIZ Principle')
    plt.xticks(indices, principle_numbers, rotation=90)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    # バー上に件数を表示
    for bar, count in zip(bars, counts):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                 f'{count}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('triz_principle_histogram.png')
    plt.show()
    
    return principles_dict

# 実行
principles_data = extract_principles_with_histogram()

# 原則ごとの詳細情報を表示
print("\n===== 原則ごとの詳細矛盾情報 =====")
for p, info in principles_data.items():
    count = len(info['related_contradictions'])
    if count <= 1:
        continue
    print(f"\n原則 {info['principle_no']}: {info['principle_title']}")
    print(f"適用例: {info['principle_example']}")
    print(f"関連矛盾件数: {count}")
    for contr in info['related_contradictions']:
        print(f" - 矛盾{contr['矛盾番号']}: [改善{contr['改善特徴']} vs 悪化{contr['悪化特徴']}]")
        print(f"   {contr['矛盾概要']}")

# 原則ごとの詳細矛盾情報をDataFrameに変換
filtered_principles = {}
for p, info in principles_data.items():
    if len(info['related_contradictions']) > 1:
        filtered_principles[p] = info

data = []
seqno = 1
for p, info in filtered_principles.items():
    principle_no = info['principle_no']
    principle_example = info['principle_example']
    for contr in info['related_contradictions']:
        data.append({
            'SEQNO': seqno,
            '原則NO': principle_no,
            '原則の適用例': principle_example,
            '矛盾番号': contr['矛盾番号'],
            '改善特徴NO vs 悪化特徴NO': f"{contr['改善特徴']} vs {contr['悪化特徴']}",
            '説明文': contr['矛盾概要']
        })
        seqno += 1

df_details = pd.DataFrame(data)
#df_details

# ---
df_details.to_excel('triz_principle_details.xlsx', index=False)

```

QEU:FOUNDER ： “これ（↓）を見れば、一目瞭然ですね。少数の原則を適用するだけで、ロバスト性のあるのシステム改善ができるんです。”

![imageTRIZ0-8-6](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-6.jpg) 

D先生： “いやあ・・・。これは分かりやすい。大体、件数が4件以上のものに対してシステム改善すればよさそうですね。それにしても、件数トップの「原則35:パラメータの変更」って、一体、なんだろう？”

**物体の状態の集積度・温度を変える。物体の物理的状態（気体、液体、固体など）を変更します。汚れてねばねくした熱い液体を扱う代わりに、詰め物の入ったキャンディーの中心の液体を凍らせてから、溶かしたチョコレートに浸します。体積を減らすために、酸素、窒素、石油ガスをガスではなく液体として輸送します。濃度または粘稠度を変更します。柔軟性の度合いを変更します。調整可能なダンパーを使用して、コンテナの壁の動きを制限することで、コンテナ内に落ちる部品の騒音を低減します。ゴムを加硫させて柔軟性と耐久性を変化させます。温度をキュリー点以上に上げると、強磁性物質が常磁性物質に変化します。食品の温度を上げて調理します（味、香り、食感、化学的性質などが変わります）。医療標本の温度を下げて、後で分析できるように保存します。**

QEU:FOUNDER ： “事例で表現すると、こう（↑）なります。相変化とか、設計（製造）パラメータのチューニングか？あとは、EXCELファイルに出力してみましょう。”

![imageTRIZ0-8-7](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-7.jpg) 

QEU:FOUNDER： “あとは、このファイルを次のステップで読み込み、LLM推論をするだけです。”

![imageTRIZ0-8-8](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-8.jpg) 

D先生 ： “新しい時代です。なにはともあれASIに聞いてみましょう。”



## ～ まとめ ～

QEU:FOUNDER ： “せっかくだから、ここでVibe Coding について総括をしようか。この動画（↓）を見ればわかる。非常に初歩的な観点から説明していて、我々素人集団からみても納得するところだ。”

[![MOVIE1](http://img.youtube.com/vi/c7NIIvrzqpI/0.jpg)](http://www.youtube.com/watch?v=c7NIIvrzqpI "【AI革命】プログラミング知識0で始められるバイブコーディング(Vibe Coding)のコツを解説")

C部長： “**簡単なものを作る分には、まったく問題ない**ということで・・・。”

![imageTRIZ0-8-9](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-9.jpg) 

QEU:FOUNDER ： “そう、基本は簡単なものを作るべきです。それでもVibe Codingって、ツボに入ると、すごいコードを作るんですよ。上級プログラマーの出来栄えのものを作るんです。その彼らのパワーを、「だましだまし」使う・・・（笑）。”

D先生： “だましだまし・・・？”

![imageTRIZ0-8-10](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-10.jpg) 

C部長： “DEEPSEEK様をだますんですか？”

QEU:FOUNDER ： “この動画でも説明しているでしょう？**AIを複数走らせた方が良い**です。我々の場合、QWENとDEEPSEEKを必ず並列して実行しています。そして、出来栄えが良い方を使う。実行してエラーがあっても、2つのAIに解析させ、そして再び出来の良いモノを使う。”

C部長： “手間がかかりますよね。”

QEU:FOUNDER ： “こういうやりかたは、バージョン管理が大変です。AIさんが、**「やらんでもいいこと」をすることがある**から・・・（笑）。”

![imageTRIZ0-8-11](/2025-06-20-QEUR23_TRIZ7/imageTRIZ0-8-11.jpg) 

QEU:FOUNDER ： “**スニペット管理が便利**ですよね。余計な部分を変えなくていいから。”

