---
title: QEUR23_SIWC4 - 閑話休題～Fireworks-LangChainを活用する
date: 2025-04-03
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_SIWC4 - 閑話休題～Fireworks-LangChainを活用する

## ～ あくまで、これは「復習」になります ～

QEU:FOUNDER ： “ちきしょう・・・。ここになって、世の中の動きの速さについていけないわ。”

[![MOVIE1](http://img.youtube.com/vi/QgAwIVB3UFU/0.jpg)](http://www.youtube.com/watch?v=QgAwIVB3UFU "松田語録：ソフトウェア知能爆発とは何か？")

D先生： “本当に速いですね。ほう・・・。この動画は「知能爆発」の件ですか・・・。以前から言われています。もうすぐ来るらしいですね。これは、例の「シンギュラリティ」とは何が違うんですか？”

![imageSWC1-5-1](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-1.jpg) 

QEU:FOUNDER ： “シンギュラリティって、人間とAIとの比較しての事象なので、比較の角度によっていろいろありうるよね。小生の理解は、**「単位時間におけるAIの知的生産量が全人間の生産量を超える」**という定義です。現状の世界情勢と、このモデル図（↑）を組み合わせると、**シンギュラリティは今年中に普通にある**よね。ただし、それは爆発と言えるかどうかはわかりません。”

D先生：“あれ？爆発せずにシンギュラリティ達成ですか？”

![imageSWC1-5-2](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-2.jpg) 

QEU:FOUNDER ： “ちなみに、さっきのモデル図の引用元はココ（↑）です。この論文のポイントは、ソフトウェアだけを使ってLLMモデルを学習することにより、ポジティブ・フィードバックが起こりうるというものです。しかし、**この論点はハードウェアのバイパスを軽視し過ぎていないか？**”

![imageSWC1-5-3](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-3.jpg) 

QEU:FOUNDER  ： “いまの最新技術を使えば、高度の知的生産を行うために「大きなAI(ex.プロプラエタリAI)」に頼る必要はないです。**自分に合ったものを作ればいいだけ**です。”

![imageSWC1-5-4](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-4.jpg) 

QEU:FOUNDER  ： “重要なのは、データの獲得です。”

![imageSWC1-5-5](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-5.jpg) 

D先生： “データの獲得者が自分で「自分にあったAGI」を操作し、新しい知識を生産していく。そして、よりよい品質、生産性向上、新しい魅力的な製品（サービス）が生まれます。こうやって「分散すればコストが安くなる」んです。さらにいえば、本来は分散している「それらの情報」を共有すれば・・・。“

![imageSWC1-5-6](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-6.jpg) 

QEU:FOUNDER  ： “Huggingfaceが参考になるね。最近、さらに加速している小型ＡＩの進歩とDMAICSサイクルが同期し、社会全体の価値が向上していく。このプロジェクト、やってみたいと思わん？”

D先生： “もう！やってみたい！！ “

![imageSWC1-5-7](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-7.jpg) 

QEU:FOUNDER ： “小生もやってみたいが、ちょっと別件（ＢＯＮＳＡＩ）が進んじゃっているんで、マイルストーンが来るまで、ちょっとまってね。ある程度まで行ったら、スイッチしましょう。さて、今回は、この業界の有名人が開発したプログラム（↑）を自分用に、小型に改造したいんです。”

D先生： “この人って、昔、強化学習の学習でお世話になりました。たしか、キャリアがOPENAIじゃなかったか？でも、なぜ彼女の投稿がMISTRALのCOOKBOOKに・・・。何はともあれ、FOUNDER・・・。今回は、何がしたいのですか？”

![imageSWC1-5-8](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-8.jpg) 

QEU:FOUNDER： “こんな風（↑）に、**自動的に学習する小型AIマシン**です。まずは、簡単なLangChainをやりましょう。それでは、プログラムをドン！まずは序盤です。”

```python
# ---
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma
from langchain_cohere import CohereEmbeddings

# エンべディングモデルの設定
embeddings = CohereEmbeddings(
    model="embed-multilingual-v3.0",
)

# ベクトルストアのファイルパス
VECTOR_STORE_PATH = "drive/MyDrive/chroma_db"

# ---
# データベースに取り込むURLのリスト
urls = [
    "https://jpnqeur23vtfdev.blogspot.com/2024/02/qeur23vtfdev0-introductionvit.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/02/qeur23vtfdev1-soartc.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/02/qeur23vtfdev2-soartcstep1a.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/02/qeur23vtfdev3-soartcstep1bsoart3.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/02/qeur23vtfdev4-soartcstep1c-soartcpart1.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/qeur23vtfdev5-soartcstep1d-soartcpart2.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/qeur23vtfdev6-soartc.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/qeur23vtfdev7-soartc-a.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/qeur23vtfdev8-soartc-2.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/qeur23vtfdev9-step2a.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/qeur23vtfdev10-step3a-soart3.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/qeur23vtfdev11-step3b.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/qeur23vtfdev12-step3c.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/soartc.html",
    "https://jpnqeur23vtfdev.blogspot.com/2024/03/technical-summary-visual-inspection.html",
    # ---
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt11-triplet.html",
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt12-triplet.html",
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt13-nsoartc.html",
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt14-nsoart.html",
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt15-triplet.html",
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt16-tripletsnn.html",
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt17-embeddingsnn.html",
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt18-pytorchsimpleembeddingmni.html",
    "https://jpnqeur23smnrt.blogspot.com/2024/12/qeur23smnrt19-pytorchsnnembeddingmnist.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt20-pytorchsimple.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt21-pytorchembedding.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt22-pytorchsnnembedding.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt23-snnembedding.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt24-soart3snn.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt25-soart3.html",
    # ---
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt40-pytorchtripletmnist.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt41-pytorchtripletmnist-2.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt42-pytorchtriplet.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt43-pytorchcnn-triplet.html",
    "https://jpnqeur23smnrt.blogspot.com/2025/01/qeur23smnrt44-pytorchcnn-triplet-2.html",
]


```

D先生： “これは懐かしい情報群ですね。この情報をベクトルストアに入れるわけです。 “

![imageSWC1-5-9](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-9.jpg) 

QEU:FOUNDER  ： “残念ながら、まだLLMの中にはない情報だから、「自分のポケット」に入れておくしかないです。それでは、つづけましょう。ちなみに、ベクトルストアはchroma、エンベッディングはCohereを使っています。これは、J語対策です。”

```python
# ---
def load_or_create_vectorstore():
    """ベクトルストアの読み込みまたは新規作成"""
    # 既存データベースの読み込み
    if os.path.exists(VECTOR_STORE_PATH):
        print("既存のChromaデータベースを読み込み中...")
        return Chroma(
            persist_directory=VECTOR_STORE_PATH,
            embedding_function=embeddings
        )
    
    # 新規作成処理
    print("新しいChromaデータベースを作成中...")
    
    # Webドキュメントの読み込み
    docs = []
    for url in urls:
        try:
            loader = WebBaseLoader(url)
            docs.extend(loader.load())
        except Exception as e:
            print(f"URL {url} の読み込みに失敗: {str(e)}")
            continue

    # テキスト分割（日本語対応）
    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=512,
        chunk_overlap=128,
        separators=["\n\n", "\n", "。", "、", " ", ""]  # 日本語の文分割を強化
    )
    doc_splits = text_splitter.split_documents(docs)

    # Chromaデータベースの作成
    vectorstore = Chroma.from_documents(
        documents=doc_splits,
        embedding=embeddings,
        persist_directory=VECTOR_STORE_PATH,
        collection_metadata={
            "language": "ja",
            "embedding_model": "cohere-multilingual-v3"
        }
    )
    
    print(f"データベースを {VECTOR_STORE_PATH} に保存しました")
    return vectorstore

# ---
# メイン処理
# ベクトルストアの準備
vectorstore = load_or_create_vectorstore()
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 5}  # 上位5件を取得
)

# 質問の実行
query = "外観検査と画像判別の技術上の差異を教えてください。"
retrieved_documents = retriever.invoke(query)

# show the retrieved document's content
content_txt = retrieved_documents[0].page_content
print(content_txt)

```

D先生： “このクエリを使うと、データベースから5件のチャンクが出てくるわけですね。 “

![imageSWC1-5-10](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-10.jpg) 

QEU:FOUNDER ： “ちゃんと、必要な情報を取り込んでいるようです。それでは、この情報を**FIREWORKSの小型LLM**に入れて推論します。”

```python
# ---
### Generate
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser

# Prompt
rag_prompt = """あなたは質問回答タスクのアシスタントです。次の取得したコンテキストを使用して質問に答えてください。
答えがわからない場合は、わからないとだけ言ってください。最大 3 つの文を使用し、答えは簡潔にしてください。

Question: {question} 

Context: {context} 

Answer:"""

# ---
# LLM
from langchain_fireworks import ChatFireworks

# Initialize a Fireworks chat model
llm = ChatFireworks(
    model="accounts/fireworks/models/llama-v3p3-70b-instruct",
    temperature=0.0,
    max_tokens=512
    )

# ---
rag_prompt_formatted = rag_prompt.format(context=content_txt, question=query)
generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])
print(generation)


```

D先生： “さて、結果はどう出るか・・・。”

![imageSWC1-5-11](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-11.jpg) 

D先生：“なかなか良さげです。もっと詳しく見たいです。”

content='外観検査と画像判別の技術上の差異は、CNN（Convolutional Neural Network）とViT（Vision Transformer）の違いである。CNNは畳み込みによって画像情報を集約して特徴ベクトルを作るため、個体判別に優れているが、被検査体の特徴が空間的に分離した場合の判別の精度は良くない。一方、ViTは自然言語処理から派生した技術であり、空間的な制限がないため、外観検査用に優れている可能性がある。'
 additional_kwargs={} 
response_metadata={'token_usage': {'prompt_tokens': 356, 'total_tokens': 486, 'completion_tokens': 130}, 
'model_name': 'accounts/fireworks/models/llama-v3p3-70b-instruct', 
'system_fingerprint': '', 
'finish_reason': 'stop', 'logprobs': None} 
usage_metadata={'input_tokens': 356, 'output_tokens': 130, 'total_tokens': 486}


D先生： “なるほどね。クエリの文に、「技術的に・・・」という言葉を入れたからこうなったでしょうね。このコメント自体は間違ってはいません。**「画像分類は、全体的に少しの変化がある」のに対し、「異常検出は99％は全く同じ、1%だけ異なる」** という風になれば、満点だったのだが・・・。“


QEU:FOUNDER  ： “それは、「事象」といいます。さて、次に進みましょう。”




## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER  ： “「巨人の方にのる（standing on shoulders on giants）」とは、どういう意味かを知る必要があります。ヒント：アイザック・ニュートン→リーナス・トーバルズ。。。”

[![MOVIE2](http://img.youtube.com/vi/RN__oJNICo4/0.jpg)](http://www.youtube.com/watch?v=RN__oJNICo4 "宮台真司氏出演！『乱世到来！社会・政治・世界の本質に迫る』")

D先生： “今回の結論は、コレ（↓）でしょうね・・・。”

![imageSWC1-5-12](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-12.jpg) 

QEU:FOUNDER ： “今回の結論、やはり「手遅れ」でしたね・・・（笑）。ただし、この苦しい中でも、がんばっている会社様がいるんだよなあ・・・。”

![imageSWC1-5-13](/2025-04-03-QEUR23_SIWC4/imageSWC1-5-13.jpg) 

D先生：“多分、あの手の人たちは、**本件にレスなし**じゃないんですか？最近は、別件（↓）で忙しいらしいし・・・。”

[![MOVIE3](http://img.youtube.com/vi/D8GDAZAs9b0/0.jpg)](http://www.youtube.com/watch?v=D8GDAZAs9b0")


QEU:FOUNDER ： “縮みつつある生存圏の確保で忙しい。**すべての行動原理は、「差別とお金」です。**”

