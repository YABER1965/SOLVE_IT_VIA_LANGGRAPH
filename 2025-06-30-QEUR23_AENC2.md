---
title: QEUR23_AENC2 - VATモデルを端子検査に適用してみる
date: 2025-06-30
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "LLM", "データセット", "BONSAI", "LangGraph"]
excerpt: あたらしいLLMの学習体系を確立する
---

## QEUR23_AENC2 - VATモデルを端子検査に適用してみる

## ～ できる！！ただし、MSEはダメ ～

### ・・・ 前回のつづきです ・・・

D先生（設定年齢65歳）： “じゃあ、いよいよ実践的な事例でやってみましょう。ここは、例によってコネクタの端子検査のモデルです。”

![imageANC0-3-1](/2025-06-30-QEUR23_AENC2/imageANC0-3-1.jpg) 

QEU:FOUNDER（設定年齢65歳） ： “前回は、単純な図形の判別でした。当然、全体の形に明確な違いがあるので、判別はSVM程度であってもイケルでしょう。それでもMSEメトリックスじゃあ、とても無理だが・・・。”

![imageANC0-3-2](/2025-06-30-QEUR23_AENC2/imageANC0-3-2.jpg) 

D先生： “今回は、どっちの画像をやりますか？**NSOART法は2ステップ法**になるので、2種類の画像が出てきます。”

![imageANC0-3-3](/2025-06-30-QEUR23_AENC2/imageANC0-3-3.jpg) 

D先生： “今回は、AUTOENCODERを使うんだったら、STEP1の出力画像で十分じゃないでしょうか？”

![imageANC0-3-4](/2025-06-30-QEUR23_AENC2/imageANC0-3-4.jpg) 

QEU:FOUNDER  ： “そうだね。STEP1の方が圧倒的にわかりやすいですね。少なくとも人間にとってみれば・・・。”

![imageANC0-3-5](/2025-06-30-QEUR23_AENC2/imageANC0-3-5.jpg) 

QEU:FOUNDER ： “STEP2であれば、画像のサイズが小さくなります。そうすると、CPUだけでも計算ができます。じゃあ、プログラムを動かしてみましょう。”

```python
# ---
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, Model
import cv2
import os
import random
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# GPUメモリ設定
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)

# 画像データ読み込み関数
def load_images_from_excel(excel_path, base_dir):
    df = pd.read_excel(excel_path)
    images = []
    labels = []
    filenames = []
    
    if "test" in base_dir:
        flag = 'test'
        for _, row in df.iterrows():
            dirname = row['dirname']
            label = row['label']
            filename = row['out_sianame']
            img_path = os.path.join(base_dir, dirname, filename)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                img = cv2.resize(img, (26, 36))
                img = img.astype(np.float32) / 255.0
                images.append(img)
                labels.append(label)
                filenames.append(filename)
    else:
        flag = 'train'
        for _, row in df.iterrows():
            filename = row['out_sianame']
            label = "OK"
            img_path = os.path.join(base_dir, filename)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                img = cv2.resize(img, (26, 36))
                img = img.astype(np.float32) / 255.0
                images.append(img)
                labels.append(label)
                filenames.append(filename)            

    return np.array(images).reshape(-1, 36, 26, 1), filenames, labels, flag

# 画像表示関数
def display_images_from_excel(excel_path, base_dir):
    X_array, filenames, labels, flag = load_images_from_excel(excel_path, base_dir)

    if len(X_array) >= 16:
        indices = random.sample(range(len(X_array)), 16)
    else:
        indices = list(range(len(X_array)))
        print(f"警告: データ数が不足しています（{len(X_array)}件）。全てのデータを表示します。")

    fig, axes = plt.subplots(4, 4, figsize=(16, 16))
    plt.subplots_adjust(hspace=0.4, wspace=0.3)
    for i, idx in enumerate(indices):
        ax = axes[i//4, i%4]
        img_data = X_array[idx].squeeze()
        str_name = filenames[idx].replace(".jpg", "").replace("camera", "")
        
        if flag == "test":
            str_label = labels[idx]
            str_title = f"{str_name} as {str_label}"
        else:
            str_title = str_name
        
        im = ax.imshow(img_data, cmap='viridis', aspect='auto')
        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        ax.set_title(str_title, fontsize=9)
        ax.set_xticks([])
        ax.set_yticks([])
    
    plt.suptitle(f"X_array:{flag} Data Heatmaps (Random 16 Samples)", fontsize=20, y=0.95)
    plt.savefig(f'heatmap_4x4_visualization_{flag}.png')
    plt.show()

    return X_array, filenames, labels

# ---
# データロードと画像表示
X_train, train_filenames, train_labels = display_images_from_excel('output_EXCELfile_train.xlsx', 'NSOART_train')

# ---
X_test, test_filenames, test_labels = display_images_from_excel('output_EXCELfile_test.xlsx', 'NSOART_test')

```

QEU:FOUNDER ： “まあ、いままで紹介した画像なので、とくにコメントする必要がないのだが。”

![imageANC0-3-6](/2025-06-30-QEUR23_AENC2/imageANC0-3-6.jpg) 

D先生： “画像サイズは、たった**36x26**です。PC計算には、ちょうどいい大きさですね。”

QEU:FOUNDER ： “TRAINデータベースには**不良画像はありません**。TESTベースには、不良画像が多く含まれています。次にすすみましょう。”

```python
# ---
# VAEモデル定義
class Sampling(layers.Layer):
    def call(self, inputs):
        z_mean, z_log_var = inputs
        epsilon = tf.random.normal(shape=tf.shape(z_mean))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon

class VAE(Model):
    def __init__(self, input_shape, latent_dim=128):
        super().__init__()
        self.latent_dim = latent_dim
        
        self.encoder = tf.keras.Sequential([
            layers.Conv2D(32, 3, strides=2, padding='same', activation='relu', input_shape=input_shape),
            layers.BatchNormalization(),
            layers.Conv2D(64, 3, strides=2, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.Conv2D(128, 3, strides=2, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.Flatten(),
            layers.Dense(latent_dim * 2, name='encoder_output')
        ], name="encoder")
        
        self.sampling = Sampling()
        
        self.decoder = tf.keras.Sequential([
            layers.Dense(5 * 4 * 128, activation='relu'),
            layers.Reshape((5, 4, 128)),
            layers.Conv2DTranspose(128, 3, strides=2, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.Conv2DTranspose(64, 3, strides=2, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.Conv2DTranspose(32, 3, strides=2, padding='same', activation='relu'),
            layers.BatchNormalization(),
            layers.Lambda(lambda x: tf.image.resize(x, (36, 26))),
            layers.Conv2D(1, 3, padding='same', activation='sigmoid')
        ], name="decoder")

    def encode(self, x):
        h = self.encoder(x)
        z_mean, z_log_var = tf.split(h, num_or_size_splits=2, axis=1)
        z = self.sampling((z_mean, z_log_var))
        return z_mean, z_log_var, z

    def decode(self, z):
        return self.decoder(z)

    def call(self, inputs):
        z_mean, z_log_var, z = self.encode(inputs)
        return self.decode(z)

    def train_step(self, data):
        x, _ = data
        with tf.GradientTape() as tape:
            z_mean, z_log_var, z = self.encode(x)
            reconstruction = self.decode(z)
            rec_loss = tf.reduce_mean(tf.reduce_sum(tf.square(x - reconstruction), axis=[1,2,3]))
            kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))
            total_loss = rec_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        return {"loss": total_loss, "reconstruction_loss": rec_loss, "kl_loss": kl_loss}

    def test_step(self, data):
        x, _ = data
        z_mean, z_log_var, z = self.encode(x)
        reconstruction = self.decode(z)
        rec_loss = tf.reduce_mean(tf.reduce_sum(tf.square(x - reconstruction), axis=[1,2,3]))
        kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))
        total_loss = rec_loss + kl_loss
        return {"loss": total_loss, "reconstruction_loss": rec_loss, "kl_loss": kl_loss}

# ---
# 訓練データの再構成誤差
model = vae
reconstructed_train = model.predict(X_train)
mse_train = np.mean(np.power(X_train - reconstructed_train, 2), axis=(1, 2, 3))
threshold = np.percentile(mse_train, 95)
print(f"Threshold: {threshold}")

# ---
# テストデータの再構成誤差
reconstructed_test = model.predict(X_test)
mse_test = np.mean(np.power(X_test - reconstructed_test, 2), axis=(1, 2, 3))

# 異常判定
pred_labels = (mse_test > threshold).astype(int)

# MSEヒストグラムの描画
# 真のラベルを二値化 (0=正常, 1=異常)
true_labels_binary = np.where(np.array(test_labels) == 0, 0, 1)

plt.figure(figsize=(10, 6))
plt.hist(mse_test[true_labels_binary == 0], bins=30, alpha=0.5, label='Normal', color='blue')
plt.hist(mse_test[true_labels_binary == 1], bins=30, alpha=0.5, label='Anomaly', color='red')
plt.axvline(x=threshold, color='r', linestyle='--', label=f'Threshold: {threshold:.4f}')
plt.title('Distribution of Reconstruction MSE')
plt.xlabel('MSE')
plt.ylabel('Frequency')
plt.legend()
plt.grid(True)
plt.savefig('mse_distribution.png')
plt.show()

```

D先生： “へえ・・・。おもしろい学習曲線です。急速に学習が進んだようです。PCから見ると、非常に学習しやすい画像のようです。”

![imageANC0-3-7](/2025-06-30-QEUR23_AENC2/imageANC0-3-7.jpg) 

QEU:FOUNDER ： “いよいよ、評価の段階に進みましょう。”

```python
# ---
# 混同行列
# 予測ラベルを二値化
pred_labels_binary = np.where(pred_labels == 0, 0, 1)

cm = confusion_matrix(true_labels_binary, pred_labels_binary)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Anomaly'])
disp.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix.png')
plt.show()

# 分類レポート
print("\nClassification Report:")
print(f"True Normal: {sum(true_labels_binary == 0)}")
print(f"True Anomaly: {sum(true_labels_binary == 1)}")
print(f"Predicted Normal: {sum(pred_labels_binary == 0)}")
print(f"Predicted Anomaly: {sum(pred_labels_binary == 1)}")
print(f"Accuracy: {np.mean(true_labels_binary == pred_labels_binary):.4f}")

```

QEU:FOUNDER ： “これを見ると、おもわず笑うよ。”

![imageANC0-3-8](/2025-06-30-QEUR23_AENC2/imageANC0-3-8.jpg) 

D先生： “知ってはいたが、MSEは、ひでえな・・・(笑)。”

QEU:FOUNDER ： “まあ、差異画像を見れば、起きている人間ならば「一発で」わかります。”

```python
# ---
# 個別画像予測関数
def predict_single_image(model, image):
    input_image = np.expand_dims(image, axis=0)
    reconstruction = model.predict(input_image)
    rec_image = reconstruction[0]
    mse = np.mean(np.power(image - rec_image, 2))
    return rec_image, mse

# ---
# 5つのランダムなテスト画像を可視化
if len(X_test) >= 5:
    indices = random.sample(range(len(X_test)), 5)
else:
    indices = list(range(len(X_test)))
    print(f"警告: テストデータ数が不足しています（{len(X_test)}件）。全てのデータを表示します。")

# 図のサイズを横長に設定 (幅30インチ, 高さ18インチ)
plt.figure(figsize=(30, 18))

# カラーバーの範囲を決定するための最小値と最大値を計算
vmin, vmax = float('inf'), float('-inf')
diff_images = []

# 最初に全ての差分画像を計算して範囲を決定
for idx in indices:
    img = X_test[idx]
    rec_img, mse = predict_single_image(model, img)
    diff_img = np.abs(img.squeeze() - rec_img.squeeze())
    diff_images.append(diff_img)
    
    # 全体の最小値と最大値を更新
    vmin = min(vmin, np.min(diff_img))
    vmax = max(vmax, np.max(diff_img))

# カラーバーの範囲を設定（10%のマージンを追加）
margin = (vmax - vmin) * 0.1
vmin -= margin
vmax += margin

# 画像をプロット
for i, idx in enumerate(indices):
    img = X_test[idx]
    rec_img, mse = predict_single_image(model, img)
    
    # 元画像 - 1行目
    plt.subplot(3, 5, i+1)
    plt.imshow(img.squeeze(), cmap='gray')
    plt.title(f'Original: {test_filenames[idx]}', fontsize=12)
    plt.axis('off')
    
    # 再構成画像 - 2行目
    plt.subplot(3, 5, i+6)
    plt.imshow(rec_img.squeeze(), cmap='gray')
    plt.title(f'Reconstructed\nMSE: {mse:.4f}', fontsize=12)
    plt.axis('off')
    
    # 差異画像 - 3行目 (共通のカラースケールを使用)
    plt.subplot(3, 5, i+11)
    im = plt.imshow(diff_images[i], cmap='viridis', vmin=vmin, vmax=vmax)
    plt.title(f'Difference\nTrue Label: {test_labels[idx]}', fontsize=12)
    plt.axis('off')

# 共通のカラーバーを追加
cax = plt.axes([0.15, 0.05, 0.7, 0.02])  # [left, bottom, width, height]
plt.colorbar(im, cax=cax, orientation='horizontal')
cax.set_xlabel('Difference Magnitude', fontsize=14)

plt.suptitle('Original vs Reconstructed vs Difference Images', fontsize=24, y=0.98)
plt.tight_layout(rect=[0, 0.08, 1, 0.96])  # 下部にスペースを確保
plt.savefig('comparison_5_samples.png', bbox_inches='tight')
plt.show()

```

D先生： “結論からいうと納得の結果です。しかし、再構成画像って、ちょっと再構成の精度が悪くないですか？**形状は正確ですが、濃淡が不正確です**。”

![imageANC0-3-9](/2025-06-30-QEUR23_AENC2/imageANC0-3-9.jpg) 

QEU:FOUNDER ： “VAEモデルが、まだ簡単なんでしょうね。”

D先生： “VAEモデルを改善しますか？”

QEU:FOUNDER  ： “つまらない。もし、これ以上やるのであればSTEP1の画像を使いたいです。D先生が検査エンジニアだったら、STEP2画像をわざわざ使って予測したい？”

D先生： “今回の場合、STEP2の手間は、どう考えても無意味ですね。GPU節約以外は・・・。”

QEU:FOUNDER  ： “GPUが必要になるので、これ以上やるかどうかわからんが、まあ、今回はここまでにしましょう。”



## ～ まとめ ～

## ・・・ 前回のつづきです ・・・

C部長 : “この図（↓）に異議あり！あの2つのグループ（政党）は、加速主義なんですかねえ？”

![imageANC0-3-10](/2025-06-30-QEUR23_AENC2/imageANC0-3-10.jpg) 

QEU:FOUNDER ： “特に、最近人気の2つのグループは、**「何かにとりつかれて加速している」**ようにしか思えません。”

![imageANC0-3-11](/2025-06-30-QEUR23_AENC2/imageANC0-3-11.jpg) 

QEU:FOUNDER ： “実は、自〇党って、あくまで**「条件付き」**なんだけど、まだマシな方だと思うんです。さて、今回の本題に入るか・・・。少なくとも3年間後ぐらいには、**40sがキーになる**と思います。”

![imageANC0-3-12](/2025-06-30-QEUR23_AENC2/imageANC0-3-12.jpg) 

C部長（設定年齢50代前半） : “私のジェネレーションですね！！”

QEU:FOUNDER ： “うそつけ！！鏡を見ろや・・・。いわゆる40sというのは、こんな感じだぞ！！”

![imageANC0-3-13](/2025-06-30-QEUR23_AENC2/imageANC0-3-13.jpg) 

C部長 : “なるほど・・・。これが、「40s」なのか・・・。Copilotで質問してみたんでしょ？ちょっとデータにずれもありますが、40sの代表的な特性が薄っすら見えています。これが50sの場合は、どうなりますか？”

![imageANC0-3-14](/2025-06-30-QEUR23_AENC2/imageANC0-3-14.jpg) 

QEU:FOUNDER （設定年齢60代後半）： “なんで、あのオッサンが出てくる？大丈夫か？Copilot・・・（笑）。こうやって調べてみると、我々の年代(60s)のことも調べたくなってきました。”

![imageANC0-3-15](/2025-06-30-QEUR23_AENC2/imageANC0-3-15.jpg) 

QEU:FOUNDER ： “はは・・・、(人材が)薄いなあ・・・（笑）。やはり思った通りでした。**70sは30年の破滅への道を推進したA級某だとすると、60sはB級なんです**。何もしなかった、**単にシステムにしがみついてきた**という点で・・・。”

C部長 : “まあ、60sは、若い時にJ国のカッコ良いところを味わうことが出来ましたからね。変わろうという意図がなかったんですよ。そういえば、昔、あることを聞いたときがあります。なんか、外国の方がずいぶんと(J国を)褒めてくれたとのことで・・・。”

![imageANC0-3-16](/2025-06-30-QEUR23_AENC2/imageANC0-3-16.jpg) 

QEU:FOUNDER ： “まさか、最近になって新版が出てくると思いませんでした。どのようなニーズがあったんだろうか・・・。それにしても、**本の「章立て」が面白い**ね。”

- 日本の挑戦（アメリカの「鏡」／日本の奇跡）
- 日本の成功**（知識ー集団としての知識追求／政府ー実力に基づく指導と民間の自主性／政府ー総合利益と公正な分配／大企業ー社員の一体感と業績 ほか）**
- アメリカの対応（教訓ー西洋は東洋から何を学ぶべきか）

C部長 : “ほう・・・、この分析は当たっているようです。なぜなら、**最近の30年間は、それを全部否定していますから**。・・・とある、平成の大偉人（↓）の登場を機会として・・・。”

![imageANC0-3-17](/2025-06-30-QEUR23_AENC2/imageANC0-3-17.jpg) 

QEU:FOUNDER ： “なんか、うんざりしてきた・・・（笑）。今回、こうやって世代別の代表的なキャラを集めたのは、ある傾向が見えるからなんです。50sが、**旧体制(↓)が通用するラストの世代**だと思うんです。”

![imageANC0-3-18](/2025-06-30-QEUR23_AENC2/imageANC0-3-18.jpg) 

QEU:FOUNDER ： “右（保守）とか左（リベラル）で政治を評価するのは、実質的に2024年で終わったのではないでしょうか？ここで注意です、「実質的に」だよ。だから、これから「保守」と言う言葉で、本当の意味で人心をつかむことができない。そのレジームの根本的な変化の予兆を、彼ら「加速派」の一部は、すでにわかっている。”

![imageANC0-3-19](/2025-06-30-QEUR23_AENC2/imageANC0-3-19.jpg) 

QEU:FOUNDER ： “組織の本質は旧来通り**（もしくはより悪質）**なのだが、それは外面からは見えなくなってきているんです。今の人には、右とか左とか、あまり興味がないですよね。もっと身近な生活や、人や組織が発信する雰囲気に興味が向くのは当然です。”

[![MOVIE1](http://img.youtube.com/vi/34f2xSrek6s/0.jpg)](http://www.youtube.com/watch?v=34f2xSrek6s "参院選を徹底議論 トランプで崩壊、世界秩序 （内田 聖子／布施 祐仁／小塚 かおる／白井 聡）")

C部長 : “じゃあ、彼らのいう「新しい時代」に乗っかっちゃおうかな♪”

![imageANC0-3-20](/2025-06-30-QEUR23_AENC2/imageANC0-3-20.jpg) 

QEU:FOUNDER ： “しかし、**内面と外面が一致していない**ので、いろいろとボロ（↑）が出てくるんです。もし、それでも乗っかりたいのであれば、もうちょっと観察してからの方がいいと思いますよ。”

![imageANC0-3-21](/2025-06-30-QEUR23_AENC2/imageANC0-3-21.jpg) 

C部長 : “じゃあ、この2つのパーティー（↑）はどうなんですか？２つとも、いかにも「50sのニオイ」がプンプンしますが・・・。う～ん、なんというかな。あの名前が**「賞味期限切れ」**なんですよ。すでに人々は**「明治がベンチマークではない」**ことについて気が付いているのではないか？それにも関わらず、**「〇新」とか「新〇組」とか**・・・。”

[![MOVIE2](http://img.youtube.com/vi/4S1b4uVd0II/0.jpg)](http://www.youtube.com/watch?v=4S1b4uVd0II "参院選の目標は？｜参政党の“消費税段階廃止”に「寄せてるんちゃうの？」｜石破首相「2万給付案」とれいわ「10万給付案」の違いは")

QEU:FOUNDER ： “「←のイケメン」は、もうオワリでしょう。・・・と言うか、**世のため人のためにも、もう終わって欲しい**。もう一方の側は、最近になって少しだけ理念に修正を入れつつあるのかな？うまく脱皮が可能であれば、まだ期待ができるかもしれない。それでも名前が悪いのは、まさにその通り・・・（笑）。”

